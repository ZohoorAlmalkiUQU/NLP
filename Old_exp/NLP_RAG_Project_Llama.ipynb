{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61c367aa-e0a3-4116-bda7-7b81404211fd",
   "metadata": {
    "id": "61c367aa-e0a3-4116-bda7-7b81404211fd"
   },
   "source": [
    "<center>\n",
    "<p style=\"text-align:center\"><img alt=\"Ragas\" src=\"https://github.com/explodinggradients/ragas/blob/main/docs/_static/imgs/logo.png?raw=true\" width=\"400\"><br><a href=\"https://arize.com/docs/phoenix/\">Phoenix Docs</a> | <a href=\"https://github.com/explodinggradients/ragas\">Ragas</a> | <a href=\"https://arize-ai.slack.com/join/shared_invite/zt-2w57bhem8-hq24MB6u7yE_ZF_ilOYSBw#/shared-invite/email\">Community</a>\n",
    "</p>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baf25a1-02bc-43c7-82e9-93e362485b74",
   "metadata": {
    "id": "0baf25a1-02bc-43c7-82e9-93e362485b74"
   },
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Building a baseline for a RAG pipeline is not usually difficult, but enhancing it to make it suitable for real-world Arabic question-answering tasks requires careful evaluation, observability, and iterative refinement. Choosing the right tools, retrieval strategies, and LLM configurations can be challenging, especially when working with large and diverse datasets.\n",
    "\n",
    "This notebook demonstrates how to **evaluate, visualize, and analyze an Arabic RAG pipeline** using a combination of powerful open-source libraries:\n",
    "\n",
    "- **[Ragas](https://docs.ragas.io/en/stable/)** for evaluation metrics such as faithfulness, answer correctness, context precision, and context recall  \n",
    "- **Arize AI’s [Phoenix](https://arize.com/docs/phoenix)** for tracing, debugging, embedding visualization, and cluster analysis  \n",
    "- **[LlamaIndex](https://docs.llamaindex.ai/en/stable/)** for building RAG pipelines, managing document indexes, and connecting retrieval to LLMs  \n",
    "\n",
    "In this tutorial, instead of using arXiv PDFs, we will work with the **ArabicaQA dataset**, a large-scale Arabic machine-reading comprehension (MRC) dataset containing questions, contexts, and ground-truth answers. This allows us to build and evaluate an **Arabic-focused RAG system** in a realistic setting.\n",
    "\n",
    "> ℹ️ **Note:**  \n",
    "> This notebook uses **open-source HuggingFace LLMs** (such as LLaMA or Gemma) and **does not require an OpenAI API key**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcb4058",
   "metadata": {
    "id": "1dcb4058"
   },
   "source": [
    "## 2. Install Dependencies and Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4899e7a-43ef-4ae7-8f12-0024037a0b43",
   "metadata": {
    "id": "c4899e7a-43ef-4ae7-8f12-0024037a0b43"
   },
   "source": [
    "Install and import Python dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d18e80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "f2d18e80",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "a8281785-7dda-4315-fd51-ede9d90e4c58",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ragas==0.1.4\n",
      "  Using cached ragas-0.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pypdf\n",
      "  Using cached pypdf-6.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting openai>=1.0.0\n",
      "  Using cached openai-2.8.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting httpx<0.28\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting openinference-instrumentation>=0.1.38\n",
      "  Using cached openinference_instrumentation-0.1.42-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting arize-phoenix[embeddings,llama-index]\n",
      "  Using cached arize_phoenix-12.16.0-py3-none-any.whl.metadata (35 kB)\n",
      "Collecting numpy (from ragas==0.1.4)\n",
      "  Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting datasets (from ragas==0.1.4)\n",
      "  Using cached datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting tiktoken (from ragas==0.1.4)\n",
      "  Downloading tiktoken-0.12.0-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting langchain (from ragas==0.1.4)\n",
      "  Using cached langchain-1.0.8-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting langchain-core (from ragas==0.1.4)\n",
      "  Downloading langchain_core-1.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting langchain-community (from ragas==0.1.4)\n",
      "  Using cached langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-openai (from ragas==0.1.4)\n",
      "  Using cached langchain_openai-1.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pysbd>=0.3.4 (from ragas==0.1.4)\n",
      "  Using cached pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from ragas==0.1.4) (1.6.0)\n",
      "Collecting appdirs (from ragas==0.1.4)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting anyio (from httpx<0.28)\n",
      "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting certifi (from httpx<0.28)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<0.28)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<0.28)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting sniffio (from httpx<0.28)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<0.28)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from pypdf) (4.15.0)\n",
      "Collecting aioitertools (from arize-phoenix[embeddings,llama-index])\n",
      "  Downloading aioitertools-0.13.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting aiosqlite (from arize-phoenix[embeddings,llama-index])\n",
      "  Using cached aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting alembic<2,>=1.3.0 (from arize-phoenix[embeddings,llama-index])\n",
      "  Using cached alembic-1.17.2-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting arize-phoenix-client>=1.23.0 (from arize-phoenix[embeddings,llama-index])\n",
      "  Using cached arize_phoenix_client-1.24.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting arize-phoenix-evals>=2.6.0 (from arize-phoenix[embeddings,llama-index])\n",
      "  Using cached arize_phoenix_evals-2.6.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting arize-phoenix-otel>=0.10.3 (from arize-phoenix[embeddings,llama-index])\n",
      "  Using cached arize_phoenix_otel-0.14.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting authlib (from arize-phoenix[embeddings,llama-index])\n",
      "  Using cached authlib-1.6.5-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting cachetools (from arize-phoenix[embeddings,llama-index])\n",
      "  Downloading cachetools-6.2.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting email-validator (from arize-phoenix[embeddings,llama-index])\n",
      "  Using cached email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting fastapi (from arize-phoenix[embeddings,llama-index])\n",
      "  Using cached fastapi-0.121.3-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting grpc-interceptor (from arize-phoenix[embeddings,llama-index])\n",
      "  Using cached grpc_interceptor-0.15.4-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting grpcio (from arize-phoenix[embeddings,llama-index])\n",
      "  Downloading grpcio-1.76.0-cp310-cp310-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting jinja2 (from arize-phoenix[embeddings,llama-index])\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jmespath (from arize-phoenix[embeddings,llama-index])\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting openinference-semantic-conventions>=0.1.20 (from arize-phoenix[embeddings,llama-index])\n",
      "  Using cached openinference_semantic_conventions-0.1.25-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp (from arize-phoenix[embeddings,llama-index])\n",
      "  Using cached opentelemetry_exporter_otlp-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-proto>=1.12.0 (from arize-phoenix[embeddings,llama-index])\n",
      "  Using cached opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk (from arize-phoenix[embeddings,llama-index])\n",
      "  Using cached opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-semantic-conventions (from arize-phoenix[embeddings,llama-index])\n",
      "  Using cached opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting orjson (from arize-phoenix[embeddings,llama-index])\n",
      "  Downloading orjson-3.11.4-cp310-cp310-win_amd64.whl.metadata (42 kB)\n",
      "Collecting prometheus-client (from arize-phoenix[embeddings,llama-index])\n",
      "  Downloading prometheus_client-0.23.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting protobuf>=4.25.8 (from arize-phoenix[embeddings,llama-index])\n",
      "  Downloading protobuf-6.33.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: psutil in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from arize-phoenix[embeddings,llama-index]) (7.1.3)\n",
      "Collecting pyarrow (from arize-phoenix[embeddings,llama-index])\n",
      "  Downloading pyarrow-22.0.0-cp310-cp310-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting pydantic>=2.1.0 (from arize-phoenix[embeddings,llama-index])\n",
      "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from arize-phoenix[embeddings,llama-index]) (2.9.0.post0)\n",
      "Collecting python-multipart (from arize-phoenix[embeddings,llama-index])\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting scikit-learn (from arize-phoenix[embeddings,llama-index])\n",
      "  Downloading scikit_learn-1.7.2-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Collecting scipy (from arize-phoenix[embeddings,llama-index])\n",
      "  Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting sqlalchemy<3,>=2.0.4 (from sqlalchemy[asyncio]<3,>=2.0.4->arize-phoenix[embeddings,llama-index])\n",
      "  Downloading sqlalchemy-2.0.44-cp310-cp310-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting sqlean-py<3.50,>=3.45.1 (from arize-phoenix[embeddings,llama-index])\n",
      "  Downloading sqlean_py-3.49.1-cp310-cp310-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting starlette (from arize-phoenix[embeddings,llama-index])\n",
      "  Using cached starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting strawberry-graphql==0.270.1 (from arize-phoenix[embeddings,llama-index])\n",
      "  Using cached strawberry_graphql-0.270.1-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting tqdm (from arize-phoenix[embeddings,llama-index])\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting uvicorn (from arize-phoenix[embeddings,llama-index])\n",
      "  Using cached uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting wrapt<2,>=1.17.2 (from arize-phoenix[embeddings,llama-index])\n",
      "  Downloading wrapt-1.17.3-cp310-cp310-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting fast-hdbscan>=0.2.0 (from arize-phoenix[embeddings,llama-index])\n",
      "  Using cached fast_hdbscan-0.2.2-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting numba>=0.60.0 (from arize-phoenix[embeddings,llama-index])\n",
      "  Downloading numba-0.62.1-cp310-cp310-win_amd64.whl.metadata (2.9 kB)\n",
      "Collecting umap-learn (from arize-phoenix[embeddings,llama-index])\n",
      "  Using cached umap_learn-0.5.9.post2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting graphql-core<3.4.0,>=3.2.0 (from strawberry-graphql==0.270.1->arize-phoenix[embeddings,llama-index])\n",
      "  Using cached graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=23 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from strawberry-graphql==0.270.1->arize-phoenix[embeddings,llama-index]) (25.0)\n",
      "Collecting Mako (from alembic<2,>=1.3.0->arize-phoenix[embeddings,llama-index])\n",
      "  Using cached mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting tomli (from alembic<2,>=1.3.0->arize-phoenix[embeddings,llama-index])\n",
      "  Downloading tomli-2.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from python-dateutil->arize-phoenix[embeddings,llama-index]) (1.17.0)\n",
      "Collecting greenlet>=1 (from sqlalchemy<3,>=2.0.4->sqlalchemy[asyncio]<3,>=2.0.4->arize-phoenix[embeddings,llama-index])\n",
      "  Downloading greenlet-3.2.4-cp310-cp310-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.0.0)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai>=1.0.0)\n",
      "  Downloading jiter-0.12.0-cp310-cp310-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from anyio->httpx<0.28) (1.3.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.1.0->arize-phoenix[embeddings,llama-index])\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic>=2.1.0->arize-phoenix[embeddings,llama-index])\n",
      "  Downloading pydantic_core-2.41.5-cp310-cp310-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic>=2.1.0->arize-phoenix[embeddings,llama-index])\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-api (from openinference-instrumentation>=0.1.38)\n",
      "  Using cached opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpath-ng (from arize-phoenix-evals>=2.6.0->arize-phoenix[embeddings,llama-index])\n",
      "  Using cached jsonpath_ng-1.7.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting pystache (from arize-phoenix-evals>=2.6.0->arize-phoenix[embeddings,llama-index])\n",
      "  Using cached pystache-0.6.8-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting llvmlite<0.46,>=0.45.0dev0 (from numba>=0.60.0->arize-phoenix[embeddings,llama-index])\n",
      "  Downloading llvmlite-0.45.1-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->arize-phoenix[embeddings,llama-index])\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->arize-phoenix[embeddings,llama-index])\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from tqdm->arize-phoenix[embeddings,llama-index]) (0.4.6)\n",
      "Collecting cryptography (from authlib->arize-phoenix[embeddings,llama-index])\n",
      "  Downloading cryptography-46.0.3-cp38-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting cffi>=2.0.0 (from cryptography->authlib->arize-phoenix[embeddings,llama-index])\n",
      "  Downloading cffi-2.0.0-cp310-cp310-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting pycparser (from cffi>=2.0.0->cryptography->authlib->arize-phoenix[embeddings,llama-index])\n",
      "  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Collecting filelock (from datasets->ragas==0.1.4)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets->ragas==0.1.4)\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting requests>=2.32.2 (from datasets->ragas==0.1.4)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting xxhash (from datasets->ragas==0.1.4)\n",
      "  Downloading xxhash-3.6.0-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets->ragas==0.1.4)\n",
      "  Downloading multiprocess-0.70.18-py310-none-any.whl.metadata (7.5 kB)\n",
      "Collecting fsspec<=2025.10.0,>=2023.1.0 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->ragas==0.1.4)\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting huggingface-hub<2.0,>=0.25.0 (from datasets->ragas==0.1.4)\n",
      "  Using cached huggingface_hub-1.1.5-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pyyaml>=5.1 (from datasets->ragas==0.1.4)\n",
      "  Downloading pyyaml-6.0.3-cp310-cp310-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->ragas==0.1.4)\n",
      "  Downloading aiohttp-3.13.2-cp310-cp310-win_amd64.whl.metadata (8.4 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.25.0->datasets->ragas==0.1.4)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting shellingham (from huggingface-hub<2.0,>=0.25.0->datasets->ragas==0.1.4)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typer-slim (from huggingface-hub<2.0,>=0.25.0->datasets->ragas==0.1.4)\n",
      "  Using cached typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->ragas==0.1.4)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->ragas==0.1.4)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->ragas==0.1.4)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->ragas==0.1.4)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->ragas==0.1.4)\n",
      "  Downloading frozenlist-1.8.0-cp310-cp310-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->ragas==0.1.4)\n",
      "  Downloading multidict-6.7.0-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->ragas==0.1.4)\n",
      "  Downloading propcache-0.4.1-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->ragas==0.1.4)\n",
      "  Downloading yarl-1.22.0-cp310-cp310-win_amd64.whl.metadata (77 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.32.2->datasets->ragas==0.1.4)\n",
      "  Downloading charset_normalizer-3.4.4-cp310-cp310-win_amd64.whl.metadata (38 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets->ragas==0.1.4)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting dnspython>=2.0.0 (from email-validator->arize-phoenix[embeddings,llama-index])\n",
      "  Using cached dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi->arize-phoenix[embeddings,llama-index])\n",
      "  Using cached annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->arize-phoenix[embeddings,llama-index])\n",
      "  Downloading markupsafe-3.0.3-cp310-cp310-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting ply (from jsonpath-ng->arize-phoenix-evals>=2.6.0->arize-phoenix[embeddings,llama-index])\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl.metadata (844 bytes)\n",
      "Collecting langgraph<1.1.0,>=1.0.2 (from langchain->ragas==0.1.4)\n",
      "  Using cached langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core->ragas==0.1.4)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core->ragas==0.1.4)\n",
      "  Using cached langsmith-0.4.45-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core->ragas==0.1.4)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core->ragas==0.1.4)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.2->langchain->ragas==0.1.4)\n",
      "  Using cached langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph<1.1.0,>=1.0.2->langchain->ragas==0.1.4)\n",
      "  Using cached langgraph_prebuilt-1.0.5-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.2->langchain->ragas==0.1.4)\n",
      "  Using cached langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain->ragas==0.1.4)\n",
      "  Downloading ormsgpack-1.12.0-cp310-cp310-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core->ragas==0.1.4)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core->ragas==0.1.4)\n",
      "  Downloading zstandard-0.25.0-cp310-cp310-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community->ragas==0.1.4)\n",
      "  Using cached langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community->ragas==0.1.4)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community->ragas==0.1.4)\n",
      "  Using cached pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community->ragas==0.1.4)\n",
      "  Using cached httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->ragas==0.1.4)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->ragas==0.1.4)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->ragas==0.1.4)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community->ragas==0.1.4)\n",
      "  Using cached langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community->ragas==0.1.4)\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community->ragas==0.1.4)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken->ragas==0.1.4)\n",
      "  Downloading regex-2025.11.3-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api->openinference-instrumentation>=0.1.38)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api->openinference-instrumentation>=0.1.38)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc==1.38.0 (from opentelemetry-exporter-otlp->arize-phoenix[embeddings,llama-index])\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http==1.38.0 (from opentelemetry-exporter-otlp->arize-phoenix[embeddings,llama-index])\n",
      "  Using cached opentelemetry_exporter_otlp_proto_http-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc==1.38.0->opentelemetry-exporter-otlp->arize-phoenix[embeddings,llama-index])\n",
      "  Using cached googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc==1.38.0->opentelemetry-exporter-otlp->arize-phoenix[embeddings,llama-index])\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting click>=8.0.0 (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets->ragas==0.1.4)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pynndescent>=0.5 (from umap-learn->arize-phoenix[embeddings,llama-index])\n",
      "  Using cached pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "Using cached ragas-0.1.4-py3-none-any.whl (73 kB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached pypdf-6.3.0-py3-none-any.whl (328 kB)\n",
      "Using cached arize_phoenix-12.16.0-py3-none-any.whl (2.6 MB)\n",
      "Using cached strawberry_graphql-0.270.1-py3-none-any.whl (301 kB)\n",
      "Using cached alembic-1.17.2-py3-none-any.whl (248 kB)\n",
      "Using cached graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
      "Downloading sqlalchemy-2.0.44-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 4.6 MB/s  0:00:00\n",
      "Downloading sqlean_py-3.49.1-cp310-cp310-win_amd64.whl (803 kB)\n",
      "   ---------------------------------------- 0.0/803.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 803.5/803.5 kB 6.9 MB/s  0:00:00\n",
      "Downloading wrapt-1.17.3-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Using cached openai-2.8.1-py3-none-any.whl (1.0 MB)\n",
      "Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.12.0-cp310-cp310-win_amd64.whl (204 kB)\n",
      "Downloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/2.0 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.3/2.0 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 2.7 MB/s  0:00:00\n",
      "Downloading pandas-2.3.3-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.3 MB 3.4 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.0/11.3 MB 3.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.8/11.3 MB 3.0 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.8/11.3 MB 3.0 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.8/11.3 MB 3.0 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.4/11.3 MB 1.9 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.5/11.3 MB 3.1 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.5/11.3 MB 3.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.6/11.3 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.3/11.3 MB 3.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.4/11.3 MB 3.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.4/11.3 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.5/11.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 3.8 MB/s  0:00:03\n",
      "Using cached openinference_instrumentation-0.1.42-py3-none-any.whl (30 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached arize_phoenix_client-1.24.0-py3-none-any.whl (143 kB)\n",
      "Using cached arize_phoenix_evals-2.6.0-py3-none-any.whl (143 kB)\n",
      "Using cached arize_phoenix_otel-0.14.0-py3-none-any.whl (17 kB)\n",
      "Using cached fast_hdbscan-0.2.2-py3-none-any.whl (27 kB)\n",
      "Downloading greenlet-3.2.4-cp310-cp310-win_amd64.whl (298 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading numba-0.62.1-cp310-cp310-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.3/2.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.1/2.7 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 3.5 MB/s  0:00:00\n",
      "Downloading llvmlite-0.45.1-cp310-cp310-win_amd64.whl (38.1 MB)\n",
      "   ---------------------------------------- 0.0/38.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/38.1 MB 3.4 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 1.0/38.1 MB 2.6 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 1.3/38.1 MB 2.6 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 1.6/38.1 MB 2.3 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 1.6/38.1 MB 2.3 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 2.9/38.1 MB 2.3 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 3.4/38.1 MB 2.4 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 4.2/38.1 MB 2.5 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 4.7/38.1 MB 2.6 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 5.2/38.1 MB 2.6 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 6.0/38.1 MB 2.7 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 6.8/38.1 MB 2.8 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 7.3/38.1 MB 2.8 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 8.1/38.1 MB 2.9 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 8.7/38.1 MB 2.9 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 9.4/38.1 MB 2.9 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 10.2/38.1 MB 3.0 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 10.7/38.1 MB 3.0 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 11.3/38.1 MB 2.9 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 12.1/38.1 MB 3.0 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 12.8/38.1 MB 3.0 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 13.1/38.1 MB 2.9 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 13.4/38.1 MB 2.9 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 14.2/38.1 MB 2.8 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 14.7/38.1 MB 2.8 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 14.9/38.1 MB 2.8 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 15.5/38.1 MB 2.8 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 16.0/38.1 MB 2.8 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 16.5/38.1 MB 2.8 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 17.3/38.1 MB 2.8 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 17.8/38.1 MB 2.8 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 18.6/38.1 MB 2.8 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 19.1/38.1 MB 2.8 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 20.2/38.1 MB 2.9 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 21.0/38.1 MB 2.9 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 22.0/38.1 MB 3.0 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 23.3/38.1 MB 3.1 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 24.4/38.1 MB 3.1 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 26.0/38.1 MB 3.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 27.0/38.1 MB 3.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 28.0/38.1 MB 3.3 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 29.1/38.1 MB 3.3 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 29.9/38.1 MB 3.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 30.9/38.1 MB 3.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 31.2/38.1 MB 3.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 32.0/38.1 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 32.5/38.1 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.3/38.1 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 34.1/38.1 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 34.9/38.1 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 35.4/38.1 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.2/38.1 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 36.7/38.1 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.5/38.1 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.0/38.1 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.0/38.1 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.1/38.1 MB 3.3 MB/s  0:00:11\n",
      "Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.9 MB 4.2 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.3/12.9 MB 4.2 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 3.6 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 3.1/12.9 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.2/12.9 MB 4.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 4.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.6/12.9 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.9/12.9 MB 5.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.9/12.9 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 10.0/12.9 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.9 MB 5.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.5/12.9 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.1/12.9 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.8/12.9 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 4.4 MB/s  0:00:02\n",
      "Using cached openinference_semantic_conventions-0.1.25-py3-none-any.whl (10 kB)\n",
      "Using cached opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
      "Downloading protobuf-6.33.1-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Using cached pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading scikit_learn-1.7.2-cp310-cp310-win_amd64.whl (8.9 MB)\n",
      "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/8.9 MB 8.5 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.3/8.9 MB 3.5 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.6/8.9 MB 3.1 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.1/8.9 MB 2.9 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.6/8.9 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.1/8.9 MB 2.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 3.7/8.9 MB 2.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 3.9/8.9 MB 2.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 4.5/8.9 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.0/8.9 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 5.5/8.9 MB 2.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.0/8.9 MB 2.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.0/8.9 MB 2.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.0/8.9 MB 2.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 7.6/8.9 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.4/8.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.9/8.9 MB 2.5 MB/s  0:00:03\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "   ---------------------------------------- 0.0/41.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/41.3 MB 5.0 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 2.4/41.3 MB 5.8 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.4/41.3 MB 5.6 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 4.2/41.3 MB 5.2 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 5.2/41.3 MB 5.2 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 6.0/41.3 MB 5.0 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 7.1/41.3 MB 5.0 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 8.1/41.3 MB 5.0 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 9.2/41.3 MB 5.0 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 10.7/41.3 MB 5.2 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 12.1/41.3 MB 5.4 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 12.8/41.3 MB 5.3 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 13.6/41.3 MB 5.1 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 14.4/41.3 MB 5.0 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 15.5/41.3 MB 5.0 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 17.0/41.3 MB 5.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 18.6/41.3 MB 5.3 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 19.9/41.3 MB 5.3 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 21.0/41.3 MB 5.3 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 21.8/41.3 MB 5.3 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 22.8/41.3 MB 5.3 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 23.9/41.3 MB 5.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 24.6/41.3 MB 5.2 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 25.7/41.3 MB 5.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 26.5/41.3 MB 5.1 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 27.5/41.3 MB 5.1 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 28.8/41.3 MB 5.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 29.9/41.3 MB 5.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 30.9/41.3 MB 5.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 32.2/41.3 MB 5.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 33.3/41.3 MB 5.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 34.6/41.3 MB 5.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 35.4/41.3 MB 5.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 36.2/41.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 36.7/41.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.5/41.3 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 38.0/41.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.5/41.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 39.1/41.3 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 40.1/41.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  41.2/41.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.3/41.3 MB 4.6 MB/s  0:00:08\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading aioitertools-0.13.0-py3-none-any.whl (24 kB)\n",
      "Using cached aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached authlib-1.6.5-py2.py3-none-any.whl (243 kB)\n",
      "Downloading cachetools-6.2.2-py3-none-any.whl (11 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Downloading cryptography-46.0.3-cp38-abi3-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 1.0/3.5 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.4/3.5 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.4/3.5 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.4/3.5 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 3.6 MB/s  0:00:00\n",
      "Downloading cffi-2.0.0-cp310-cp310-win_amd64.whl (182 kB)\n",
      "Using cached datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "Using cached dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Using cached huggingface_hub-1.1.5-py3-none-any.whl (516 kB)\n",
      "Using cached hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "Downloading multiprocess-0.70.18-py310-none-any.whl (134 kB)\n",
      "Downloading aiohttp-3.13.2-cp310-cp310-win_amd64.whl (455 kB)\n",
      "Downloading multidict-6.7.0-cp310-cp310-win_amd64.whl (46 kB)\n",
      "Downloading yarl-1.22.0-cp310-cp310-win_amd64.whl (86 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading frozenlist-1.8.0-cp310-cp310-win_amd64.whl (43 kB)\n",
      "Downloading propcache-0.4.1-cp310-cp310-win_amd64.whl (41 kB)\n",
      "Downloading pyarrow-22.0.0-cp310-cp310-win_amd64.whl (28.1 MB)\n",
      "   ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/28.1 MB 6.7 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 1.8/28.1 MB 5.3 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 2.9/28.1 MB 4.8 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 3.9/28.1 MB 5.1 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 5.5/28.1 MB 5.7 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.6/28.1 MB 5.5 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 8.1/28.1 MB 5.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 9.4/28.1 MB 5.9 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 11.0/28.1 MB 6.0 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 12.1/28.1 MB 5.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 13.1/28.1 MB 5.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 14.2/28.1 MB 5.7 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 15.2/28.1 MB 5.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 16.5/28.1 MB 5.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 17.6/28.1 MB 5.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 18.9/28.1 MB 5.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 19.9/28.1 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 21.5/28.1 MB 5.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 22.5/28.1 MB 5.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 23.6/28.1 MB 5.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 24.6/28.1 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 25.4/28.1 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 26.5/28.1 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 27.3/28.1 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.1/28.1 MB 5.4 MB/s  0:00:05\n",
      "Downloading pyyaml-6.0.3-cp310-cp310-win_amd64.whl (158 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp310-cp310-win_amd64.whl (107 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
      "Using cached dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
      "Using cached fastapi-0.121.3-py3-none-any.whl (109 kB)\n",
      "Using cached starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "Using cached annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached grpc_interceptor-0.15.4-py3-none-any.whl (20 kB)\n",
      "Downloading grpcio-1.76.0-cp310-cp310-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.8/4.7 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.4/4.7 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.4/4.7 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.5/4.7 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 5.5 MB/s  0:00:00\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading markupsafe-3.0.3-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached jsonpath_ng-1.7.0-py3-none-any.whl (30 kB)\n",
      "Using cached langchain-1.0.8-py3-none-any.whl (93 kB)\n",
      "Downloading langchain_core-1.1.0-py3-none-any.whl (473 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langgraph-1.0.3-py3-none-any.whl (156 kB)\n",
      "Using cached langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
      "Using cached langgraph_prebuilt-1.0.5-py3-none-any.whl (35 kB)\n",
      "Using cached langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Using cached langsmith-0.4.45-py3-none-any.whl (411 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading orjson-3.11.4-cp310-cp310-win_amd64.whl (131 kB)\n",
      "Downloading ormsgpack-1.12.0-cp310-cp310-win_amd64.whl (112 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading xxhash-3.6.0-cp310-cp310-win_amd64.whl (31 kB)\n",
      "Downloading zstandard-0.25.0-cp310-cp310-win_amd64.whl (506 kB)\n",
      "Using cached langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Using cached langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached langchain_openai-1.0.3-py3-none-any.whl (82 kB)\n",
      "Downloading tiktoken-0.12.0-cp310-cp310-win_amd64.whl (879 kB)\n",
      "   ---------------------------------------- 0.0/879.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 879.4/879.4 kB 6.6 MB/s  0:00:00\n",
      "Downloading regex-2025.11.3-cp310-cp310-win_amd64.whl (277 kB)\n",
      "Using cached mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Using cached opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Using cached opentelemetry_exporter_otlp-1.38.0-py3-none-any.whl (7.0 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_http-1.38.0-py3-none-any.whl (19 kB)\n",
      "Using cached googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "Using cached opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
      "Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "Downloading prometheus_client-0.23.1-py3-none-any.whl (61 kB)\n",
      "Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Using cached pystache-0.6.8-py3-none-any.whl (82 kB)\n",
      "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading tomli-2.3.0-py3-none-any.whl (14 kB)\n",
      "Using cached typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Using cached umap_learn-0.5.9.post2-py3-none-any.whl (90 kB)\n",
      "Using cached pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "Using cached uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Installing collected packages: pytz, ply, appdirs, zstandard, zipp, xxhash, wrapt, urllib3, tzdata, typing-inspection, tqdm, tomli, threadpoolctl, tenacity, sqlean-py, sniffio, shellingham, regex, pyyaml, python-multipart, python-dotenv, pystache, pysbd, pypdf, pydantic-core, pycparser, pyarrow, protobuf, propcache, prometheus-client, ormsgpack, orjson, openinference-semantic-conventions, numpy, mypy-extensions, multidict, marshmallow, MarkupSafe, llvmlite, jsonpointer, jsonpath-ng, joblib, jmespath, jiter, idna, httpx-sse, hf-xet, h11, grpcio, greenlet, graphql-core, fsspec, frozenlist, filelock, dnspython, distro, dill, click, charset_normalizer, certifi, cachetools, attrs, async-timeout, annotated-types, annotated-doc, aiosqlite, aioitertools, aiohappyeyeballs, yarl, uvicorn, typing-inspect, typer-slim, strawberry-graphql, sqlalchemy, scipy, requests, pydantic, pandas, opentelemetry-proto, numba, multiprocess, Mako, jsonpatch, jinja2, importlib-metadata, httpcore, grpc-interceptor, googleapis-common-protos, email-validator, cffi, anyio, aiosignal, tiktoken, starlette, scikit-learn, requests-toolbelt, pydantic-settings, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, httpx, dataclasses-json, cryptography, alembic, aiohttp, pynndescent, opentelemetry-semantic-conventions, openai, langsmith, langgraph-sdk, huggingface-hub, fastapi, fast-hdbscan, authlib, umap-learn, opentelemetry-sdk, langchain-core, datasets, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, openinference-instrumentation, langgraph-checkpoint, langchain-text-splitters, langchain-openai, opentelemetry-exporter-otlp, langgraph-prebuilt, langchain-classic, arize-phoenix-evals, langgraph, langchain-community, arize-phoenix-otel, arize-phoenix-client, langchain, arize-phoenix, ragas\n",
      "\n",
      "   ----------------------------------------   0/134 [pytz]\n",
      "   ----------------------------------------   0/134 [pytz]\n",
      "    ---------------------------------------   2/134 [appdirs]\n",
      "   - --------------------------------------   6/134 [wrapt]\n",
      "   -- -------------------------------------   7/134 [urllib3]\n",
      "   -- -------------------------------------   7/134 [urllib3]\n",
      "   -- -------------------------------------   8/134 [tzdata]\n",
      "   -- -------------------------------------   8/134 [tzdata]\n",
      "   -- -------------------------------------   8/134 [tzdata]\n",
      "   -- -------------------------------------  10/134 [tqdm]\n",
      "   --- ------------------------------------  11/134 [tomli]\n",
      "   --- ------------------------------------  13/134 [tenacity]\n",
      "   ----- ----------------------------------  17/134 [regex]\n",
      "   ----- ----------------------------------  18/134 [pyyaml]\n",
      "   ----- ----------------------------------  19/134 [python-multipart]\n",
      "   ------ ---------------------------------  21/134 [pystache]\n",
      "   ------ ---------------------------------  21/134 [pystache]\n",
      "   ------ ---------------------------------  21/134 [pystache]\n",
      "   ------ ---------------------------------  22/134 [pysbd]\n",
      "   ------ ---------------------------------  22/134 [pysbd]\n",
      "   ------ ---------------------------------  23/134 [pypdf]\n",
      "   ------ ---------------------------------  23/134 [pypdf]\n",
      "   ------ ---------------------------------  23/134 [pypdf]\n",
      "   ------ ---------------------------------  23/134 [pypdf]\n",
      "   ------- --------------------------------  24/134 [pydantic-core]\n",
      "   ------- --------------------------------  25/134 [pycparser]\n",
      "   ------- --------------------------------  26/134 [pyarrow]\n",
      "   ------- --------------------------------  26/134 [pyarrow]\n",
      "   ------- --------------------------------  26/134 [pyarrow]\n",
      "   ------- --------------------------------  26/134 [pyarrow]\n",
      "   ------- --------------------------------  26/134 [pyarrow]\n",
      "   ------- --------------------------------  26/134 [pyarrow]\n",
      "   ------- --------------------------------  26/134 [pyarrow]\n",
      "   ------- --------------------------------  26/134 [pyarrow]\n",
      "   ------- --------------------------------  26/134 [pyarrow]\n",
      "   ------- --------------------------------  26/134 [pyarrow]\n",
      "   ------- --------------------------------  26/134 [pyarrow]\n",
      "   ------- --------------------------------  26/134 [pyarrow]\n",
      "   ------- --------------------------------  26/134 [pyarrow]\n",
      "   -------- -------------------------------  27/134 [protobuf]\n",
      "   -------- -------------------------------  27/134 [protobuf]\n",
      "   -------- -------------------------------  28/134 [propcache]\n",
      "   -------- -------------------------------  29/134 [prometheus-client]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   --------- ------------------------------  33/134 [numpy]\n",
      "   ---------- -----------------------------  35/134 [multidict]\n",
      "   ----------- ----------------------------  37/134 [MarkupSafe]\n",
      "   ----------- ----------------------------  38/134 [llvmlite]\n",
      "   ----------- ----------------------------  38/134 [llvmlite]\n",
      "   ----------- ----------------------------  38/134 [llvmlite]\n",
      "   ----------- ----------------------------  38/134 [llvmlite]\n",
      "   ----------- ----------------------------  39/134 [jsonpointer]\n",
      "   ------------ ---------------------------  41/134 [joblib]\n",
      "   ------------ ---------------------------  41/134 [joblib]\n",
      "   ------------ ---------------------------  41/134 [joblib]\n",
      "   ------------ ---------------------------  41/134 [joblib]\n",
      "   ------------ ---------------------------  41/134 [joblib]\n",
      "   ------------- --------------------------  44/134 [idna]\n",
      "   ------------- --------------------------  45/134 [httpx-sse]\n",
      "   -------------- -------------------------  47/134 [h11]\n",
      "   -------------- -------------------------  48/134 [grpcio]\n",
      "   -------------- -------------------------  48/134 [grpcio]\n",
      "   -------------- -------------------------  48/134 [grpcio]\n",
      "   -------------- -------------------------  49/134 [greenlet]\n",
      "   -------------- -------------------------  50/134 [graphql-core]\n",
      "   -------------- -------------------------  50/134 [graphql-core]\n",
      "   -------------- -------------------------  50/134 [graphql-core]\n",
      "   -------------- -------------------------  50/134 [graphql-core]\n",
      "   -------------- -------------------------  50/134 [graphql-core]\n",
      "   -------------- -------------------------  50/134 [graphql-core]\n",
      "   -------------- -------------------------  50/134 [graphql-core]\n",
      "   --------------- ------------------------  51/134 [fsspec]\n",
      "   --------------- ------------------------  51/134 [fsspec]\n",
      "   --------------- ------------------------  51/134 [fsspec]\n",
      "   --------------- ------------------------  53/134 [filelock]\n",
      "   ---------------- -----------------------  54/134 [dnspython]\n",
      "   ---------------- -----------------------  54/134 [dnspython]\n",
      "   ---------------- -----------------------  54/134 [dnspython]\n",
      "   ---------------- -----------------------  54/134 [dnspython]\n",
      "   ---------------- -----------------------  54/134 [dnspython]\n",
      "   ---------------- -----------------------  54/134 [dnspython]\n",
      "   ---------------- -----------------------  54/134 [dnspython]\n",
      "   ---------------- -----------------------  56/134 [dill]\n",
      "   ---------------- -----------------------  56/134 [dill]\n",
      "   ----------------- ----------------------  57/134 [click]\n",
      "   ----------------- ----------------------  58/134 [charset_normalizer]\n",
      "   ----------------- ----------------------  59/134 [certifi]\n",
      "   ------------------ ---------------------  61/134 [attrs]\n",
      "   ------------------- --------------------  65/134 [aiosqlite]\n",
      "   ------------------- --------------------  66/134 [aioitertools]\n",
      "   -------------------- -------------------  68/134 [yarl]\n",
      "   -------------------- -------------------  69/134 [uvicorn]\n",
      "   --------------------- ------------------  71/134 [typer-slim]\n",
      "   --------------------- ------------------  72/134 [strawberry-graphql]\n",
      "   --------------------- ------------------  72/134 [strawberry-graphql]\n",
      "   --------------------- ------------------  72/134 [strawberry-graphql]\n",
      "   --------------------- ------------------  72/134 [strawberry-graphql]\n",
      "   --------------------- ------------------  72/134 [strawberry-graphql]\n",
      "   --------------------- ------------------  72/134 [strawberry-graphql]\n",
      "   --------------------- ------------------  72/134 [strawberry-graphql]\n",
      "   --------------------- ------------------  72/134 [strawberry-graphql]\n",
      "   --------------------- ------------------  72/134 [strawberry-graphql]\n",
      "   --------------------- ------------------  72/134 [strawberry-graphql]\n",
      "   --------------------- ------------------  72/134 [strawberry-graphql]\n",
      "   --------------------- ------------------  73/134 [sqlalchemy]\n",
      "   --------------------- ------------------  73/134 [sqlalchemy]\n",
      "   --------------------- ------------------  73/134 [sqlalchemy]\n",
      "   --------------------- ------------------  73/134 [sqlalchemy]\n",
      "   --------------------- ------------------  73/134 [sqlalchemy]\n",
      "   --------------------- ------------------  73/134 [sqlalchemy]\n",
      "   --------------------- ------------------  73/134 [sqlalchemy]\n",
      "   --------------------- ------------------  73/134 [sqlalchemy]\n",
      "   --------------------- ------------------  73/134 [sqlalchemy]\n",
      "   --------------------- ------------------  73/134 [sqlalchemy]\n",
      "   --------------------- ------------------  73/134 [sqlalchemy]\n",
      "   --------------------- ------------------  73/134 [sqlalchemy]\n",
      "   --------------------- ------------------  73/134 [sqlalchemy]\n",
      "   --------------------- ------------------  73/134 [sqlalchemy]\n",
      "   --------------------- ------------------  73/134 [sqlalchemy]\n",
      "   --------------------- ------------------  73/134 [sqlalchemy]\n",
      "   --------------------- ------------------  73/134 [sqlalchemy]\n",
      "   --------------------- ------------------  73/134 [sqlalchemy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  74/134 [scipy]\n",
      "   ---------------------- -----------------  75/134 [requests]\n",
      "   ---------------------- -----------------  76/134 [pydantic]\n",
      "   ---------------------- -----------------  76/134 [pydantic]\n",
      "   ---------------------- -----------------  76/134 [pydantic]\n",
      "   ---------------------- -----------------  76/134 [pydantic]\n",
      "   ---------------------- -----------------  76/134 [pydantic]\n",
      "   ---------------------- -----------------  76/134 [pydantic]\n",
      "   ---------------------- -----------------  76/134 [pydantic]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ---------------------- -----------------  77/134 [pandas]\n",
      "   ----------------------- ----------------  78/134 [opentelemetry-proto]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  79/134 [numba]\n",
      "   ----------------------- ----------------  80/134 [multiprocess]\n",
      "   ----------------------- ----------------  80/134 [multiprocess]\n",
      "   ------------------------ ---------------  81/134 [Mako]\n",
      "   ------------------------ ---------------  81/134 [Mako]\n",
      "   ------------------------ ---------------  83/134 [jinja2]\n",
      "   ------------------------ ---------------  83/134 [jinja2]\n",
      "   ------------------------- --------------  84/134 [importlib-metadata]\n",
      "   ------------------------- --------------  85/134 [httpcore]\n",
      "   ------------------------- --------------  86/134 [grpc-interceptor]\n",
      "   ------------------------- --------------  87/134 [googleapis-common-protos]\n",
      "   ------------------------- --------------  87/134 [googleapis-common-protos]\n",
      "   ------------------------- --------------  87/134 [googleapis-common-protos]\n",
      "   -------------------------- -------------  88/134 [email-validator]\n",
      "   -------------------------- -------------  89/134 [cffi]\n",
      "   -------------------------- -------------  90/134 [anyio]\n",
      "   -------------------------- -------------  90/134 [anyio]\n",
      "   --------------------------- ------------  92/134 [tiktoken]\n",
      "   --------------------------- ------------  93/134 [starlette]\n",
      "   --------------------------- ------------  93/134 [starlette]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  94/134 [scikit-learn]\n",
      "   ---------------------------- -----------  95/134 [requests-toolbelt]\n",
      "   ---------------------------- -----------  96/134 [pydantic-settings]\n",
      "   ---------------------------- -----------  96/134 [pydantic-settings]\n",
      "   ----------------------------- ----------  98/134 [opentelemetry-api]\n",
      "   ----------------------------- ----------  98/134 [opentelemetry-api]\n",
      "   ----------------------------- ----------  99/134 [httpx]\n",
      "   ----------------------------- ----------  99/134 [httpx]\n",
      "   ------------------------------ --------- 101/134 [cryptography]\n",
      "   ------------------------------ --------- 101/134 [cryptography]\n",
      "   ------------------------------ --------- 101/134 [cryptography]\n",
      "   ------------------------------ --------- 101/134 [cryptography]\n",
      "   ------------------------------ --------- 102/134 [alembic]\n",
      "   ------------------------------ --------- 102/134 [alembic]\n",
      "   ------------------------------ --------- 102/134 [alembic]\n",
      "   ------------------------------ --------- 102/134 [alembic]\n",
      "   ------------------------------ --------- 103/134 [aiohttp]\n",
      "   ------------------------------ --------- 103/134 [aiohttp]\n",
      "   ------------------------------ --------- 103/134 [aiohttp]\n",
      "   ------------------------------ --------- 103/134 [aiohttp]\n",
      "   ------------------------ ------ 105/134 [opentelemetry-semantic-conventions]\n",
      "   ------------------------ ------ 105/134 [opentelemetry-semantic-conventions]\n",
      "   ------------------------ ------ 105/134 [opentelemetry-semantic-conventions]\n",
      "   ------------------------ ------ 105/134 [opentelemetry-semantic-conventions]\n",
      "   ------------------------ ------ 105/134 [opentelemetry-semantic-conventions]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 106/134 [openai]\n",
      "   ------------------------------- -------- 107/134 [langsmith]\n",
      "   ------------------------------- -------- 107/134 [langsmith]\n",
      "   ------------------------------- -------- 107/134 [langsmith]\n",
      "   ------------------------------- -------- 107/134 [langsmith]\n",
      "   -------------------------------- ------- 108/134 [langgraph-sdk]\n",
      "   -------------------------------- ------- 109/134 [huggingface-hub]\n",
      "   -------------------------------- ------- 109/134 [huggingface-hub]\n",
      "   -------------------------------- ------- 109/134 [huggingface-hub]\n",
      "   -------------------------------- ------- 109/134 [huggingface-hub]\n",
      "   -------------------------------- ------- 109/134 [huggingface-hub]\n",
      "   -------------------------------- ------- 109/134 [huggingface-hub]\n",
      "   -------------------------------- ------- 109/134 [huggingface-hub]\n",
      "   -------------------------------- ------- 110/134 [fastapi]\n",
      "   -------------------------------- ------- 110/134 [fastapi]\n",
      "   -------------------------------- ------- 110/134 [fastapi]\n",
      "   --------------------------------- ------ 111/134 [fast-hdbscan]\n",
      "   --------------------------------- ------ 112/134 [authlib]\n",
      "   --------------------------------- ------ 112/134 [authlib]\n",
      "   --------------------------------- ------ 112/134 [authlib]\n",
      "   --------------------------------- ------ 112/134 [authlib]\n",
      "   --------------------------------- ------ 112/134 [authlib]\n",
      "   --------------------------------- ------ 112/134 [authlib]\n",
      "   --------------------------------- ------ 112/134 [authlib]\n",
      "   --------------------------------- ------ 112/134 [authlib]\n",
      "   --------------------------------- ------ 112/134 [authlib]\n",
      "   --------------------------------- ------ 113/134 [umap-learn]\n",
      "   ---------------------------------- ----- 114/134 [opentelemetry-sdk]\n",
      "   ---------------------------------- ----- 114/134 [opentelemetry-sdk]\n",
      "   ---------------------------------- ----- 115/134 [langchain-core]\n",
      "   ---------------------------------- ----- 115/134 [langchain-core]\n",
      "   ---------------------------------- ----- 115/134 [langchain-core]\n",
      "   ---------------------------------- ----- 115/134 [langchain-core]\n",
      "   ---------------------------------- ----- 115/134 [langchain-core]\n",
      "   ---------------------------------- ----- 115/134 [langchain-core]\n",
      "   ---------------------------------- ----- 115/134 [langchain-core]\n",
      "   ---------------------------------- ----- 115/134 [langchain-core]\n",
      "   ---------------------------------- ----- 115/134 [langchain-core]\n",
      "   ---------------------------------- ----- 116/134 [datasets]\n",
      "   ---------------------------------- ----- 116/134 [datasets]\n",
      "   ---------------------------------- ----- 116/134 [datasets]\n",
      "   ---------------------------------- ----- 116/134 [datasets]\n",
      "   ---------------------------------- ----- 116/134 [datasets]\n",
      "   ---------------------------------- ----- 116/134 [datasets]\n",
      "   ---------------------------------- ----- 116/134 [datasets]\n",
      "   ----------------------- --- 118/134 [opentelemetry-exporter-otlp-proto-grpc]\n",
      "   ----------------------------------- ---- 120/134 [langgraph-checkpoint]\n",
      "   ------------------------------------ --- 121/134 [langchain-text-splitters]\n",
      "   ------------------------------------ --- 122/134 [langchain-openai]\n",
      "   ------------------------------------- -- 124/134 [langgraph-prebuilt]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 125/134 [langchain-classic]\n",
      "   ------------------------------------- -- 126/134 [arize-phoenix-evals]\n",
      "   ------------------------------------- -- 126/134 [arize-phoenix-evals]\n",
      "   ------------------------------------- -- 126/134 [arize-phoenix-evals]\n",
      "   ------------------------------------- -- 126/134 [arize-phoenix-evals]\n",
      "   ------------------------------------- -- 127/134 [langgraph]\n",
      "   ------------------------------------- -- 127/134 [langgraph]\n",
      "   ------------------------------------- -- 127/134 [langgraph]\n",
      "   ------------------------------------- -- 127/134 [langgraph]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 128/134 [langchain-community]\n",
      "   -------------------------------------- - 130/134 [arize-phoenix-client]\n",
      "   -------------------------------------- - 130/134 [arize-phoenix-client]\n",
      "   -------------------------------------- - 130/134 [arize-phoenix-client]\n",
      "   ---------------------------------------  131/134 [langchain]\n",
      "   ---------------------------------------  132/134 [arize-phoenix]\n",
      "   ---------------------------------------  132/134 [arize-phoenix]\n",
      "   ---------------------------------------  132/134 [arize-phoenix]\n",
      "   ---------------------------------------  132/134 [arize-phoenix]\n",
      "   ---------------------------------------  132/134 [arize-phoenix]\n",
      "   ---------------------------------------  132/134 [arize-phoenix]\n",
      "   ---------------------------------------  132/134 [arize-phoenix]\n",
      "   ---------------------------------------  132/134 [arize-phoenix]\n",
      "   ---------------------------------------  132/134 [arize-phoenix]\n",
      "   ---------------------------------------  132/134 [arize-phoenix]\n",
      "   ---------------------------------------  132/134 [arize-phoenix]\n",
      "   ---------------------------------------  132/134 [arize-phoenix]\n",
      "   ---------------------------------------  132/134 [arize-phoenix]\n",
      "   ---------------------------------------  132/134 [arize-phoenix]\n",
      "   ---------------------------------------  132/134 [arize-phoenix]\n",
      "   ---------------------------------------  132/134 [arize-phoenix]\n",
      "   ---------------------------------------  132/134 [arize-phoenix]\n",
      "   ---------------------------------------  132/134 [arize-phoenix]\n",
      "   ---------------------------------------  132/134 [arize-phoenix]\n",
      "   ---------------------------------------  132/134 [arize-phoenix]\n",
      "   ---------------------------------------  132/134 [arize-phoenix]\n",
      "   ---------------------------------------  133/134 [ragas]\n",
      "   ---------------------------------------  133/134 [ragas]\n",
      "   ---------------------------------------- 134/134 [ragas]\n",
      "\n",
      "Successfully installed Mako-1.3.10 MarkupSafe-3.0.3 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aioitertools-0.13.0 aiosignal-1.4.0 aiosqlite-0.21.0 alembic-1.17.2 annotated-doc-0.0.4 annotated-types-0.7.0 anyio-4.11.0 appdirs-1.4.4 arize-phoenix-12.16.0 arize-phoenix-client-1.24.0 arize-phoenix-evals-2.6.0 arize-phoenix-otel-0.14.0 async-timeout-4.0.3 attrs-25.4.0 authlib-1.6.5 cachetools-6.2.2 certifi-2025.11.12 cffi-2.0.0 charset_normalizer-3.4.4 click-8.3.1 cryptography-46.0.3 dataclasses-json-0.6.7 datasets-4.4.1 dill-0.4.0 distro-1.9.0 dnspython-2.8.0 email-validator-2.3.0 fast-hdbscan-0.2.2 fastapi-0.121.3 filelock-3.20.0 frozenlist-1.8.0 fsspec-2025.10.0 googleapis-common-protos-1.72.0 graphql-core-3.2.7 greenlet-3.2.4 grpc-interceptor-0.15.4 grpcio-1.76.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.27.2 httpx-sse-0.4.3 huggingface-hub-1.1.5 idna-3.11 importlib-metadata-8.7.0 jinja2-3.1.6 jiter-0.12.0 jmespath-1.0.1 joblib-1.5.2 jsonpatch-1.33 jsonpath-ng-1.7.0 jsonpointer-3.0.0 langchain-1.0.8 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-core-1.1.0 langchain-openai-1.0.3 langchain-text-splitters-1.0.0 langgraph-1.0.3 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.5 langgraph-sdk-0.2.9 langsmith-0.4.45 llvmlite-0.45.1 marshmallow-3.26.1 multidict-6.7.0 multiprocess-0.70.18 mypy-extensions-1.1.0 numba-0.62.1 numpy-2.2.6 openai-2.8.1 openinference-instrumentation-0.1.42 openinference-semantic-conventions-0.1.25 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-exporter-otlp-proto-http-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 orjson-3.11.4 ormsgpack-1.12.0 pandas-2.3.3 ply-3.11 prometheus-client-0.23.1 propcache-0.4.1 protobuf-6.33.1 pyarrow-22.0.0 pycparser-2.23 pydantic-2.12.4 pydantic-core-2.41.5 pydantic-settings-2.12.0 pynndescent-0.5.13 pypdf-6.3.0 pysbd-0.3.4 pystache-0.6.8 python-dotenv-1.2.1 python-multipart-0.0.20 pytz-2025.2 pyyaml-6.0.3 ragas-0.1.4 regex-2025.11.3 requests-2.32.5 requests-toolbelt-1.0.0 scikit-learn-1.7.2 scipy-1.15.3 shellingham-1.5.4 sniffio-1.3.1 sqlalchemy-2.0.44 sqlean-py-3.49.1 starlette-0.50.0 strawberry-graphql-0.270.1 tenacity-9.1.2 threadpoolctl-3.6.0 tiktoken-0.12.0 tomli-2.3.0 tqdm-4.67.1 typer-slim-0.20.0 typing-inspect-0.9.0 typing-inspection-0.4.2 tzdata-2025.2 umap-learn-0.5.9.post2 urllib3-2.5.0 uvicorn-0.38.0 wrapt-1.17.3 xxhash-3.6.0 yarl-1.22.0 zipp-3.23.0 zstandard-0.25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: arize-phoenix 12.16.0 does not provide the extra 'llama-index'\n"
     ]
    }
   ],
   "source": [
    "%pip install -U \"ragas==0.1.4\" pypdf \"arize-phoenix[llama-index,embeddings]\" \"openai>=1.0.0\" pandas \"httpx<0.28\" \"openinference-instrumentation>=0.1.38\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62030782-aa1d-4671-a028-484a6249109a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index>=0.11.0\n",
      "  Downloading llama_index-0.14.8-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting llama-index-llms-huggingface\n",
      "  Downloading llama_index_llms_huggingface-0.6.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-cli<0.6,>=0.5.0 (from llama-index>=0.11.0)\n",
      "  Downloading llama_index_cli-0.5.3-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting llama-index-core<0.15.0,>=0.14.8 (from llama-index>=0.11.0)\n",
      "  Downloading llama_index_core-0.14.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.6,>=0.5.0 (from llama-index>=0.11.0)\n",
      "  Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl.metadata (400 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index>=0.11.0)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-index-llms-openai<0.7,>=0.6.0 (from llama-index>=0.11.0)\n",
      "  Downloading llama_index_llms_openai-0.6.9-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting llama-index-readers-file<0.6,>=0.5.0 (from llama-index>=0.11.0)\n",
      "  Downloading llama_index_readers_file-0.5.5-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index>=0.11.0)\n",
      "  Downloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index>=0.11.0)\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (3.13.2)\n",
      "Requirement already satisfied: aiosqlite in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (0.21.0)\n",
      "Collecting banks<3,>=2.2.0 (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0)\n",
      "  Downloading banks-2.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (0.6.7)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0)\n",
      "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (2025.10.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (0.27.2)\n",
      "Collecting llama-index-workflows!=2.9.0,<3,>=2 (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0)\n",
      "  Downloading llama_index_workflows-2.11.3-py3-none-any.whl.metadata (770 bytes)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (3.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (2.0.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (11.1.0)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (4.5.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (2.12.4)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (2.0.44)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (0.12.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (4.15.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (1.17.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (1.22.0)\n",
      "Collecting griffe (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0)\n",
      "  Downloading griffe-1.15.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (3.1.6)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index>=0.11.0) (2.8.1)\n",
      "Collecting beautifulsoup4<5,>=4.12.3 (from llama-index-readers-file<0.6,>=0.5.0->llama-index>=0.11.0)\n",
      "  Downloading beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting defusedxml>=0.7.1 (from llama-index-readers-file<0.6,>=0.5.0->llama-index>=0.11.0)\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting pandas<2.3.0 (from llama-index-readers-file<0.6,>=0.5.0->llama-index>=0.11.0)\n",
      "  Downloading pandas-2.2.3-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pypdf<7,>=6.1.3 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index>=0.11.0) (6.3.0)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.6,>=0.5.0->llama-index>=0.11.0)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index>=0.11.0)\n",
      "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0)\n",
      "  Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index>=0.11.0) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index>=0.11.0) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index>=0.11.0) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index>=0.11.0) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index>=0.11.0) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index>=0.11.0) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from httpx->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from httpx->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index>=0.11.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index>=0.11.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index>=0.11.0) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (0.4.6)\n",
      "Requirement already satisfied: torch<3,>=2.1.2 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-llms-huggingface) (2.5.1)\n",
      "Collecting transformers<5,>=4.37.0 (from transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface)\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (3.20.0)\n",
      "Collecting sympy==1.13.1 (from torch<3,>=2.1.2->llama-index-llms-huggingface)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from sympy==1.13.1->torch<3,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers<5,>=4.37.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from transformers<5,>=4.37.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from transformers<5,>=4.37.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (2025.11.3)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5,>=4.37.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5,>=4.37.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting accelerate>=0.26.0 (from transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface)\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (7.1.3)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting llama-cloud==0.1.35 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud-0.1.35-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.81-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.81 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.81-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: click<9,>=8.1.7 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-cloud-services>=0.6.81->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0) (8.3.1)\n",
      "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.80-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.80 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.80-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.79-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.79 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.79-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.78-py3-none-any.whl.metadata (6.6 kB)\n",
      "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-cloud-services>=0.6.78 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.78-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.77-py3-none-any.whl.metadata (6.6 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting llama-cloud-services>=0.6.77 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.77-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.76-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.76 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.76-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.75-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.75 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.75-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.74-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.74 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.74-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.73-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.73 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.73-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.72-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.72 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.72-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.71-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.71 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.71-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.70-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.70 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.70-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.69-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.69 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.69-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.68-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.68 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.68-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.67-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.67 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.67-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.66-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.66 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.66-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.65-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.64 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.65-py3-none-any.whl.metadata (3.3 kB)\n",
      "  Downloading llama_cloud_services-0.6.64-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.64-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading llama_parse-0.6.63-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.63 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.63-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.62-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.62 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.62-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.60-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.60 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.60-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.59-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.59 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.59-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.58-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.58 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.57-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.56 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.56-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading llama_parse-0.6.55-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.55 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_parse-0.6.54-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0)\n",
      "  Downloading llama_cloud_services-0.6.54-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv<2,>=1.0.1 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index>=0.11.0) (1.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from nltk>3.8.1->llama-index>=0.11.0) (1.5.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index>=0.11.0) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from dataclasses-json->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (3.26.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.8->llama-index>=0.11.0) (3.0.2)\n",
      "Downloading llama_index-0.14.8-py3-none-any.whl (7.4 kB)\n",
      "Downloading llama_index_cli-0.5.3-py3-none-any.whl (28 kB)\n",
      "Downloading llama_index_core-0.14.8-py3-none-any.whl (11.9 MB)\n",
      "   ---------------------------------------- 0.0/11.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.9 MB 1.6 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.0/11.9 MB 1.6 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.3/11.9 MB 1.7 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 1.8/11.9 MB 1.8 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.4/11.9 MB 1.8 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.9/11.9 MB 1.9 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 3.4/11.9 MB 2.1 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 3.9/11.9 MB 2.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.5/11.9 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.0/11.9 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 5.5/11.9 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.0/11.9 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.8/11.9 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 7.6/11.9 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.9/11.9 MB 2.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.4/11.9 MB 2.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.9/11.9 MB 2.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.7/11.9 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.2/11.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.0/11.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.8/11.9 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.9/11.9 MB 2.6 MB/s  0:00:04\n",
      "Downloading banks-2.2.0-py3-none-any.whl (29 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl (7.0 kB)\n",
      "Downloading llama_index_llms_openai-0.6.9-py3-none-any.whl (26 kB)\n",
      "Downloading llama_index_readers_file-0.5.5-py3-none-any.whl (51 kB)\n",
      "Downloading beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n",
      "Downloading llama_index_workflows-2.11.3-py3-none-any.whl (90 kB)\n",
      "Downloading pandas-2.2.3-cp310-cp310-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.6 MB 4.2 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.3/11.6 MB 3.5 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.4/11.6 MB 4.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/11.6 MB 4.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.2/11.6 MB 4.3 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.0/11.6 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.5/11.6 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.3/11.6 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.1/11.6 MB 3.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.9/11.6 MB 3.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.7/11.6 MB 3.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.7/11.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.5/11.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.0/11.6 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.3/11.6 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 3.6 MB/s  0:00:03\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading llama_index_llms_huggingface-0.6.1-py3-none-any.whl (7.8 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.8/6.2 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.6/6.2 MB 4.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.4/6.2 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.9/6.2 MB 3.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.7/6.2 MB 3.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.2/6.2 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.7/6.2 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.0/6.2 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.8/6.2 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 3.1 MB/s  0:00:02\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.0 MB 3.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.6/12.0 MB 3.8 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.4/12.0 MB 3.9 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.1/12.0 MB 4.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.5/12.0 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.5/12.0 MB 4.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.0/12.0 MB 4.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.1/12.0 MB 4.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.1/12.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.4/12.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.5/12.0 MB 4.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.5/12.0 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 4.7 MB/s  0:00:02\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 524.3/566.1 kB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 566.1/566.1 kB 2.8 MB/s  0:00:00\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.7 MB 3.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 4.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.4/2.7 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 4.0 MB/s  0:00:00\n",
      "Downloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl (17 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading llama_cloud-0.1.35-py3-none-any.whl (303 kB)\n",
      "Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl (15 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl (3.2 kB)\n",
      "Downloading llama_parse-0.6.54-py3-none-any.whl (4.9 kB)\n",
      "Downloading llama_cloud_services-0.6.54-py3-none-any.whl (63 kB)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.8/1.5 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 2.3 MB/s  0:00:00\n",
      "Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Downloading griffe-1.15.0-py3-none-any.whl (150 kB)\n",
      "Installing collected packages: striprtf, filetype, dirtyjson, sympy, soupsieve, safetensors, griffe, deprecated, defusedxml, pandas, nltk, huggingface-hub, beautifulsoup4, tokenizers, llama-index-instrumentation, banks, accelerate, transformers, llama-index-workflows, llama-cloud, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-llms-huggingface, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-cli, llama-index-readers-llama-parse, llama-index\n",
      "\n",
      "   - --------------------------------------  1/31 [filetype]\n",
      "  Attempting uninstall: sympy\n",
      "   - --------------------------------------  1/31 [filetype]\n",
      "    Found existing installation: sympy 1.14.0\n",
      "   - --------------------------------------  1/31 [filetype]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "    Uninstalling sympy-1.14.0:\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "      Successfully uninstalled sympy-1.14.0\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   --- ------------------------------------  3/31 [sympy]\n",
      "   ----- ----------------------------------  4/31 [soupsieve]\n",
      "   ------- --------------------------------  6/31 [griffe]\n",
      "   ------- --------------------------------  6/31 [griffe]\n",
      "   ------- --------------------------------  6/31 [griffe]\n",
      "   ------- --------------------------------  6/31 [griffe]\n",
      "   ---------- -----------------------------  8/31 [defusedxml]\n",
      "  Attempting uninstall: pandas\n",
      "   ---------- -----------------------------  8/31 [defusedxml]\n",
      "    Found existing installation: pandas 2.3.3\n",
      "   ---------- -----------------------------  8/31 [defusedxml]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "    Uninstalling pandas-2.3.3:\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "      Successfully uninstalled pandas-2.3.3\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ----------- ----------------------------  9/31 [pandas]\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "  Attempting uninstall: huggingface-hub\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "    Found existing installation: huggingface_hub 1.1.5\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "    Uninstalling huggingface_hub-1.1.5:\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "      Successfully uninstalled huggingface_hub-1.1.5\n",
      "   ------------ --------------------------- 10/31 [nltk]\n",
      "   -------------- ------------------------- 11/31 [huggingface-hub]\n",
      "   -------------- ------------------------- 11/31 [huggingface-hub]\n",
      "   -------------- ------------------------- 11/31 [huggingface-hub]\n",
      "   -------------- ------------------------- 11/31 [huggingface-hub]\n",
      "   -------------- ------------------------- 11/31 [huggingface-hub]\n",
      "   -------------- ------------------------- 11/31 [huggingface-hub]\n",
      "   -------------- ------------------------- 11/31 [huggingface-hub]\n",
      "   -------------- ------------------------- 11/31 [huggingface-hub]\n",
      "   --------------- ------------------------ 12/31 [beautifulsoup4]\n",
      "   ---------------- ----------------------- 13/31 [tokenizers]\n",
      "   ------------------ --------------------- 14/31 [llama-index-instrumentation]\n",
      "   ------------------- -------------------- 15/31 [banks]\n",
      "   -------------------- ------------------- 16/31 [accelerate]\n",
      "   -------------------- ------------------- 16/31 [accelerate]\n",
      "   -------------------- ------------------- 16/31 [accelerate]\n",
      "   -------------------- ------------------- 16/31 [accelerate]\n",
      "   -------------------- ------------------- 16/31 [accelerate]\n",
      "   -------------------- ------------------- 16/31 [accelerate]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   --------------------- ------------------ 17/31 [transformers]\n",
      "   ----------------------- ---------------- 18/31 [llama-index-workflows]\n",
      "   ----------------------- ---------------- 18/31 [llama-index-workflows]\n",
      "   ------------------------ --------------- 19/31 [llama-cloud]\n",
      "   ------------------------ --------------- 19/31 [llama-cloud]\n",
      "   ------------------------ --------------- 19/31 [llama-cloud]\n",
      "   ------------------------ --------------- 19/31 [llama-cloud]\n",
      "   ------------------------ --------------- 19/31 [llama-cloud]\n",
      "   ------------------------ --------------- 19/31 [llama-cloud]\n",
      "   ------------------------ --------------- 19/31 [llama-cloud]\n",
      "   ------------------------ --------------- 19/31 [llama-cloud]\n",
      "   ------------------------ --------------- 19/31 [llama-cloud]\n",
      "   ------------------------ --------------- 19/31 [llama-cloud]\n",
      "   ------------------------ --------------- 19/31 [llama-cloud]\n",
      "   ------------------------ --------------- 19/31 [llama-cloud]\n",
      "   ------------------------ --------------- 19/31 [llama-cloud]\n",
      "   ------------------------ --------------- 19/31 [llama-cloud]\n",
      "   ------------------------ --------------- 19/31 [llama-cloud]\n",
      "   ------------------------ --------------- 19/31 [llama-cloud]\n",
      "   ------------------------ --------------- 19/31 [llama-cloud]\n",
      "   ------------------------ --------------- 19/31 [llama-cloud]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   ------------------------- -------------- 20/31 [llama-index-core]\n",
      "   --------------------------- ------------ 21/31 [llama-index-readers-file]\n",
      "   --------------------------- ------------ 21/31 [llama-index-readers-file]\n",
      "   --------------------- ------ 24/31 [llama-index-indices-managed-llama-cloud]\n",
      "   --------------------------------- ------ 26/31 [llama-cloud-services]\n",
      "   --------------------------------- ------ 26/31 [llama-cloud-services]\n",
      "   ------------------------------------ --- 28/31 [llama-index-cli]\n",
      "   ---------------------------------------- 31/31 [llama-index]\n",
      "\n",
      "Successfully installed accelerate-1.12.0 banks-2.2.0 beautifulsoup4-4.14.2 defusedxml-0.7.1 deprecated-1.2.18 dirtyjson-1.0.8 filetype-1.2.0 griffe-1.15.0 huggingface-hub-0.36.0 llama-cloud-0.1.35 llama-cloud-services-0.6.54 llama-index-0.14.8 llama-index-cli-0.5.3 llama-index-core-0.14.8 llama-index-embeddings-openai-0.5.1 llama-index-indices-managed-llama-cloud-0.9.4 llama-index-instrumentation-0.4.2 llama-index-llms-huggingface-0.6.1 llama-index-llms-openai-0.6.9 llama-index-readers-file-0.5.5 llama-index-readers-llama-parse-0.5.1 llama-index-workflows-2.11.3 llama-parse-0.6.54 nltk-3.9.2 pandas-2.2.3 safetensors-0.7.0 soupsieve-2.8 striprtf-0.0.26 sympy-1.13.1 tokenizers-0.22.1 transformers-4.57.1\n"
     ]
    }
   ],
   "source": [
    "!pip install \"llama-index>=0.11.0\" \"llama-index-llms-huggingface\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb44a37e-b84b-4122-b289-c74c0e1b9820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True\n",
      "Torch CUDA build: 12.1\n",
      "GPU: NVIDIA GeForce GTX 1660 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA:\", torch.cuda.is_available())\n",
    "print(\"Torch CUDA build:\", torch.version.cuda)\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02304338",
   "metadata": {
    "id": "02304338"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Display the complete contents of dataframe cells.\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "yIsaUyZm0o8H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348,
     "referenced_widgets": [
      "48266caffc3642bf80243e2b263788ac",
      "ec524274197a472bab36b64889c7dc22",
      "4b4e2f42e5d943cfa4452775d7f578d8",
      "60d5150556e24769b4226fb6140c4063",
      "be5e183822084b678718b93b1be65825",
      "001c0e7167de433ba6cdb0153b4e659c",
      "6869d513358e4bfd83bdb71574bf10c7",
      "1b47880b48754a76baf2c33695e0d710",
      "14d4231d5e1840e48fbab399d928a0e3",
      "201fc2a10d6e4fa09fcdf4450ef217a4",
      "9fa638591c1446f296bcd0a4d5d8beec"
     ]
    },
    "id": "yIsaUyZm0o8H",
    "outputId": "031aeada-7e7a-41ae-eeb1-6901f818a29c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AZhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n",
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct.\n403 Client Error. (Request ID: Root=1-693b3b40-05fbd94931edb91a484df44e;eaa73c62-bfbf-4db1-8f8e-07e761085e65)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.2-1B-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct to ask for access.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:402\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 402\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\requests\\models.py:1026\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\transformers\\utils\\hub.py:479\u001b[0m, in \u001b[0;36mcached_files\u001b[1;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[1;32m--> 479\u001b[0m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:1007\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[0;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[0;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[0;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:1114\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[1;32m-> 1114\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:1655\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[1;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[0;32m   1650\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m\n\u001b[0;32m   1652\u001b[0m ):\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[1;32m-> 1655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[0;32m   1656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1657\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:1543\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[1;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1543\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:1460\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[0m\n\u001b[0;32m   1459\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1460\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1469\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:283\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 283\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m    284\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    285\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    286\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    288\u001b[0m     )\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:307\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    306\u001b[0m response \u001b[38;5;241m=\u001b[39m http_backoff(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m--> 307\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:419\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    416\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    418\u001b[0m     )\n\u001b[1;32m--> 419\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(GatedRepoError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_message \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to this resource is disabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mGatedRepoError\u001b[0m: 403 Client Error. (Request ID: Root=1-693b3b40-05fbd94931edb91a484df44e;eaa73c62-bfbf-4db1-8f8e-07e761085e65)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.2-1B-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct to ask for access.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing device:\u001b[39m\u001b[38;5;124m\"\u001b[39m, device)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# --- Tokenizer ---\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     20\u001b[0m     tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:1109\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1107\u001b[0m         config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfor_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_dict)\n\u001b[0;32m   1108\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1109\u001b[0m         config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m   1110\u001b[0m             pretrained_model_name_or_path, trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1111\u001b[0m         )\n\u001b[0;32m   1112\u001b[0m config_tokenizer_class \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtokenizer_class\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1332\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m   1329\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1330\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1332\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m PretrainedConfig\u001b[38;5;241m.\u001b[39mget_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1333\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1334\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\transformers\\configuration_utils.py:662\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    660\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    661\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 662\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\transformers\\configuration_utils.py:721\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    717\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    736\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\transformers\\utils\\hub.py:322\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcached_file\u001b[39m(\n\u001b[0;32m    265\u001b[0m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[0;32m    266\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    268\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    269\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m     file \u001b[38;5;241m=\u001b[39m cached_files(path_or_repo_id\u001b[38;5;241m=\u001b[39mpath_or_repo_id, filenames\u001b[38;5;241m=\u001b[39m[filename], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    323\u001b[0m     file \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\transformers\\utils\\hub.py:543\u001b[0m, in \u001b[0;36mcached_files\u001b[1;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_gated_repo:\n\u001b[0;32m    542\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 543\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    546\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, LocalEntryNotFoundError):\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_connection_errors:\n",
      "\u001b[1;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct.\n403 Client Error. (Request ID: Root=1-693b3b40-05fbd94931edb91a484df44e;eaa73c62-bfbf-4db1-8f8e-07e761085e65)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.2-1B-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct to ask for access."
     ]
    }
   ],
   "source": [
    "from llama_index.core.settings import Settings\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Reset any previous LLM in LlamaIndex\n",
    "Settings.llm = None  \n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# --- Tokenizer ---\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# --- Model ---\n",
    "if device == \"cuda\":\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=dtype,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "else:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=dtype,\n",
    "    )\n",
    "\n",
    "print(\"First model parameter device:\", next(model.parameters()).device)\n",
    "\n",
    "# --- Wrap in LlamaIndex LLM ---\n",
    "llm = HuggingFaceLLM(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    model_name=model_name,\n",
    "    tokenizer_name=model_name,\n",
    "    context_window=4096,\n",
    "    max_new_tokens=256,\n",
    "    generate_kwargs={\n",
    "        \"do_sample\": False,   # greedy, deterministic (good for evaluation)\n",
    "    },\n",
    ")\n",
    "\n",
    "from ragas.llms import LlamaIndexLLMWrapper\n",
    "evaluator_llm = LlamaIndexLLMWrapper(llm)   # deprecation warning is OK for now\n",
    "\n",
    "# Register with LlamaIndex (if you use it elsewhere)\n",
    "Settings.llm = llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9373c880",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "9373c880",
    "outputId": "463a4663-de14-4e0d-d7ab-06d7050ebeee"
   },
   "outputs": [],
   "source": [
    "import phoenix as px\n",
    "\n",
    "(session := px.launch_app()).view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a253f768-5570-46d5-976b-55fc7730c7ec",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openinference-instrumentation-langchain\n",
      "  Downloading openinference_instrumentation_langchain-0.1.55-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting openinference-instrumentation-llama-index\n",
      "  Downloading openinference_instrumentation_llama_index-4.3.9-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: openinference-instrumentation>=0.1.27 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from openinference-instrumentation-langchain) (0.1.42)\n",
      "Requirement already satisfied: openinference-semantic-conventions>=0.1.17 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from openinference-instrumentation-langchain) (0.1.25)\n",
      "Requirement already satisfied: opentelemetry-api in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from openinference-instrumentation-langchain) (1.38.0)\n",
      "Collecting opentelemetry-instrumentation (from openinference-instrumentation-langchain)\n",
      "  Downloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from openinference-instrumentation-langchain) (0.59b0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from openinference-instrumentation-langchain) (1.17.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from openinference-instrumentation-llama-index) (4.15.0)\n",
      "Requirement already satisfied: opentelemetry-sdk in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from openinference-instrumentation>=0.1.27->openinference-instrumentation-langchain) (1.38.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from opentelemetry-api->openinference-instrumentation-langchain) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api->openinference-instrumentation-langchain) (3.23.0)\n",
      "Requirement already satisfied: packaging>=18.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from opentelemetry-instrumentation->openinference-instrumentation-langchain) (25.0)\n",
      "Downloading openinference_instrumentation_langchain-0.1.55-py3-none-any.whl (22 kB)\n",
      "Downloading openinference_instrumentation_llama_index-4.3.9-py3-none-any.whl (29 kB)\n",
      "Downloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: opentelemetry-instrumentation, openinference-instrumentation-llama-index, openinference-instrumentation-langchain\n",
      "\n",
      "   --------- ------------------ 1/3 [openinference-instrumentation-llama-index]\n",
      "   ------------------------------ 3/3 [openinference-instrumentation-langchain]\n",
      "\n",
      "Successfully installed openinference-instrumentation-langchain-0.1.55 openinference-instrumentation-llama-index-4.3.9 opentelemetry-instrumentation-0.59b0\n"
     ]
    }
   ],
   "source": [
    "!pip install openinference-instrumentation-langchain openinference-instrumentation-llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e3c8b98",
   "metadata": {
    "id": "3e3c8b98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n",
      "Attempting to instrument while already instrumented\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenTelemetry Tracing Details\n",
      "|  Phoenix Project: default\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: localhost:4317\n",
      "|  Transport: gRPC\n",
      "|  Transport Headers: {}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n",
      "✅ LangChain tracing enabled!\n",
      "⚠️  LlamaIndex tracing skipped due to version compatibility\n"
     ]
    }
   ],
   "source": [
    "from phoenix.otel import register\n",
    "from openinference.instrumentation.langchain import LangChainInstrumentor\n",
    "\n",
    "tracer_provider = register()\n",
    "LangChainInstrumentor().instrument(tracer_provider=tracer_provider)\n",
    "\n",
    "print(\"✅ LangChain tracing enabled!\")\n",
    "print(\"⚠️  LlamaIndex tracing skipped due to version compatibility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f707d3-e921-4f81-bbfb-a2ddb917c79d",
   "metadata": {
    "id": "78f707d3-e921-4f81-bbfb-a2ddb917c79d"
   },
   "source": [
    "## 4. Load our dataset (ArabicaQA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0959578e-0082-4bbc-8bf9-b7503fc53312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['paragraphs'],\n",
       "        num_rows: 2108\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the MRC split of ArabicaQA from Hugging Face\n",
    "arabica_mrc = load_dataset(\n",
    "    \"abdoelsayed/ArabicaQA\",\n",
    "    data_files={\n",
    "        #\"train\": \"MRC/train.json\",\n",
    "        #\"validation\": \"MRC/val.json\",\n",
    "        \"test\": \"MRC/test.json\",\n",
    "    },\n",
    "    field=\"data\",  # the JSON has a top-level field called \"data\"\n",
    ")\n",
    "\n",
    "arabica_mrc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437cd4f0-4be6-453b-93c5-07e9f8f226a1",
   "metadata": {},
   "source": [
    "In ArabicaQA (MRC task):\n",
    "The MRC test set contains:\n",
    "- question\n",
    "-  context (the correct paragraph from Wikipedia)\n",
    "-  answers (ground truth answer spans)\n",
    "\n",
    "We will use:\n",
    "- context → to build your vector index (RAG knowledge base)\n",
    "- question → to query your RAG\n",
    "- answers → ground truth for RAGAS evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b89939d4-115b-41c9-8753-8ec9d05a2494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paragraphs': [{'context': 'المرصد الحضري لمدينة الرياض ويعرف اختصارًا بمرصد الرياض هو مركز متخصص في وضع نظم مراقبة حضرية لرصد سير عمليات التنمية الحضرية للمدينة، ويهدف إلى فهم الوضع الحالي للمدينة ووضع تصور للاتجاهات المستقبلية، ومراقبة الإنجاز لتحقيق الأهداف واتخاذ القرارات. التأسيس. بدأت أول خطوات إنشاء المرصد في عام 2009م، من الهيئة العليا لتطوير مدينة الرياض؛ ومن ثم أُقرَّ الهيكل التنظيمي للمرصد الحضري الذي يتكون من مجلس ولجنة تنفيذية ومركز. ويترأس مجلس المرصد أمير المنطقة بالإضافة إلى أربعة عشر عضوا، وتتكون اللَّجنة التنفيذية من 15 عضوًا يمثلون أهم مصادر البيانات ذات الصلة بالمؤشرات الحضرية من القطاع الحكومي والقطاع الخاص. المهام. في عام 1434هـ أطلق المرصد الحضري لمدينة الرياض، المؤشرات الحضرية للدورة الأولى التي ضمت (80) مؤشراً، بعد إقرار نتائج تلك المؤشرات في اجتماع الهيئة الثاني لعام 1435هـ، وشملت الحدّ الأدنى من المؤشرات الحضرية العالمية بالإضافة إلى المؤشرات المحلية. يعمل المرصد الحضري لمدينة الرياض على رصد وتقييم اتجاهات التنمية في مدينة الرياض من خلال إنتاج المؤشرات الحضرية التي تقدم معلومات موجزة عن الوضع الراهن والاتجاهات المستقبلية المتوقعة وتقيس مستوى الاستجابة للسياسات والبرامج التنفيذية حسب الأهداف لخطط التنمية المستدامة، ويتم ذلك ضمن إطار رصد عالمي يوفر خطة شاملة للرصد والتقييم ويسهل من عملية تحديد المؤشرات الأساسية ضمن مجموعات معيارية تُمكِّن من مقارنة التقدم مع المدن الأخرى ومؤشرات أخرى تعكس خصوصية مدينة الرياض من خلال تحديد الأولويات والقضايا الهامة في المدينة حسب أهداف المخطط الاستراتيجي الشامل لمدينة الرياض، ورؤية المملكة 2030، بالإضافة إلى أولويات الجهات المشاركة بالمرصد التي تشمل القطاع الحكومي والقطاع الخاص والمجتمع المدني. الإنجازات. في مارس 2017 حصل المرصد الحضري بمدينة الرياض على الشهادة الذهبية WCCD ISO 37120 من المجلس العالمي لبيانات المدن في كندا (WCCD).',\n",
       "   'document_id': 1718795,\n",
       "   'qas': [{'answers': [{'answer_category': None,\n",
       "       'answer_end': 483,\n",
       "       'answer_id': 1067193,\n",
       "       'answer_start': 424,\n",
       "       'document_id': 1718795,\n",
       "       'question_id': 1166998,\n",
       "       'text': 'يترأس مجلس المرصد أمير المنطقة بالإضافة إلى أربعة عشر عضوا،'}],\n",
       "     'id': 1166998,\n",
       "     'is_impossible': False,\n",
       "     'question': 'من الذي يترأس المرصد الحضري لمدينة الرياض؟'},\n",
       "    {'answers': [{'answer_category': None,\n",
       "       'answer_end': 1687,\n",
       "       'answer_id': 1067194,\n",
       "       'answer_start': 1560,\n",
       "       'document_id': 1718795,\n",
       "       'question_id': 1166999,\n",
       "       'text': ' في مارس 2017 حصل المرصد الحضري بمدينة الرياض على الشهادة الذهبية WCCD ISO 37120 من المجلس العالمي لبيانات المدن في كندا (WCCD)'}],\n",
       "     'id': 1166999,\n",
       "     'is_impossible': False,\n",
       "     'question': 'ما هي الإنجازات البارزة التي حققها المرصد الحضري بمدينة الرياض؟'},\n",
       "    {'answers': [{'answer_category': None,\n",
       "       'answer_end': 134,\n",
       "       'answer_id': 1067188,\n",
       "       'answer_start': 56,\n",
       "       'document_id': 1718795,\n",
       "       'question_id': 1166993,\n",
       "       'text': 'هو مركز متخصص في وضع نظم مراقبة حضرية لرصد سير عمليات التنمية الحضرية للمدينة،'}],\n",
       "     'id': 1166993,\n",
       "     'is_impossible': False,\n",
       "     'question': 'ما هو المرصد الحضري لمدينة الرياض؟'},\n",
       "    {'answers': [{'answer_category': None,\n",
       "       'answer_end': 201,\n",
       "       'answer_id': 1067189,\n",
       "       'answer_start': 136,\n",
       "       'document_id': 1718795,\n",
       "       'question_id': 1166994,\n",
       "       'text': 'يهدف إلى فهم الوضع الحالي للمدينة ووضع تصور للاتجاهات المستقبلية،'}],\n",
       "     'id': 1166994,\n",
       "     'is_impossible': False,\n",
       "     'question': 'ما هو الهدف من المرصد الحضري لمدينة الرياض؟'},\n",
       "    {'answers': [{'answer_category': None,\n",
       "       'answer_end': 249,\n",
       "       'answer_id': 1067190,\n",
       "       'answer_start': 202,\n",
       "       'document_id': 1718795,\n",
       "       'question_id': 1166995,\n",
       "       'text': 'ومراقبة الإنجاز لتحقيق الأهداف واتخاذ القرارات.'}],\n",
       "     'id': 1166995,\n",
       "     'is_impossible': False,\n",
       "     'question': 'ما هي مهام المرصد الحضري لمدينة الرياض؟'},\n",
       "    {'answers': [{'answer_category': None,\n",
       "       'answer_end': 300,\n",
       "       'answer_id': 1067191,\n",
       "       'answer_start': 274,\n",
       "       'document_id': 1718795,\n",
       "       'question_id': 1166996,\n",
       "       'text': 'إنشاء المرصد في عام 2009م،'}],\n",
       "     'id': 1166996,\n",
       "     'is_impossible': False,\n",
       "     'question': 'متي تم أنشاء المرصد الحضري لمدينة الرياض؟'},\n",
       "    {'answers': [{'answer_category': None,\n",
       "       'answer_end': 337,\n",
       "       'answer_id': 1067192,\n",
       "       'answer_start': 301,\n",
       "       'document_id': 1718795,\n",
       "       'question_id': 1166997,\n",
       "       'text': 'من الهيئة العليا لتطوير مدينة الرياض'}],\n",
       "     'id': 1166997,\n",
       "     'is_impossible': False,\n",
       "     'question': 'من الذي قام بأنشاء المرصد الحضري لمدينة الرياض؟'}]}]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = arabica_mrc[\"test\"]\n",
    "test_ds[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9abf95-d18e-4880-a53d-70188287c5b4",
   "metadata": {},
   "source": [
    "## Convert the test set into a clean RAG-ready DataFrame\n",
    "For RAG, we need:\n",
    "- knowledge documents → contexts\n",
    "- evaluation questions → questions\n",
    "- ground truth → answers\n",
    "\n",
    "ArabicaQA test samples have 1 context + multiple Q/A pairs, so we must flatten them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fca413e9-d8c9-4f4b-8b8c-975061798445",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>المرصد الحضري لمدينة الرياض ويعرف اختصارًا بمرصد الرياض هو مركز متخصص في وضع نظم مراقبة حضرية لرصد سير عمليات التنمية الحضرية للمدينة، ويهدف إلى فهم الوضع الحالي للمدينة ووضع تصور للاتجاهات المستقبلية، ومراقبة الإنجاز لتحقيق الأهداف واتخاذ القرارات. التأسيس. بدأت أول خطوات إنشاء المرصد في عام 2009م، من الهيئة العليا لتطوير مدينة الرياض؛ ومن ثم أُقرَّ الهيكل التنظيمي للمرصد الحضري الذي يتكون من مجلس ولجنة تنفيذية ومركز. ويترأس مجلس المرصد أمير المنطقة بالإضافة إلى أربعة عشر عضوا، وتتكون اللَّجنة التنفيذية من 15 عضوًا يمثلون أهم مصادر البيانات ذات الصلة بالمؤشرات الحضرية من القطاع الحكومي والقطاع الخاص. المهام. في عام 1434هـ أطلق المرصد الحضري لمدينة الرياض، المؤشرات الحضرية للدورة الأولى التي ضمت (80) مؤشراً، بعد إقرار نتائج تلك المؤشرات في اجتماع الهيئة الثاني لعام 1435هـ، وشملت الحدّ الأدنى من المؤشرات الحضرية العالمية بالإضافة إلى المؤشرات المحلية. يعمل المرصد الحضري لمدينة الرياض على رصد وتقييم اتجاهات التنمية في مدينة الرياض من خلال إنتاج المؤشرات الحضرية التي تقدم معلومات موجزة عن الوضع الراهن والاتجاهات المستقبلية المتوقعة وتقيس مستوى الاستجابة للسياسات والبرامج التنفيذية حسب الأهداف لخطط التنمية المستدامة، ويتم ذلك ضمن إطار رصد عالمي يوفر خطة شاملة للرصد والتقييم ويسهل من عملية تحديد المؤشرات الأساسية ضمن مجموعات معيارية تُمكِّن من مقارنة التقدم مع المدن الأخرى ومؤشرات أخرى تعكس خصوصية مدينة الرياض من خلال تحديد الأولويات والقضايا الهامة في المدينة حسب أهداف المخطط الاستراتيجي الشامل لمدينة الرياض، ورؤية المملكة 2030، بالإضافة إلى أولويات الجهات المشاركة بالمرصد التي تشمل القطاع الحكومي والقطاع الخاص والمجتمع المدني. الإنجازات. في مارس 2017 حصل المرصد الحضري بمدينة الرياض على الشهادة الذهبية WCCD ISO 37120 من المجلس العالمي لبيانات المدن في كندا (WCCD).</td>\n",
       "      <td>من الذي يترأس المرصد الحضري لمدينة الرياض؟</td>\n",
       "      <td>يترأس مجلس المرصد أمير المنطقة بالإضافة إلى أربعة عشر عضوا،</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>المرصد الحضري لمدينة الرياض ويعرف اختصارًا بمرصد الرياض هو مركز متخصص في وضع نظم مراقبة حضرية لرصد سير عمليات التنمية الحضرية للمدينة، ويهدف إلى فهم الوضع الحالي للمدينة ووضع تصور للاتجاهات المستقبلية، ومراقبة الإنجاز لتحقيق الأهداف واتخاذ القرارات. التأسيس. بدأت أول خطوات إنشاء المرصد في عام 2009م، من الهيئة العليا لتطوير مدينة الرياض؛ ومن ثم أُقرَّ الهيكل التنظيمي للمرصد الحضري الذي يتكون من مجلس ولجنة تنفيذية ومركز. ويترأس مجلس المرصد أمير المنطقة بالإضافة إلى أربعة عشر عضوا، وتتكون اللَّجنة التنفيذية من 15 عضوًا يمثلون أهم مصادر البيانات ذات الصلة بالمؤشرات الحضرية من القطاع الحكومي والقطاع الخاص. المهام. في عام 1434هـ أطلق المرصد الحضري لمدينة الرياض، المؤشرات الحضرية للدورة الأولى التي ضمت (80) مؤشراً، بعد إقرار نتائج تلك المؤشرات في اجتماع الهيئة الثاني لعام 1435هـ، وشملت الحدّ الأدنى من المؤشرات الحضرية العالمية بالإضافة إلى المؤشرات المحلية. يعمل المرصد الحضري لمدينة الرياض على رصد وتقييم اتجاهات التنمية في مدينة الرياض من خلال إنتاج المؤشرات الحضرية التي تقدم معلومات موجزة عن الوضع الراهن والاتجاهات المستقبلية المتوقعة وتقيس مستوى الاستجابة للسياسات والبرامج التنفيذية حسب الأهداف لخطط التنمية المستدامة، ويتم ذلك ضمن إطار رصد عالمي يوفر خطة شاملة للرصد والتقييم ويسهل من عملية تحديد المؤشرات الأساسية ضمن مجموعات معيارية تُمكِّن من مقارنة التقدم مع المدن الأخرى ومؤشرات أخرى تعكس خصوصية مدينة الرياض من خلال تحديد الأولويات والقضايا الهامة في المدينة حسب أهداف المخطط الاستراتيجي الشامل لمدينة الرياض، ورؤية المملكة 2030، بالإضافة إلى أولويات الجهات المشاركة بالمرصد التي تشمل القطاع الحكومي والقطاع الخاص والمجتمع المدني. الإنجازات. في مارس 2017 حصل المرصد الحضري بمدينة الرياض على الشهادة الذهبية WCCD ISO 37120 من المجلس العالمي لبيانات المدن في كندا (WCCD).</td>\n",
       "      <td>ما هي الإنجازات البارزة التي حققها المرصد الحضري بمدينة الرياض؟</td>\n",
       "      <td>في مارس 2017 حصل المرصد الحضري بمدينة الرياض على الشهادة الذهبية WCCD ISO 37120 من المجلس العالمي لبيانات المدن في كندا (WCCD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>المرصد الحضري لمدينة الرياض ويعرف اختصارًا بمرصد الرياض هو مركز متخصص في وضع نظم مراقبة حضرية لرصد سير عمليات التنمية الحضرية للمدينة، ويهدف إلى فهم الوضع الحالي للمدينة ووضع تصور للاتجاهات المستقبلية، ومراقبة الإنجاز لتحقيق الأهداف واتخاذ القرارات. التأسيس. بدأت أول خطوات إنشاء المرصد في عام 2009م، من الهيئة العليا لتطوير مدينة الرياض؛ ومن ثم أُقرَّ الهيكل التنظيمي للمرصد الحضري الذي يتكون من مجلس ولجنة تنفيذية ومركز. ويترأس مجلس المرصد أمير المنطقة بالإضافة إلى أربعة عشر عضوا، وتتكون اللَّجنة التنفيذية من 15 عضوًا يمثلون أهم مصادر البيانات ذات الصلة بالمؤشرات الحضرية من القطاع الحكومي والقطاع الخاص. المهام. في عام 1434هـ أطلق المرصد الحضري لمدينة الرياض، المؤشرات الحضرية للدورة الأولى التي ضمت (80) مؤشراً، بعد إقرار نتائج تلك المؤشرات في اجتماع الهيئة الثاني لعام 1435هـ، وشملت الحدّ الأدنى من المؤشرات الحضرية العالمية بالإضافة إلى المؤشرات المحلية. يعمل المرصد الحضري لمدينة الرياض على رصد وتقييم اتجاهات التنمية في مدينة الرياض من خلال إنتاج المؤشرات الحضرية التي تقدم معلومات موجزة عن الوضع الراهن والاتجاهات المستقبلية المتوقعة وتقيس مستوى الاستجابة للسياسات والبرامج التنفيذية حسب الأهداف لخطط التنمية المستدامة، ويتم ذلك ضمن إطار رصد عالمي يوفر خطة شاملة للرصد والتقييم ويسهل من عملية تحديد المؤشرات الأساسية ضمن مجموعات معيارية تُمكِّن من مقارنة التقدم مع المدن الأخرى ومؤشرات أخرى تعكس خصوصية مدينة الرياض من خلال تحديد الأولويات والقضايا الهامة في المدينة حسب أهداف المخطط الاستراتيجي الشامل لمدينة الرياض، ورؤية المملكة 2030، بالإضافة إلى أولويات الجهات المشاركة بالمرصد التي تشمل القطاع الحكومي والقطاع الخاص والمجتمع المدني. الإنجازات. في مارس 2017 حصل المرصد الحضري بمدينة الرياض على الشهادة الذهبية WCCD ISO 37120 من المجلس العالمي لبيانات المدن في كندا (WCCD).</td>\n",
       "      <td>ما هو المرصد الحضري لمدينة الرياض؟</td>\n",
       "      <td>هو مركز متخصص في وضع نظم مراقبة حضرية لرصد سير عمليات التنمية الحضرية للمدينة،</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>المرصد الحضري لمدينة الرياض ويعرف اختصارًا بمرصد الرياض هو مركز متخصص في وضع نظم مراقبة حضرية لرصد سير عمليات التنمية الحضرية للمدينة، ويهدف إلى فهم الوضع الحالي للمدينة ووضع تصور للاتجاهات المستقبلية، ومراقبة الإنجاز لتحقيق الأهداف واتخاذ القرارات. التأسيس. بدأت أول خطوات إنشاء المرصد في عام 2009م، من الهيئة العليا لتطوير مدينة الرياض؛ ومن ثم أُقرَّ الهيكل التنظيمي للمرصد الحضري الذي يتكون من مجلس ولجنة تنفيذية ومركز. ويترأس مجلس المرصد أمير المنطقة بالإضافة إلى أربعة عشر عضوا، وتتكون اللَّجنة التنفيذية من 15 عضوًا يمثلون أهم مصادر البيانات ذات الصلة بالمؤشرات الحضرية من القطاع الحكومي والقطاع الخاص. المهام. في عام 1434هـ أطلق المرصد الحضري لمدينة الرياض، المؤشرات الحضرية للدورة الأولى التي ضمت (80) مؤشراً، بعد إقرار نتائج تلك المؤشرات في اجتماع الهيئة الثاني لعام 1435هـ، وشملت الحدّ الأدنى من المؤشرات الحضرية العالمية بالإضافة إلى المؤشرات المحلية. يعمل المرصد الحضري لمدينة الرياض على رصد وتقييم اتجاهات التنمية في مدينة الرياض من خلال إنتاج المؤشرات الحضرية التي تقدم معلومات موجزة عن الوضع الراهن والاتجاهات المستقبلية المتوقعة وتقيس مستوى الاستجابة للسياسات والبرامج التنفيذية حسب الأهداف لخطط التنمية المستدامة، ويتم ذلك ضمن إطار رصد عالمي يوفر خطة شاملة للرصد والتقييم ويسهل من عملية تحديد المؤشرات الأساسية ضمن مجموعات معيارية تُمكِّن من مقارنة التقدم مع المدن الأخرى ومؤشرات أخرى تعكس خصوصية مدينة الرياض من خلال تحديد الأولويات والقضايا الهامة في المدينة حسب أهداف المخطط الاستراتيجي الشامل لمدينة الرياض، ورؤية المملكة 2030، بالإضافة إلى أولويات الجهات المشاركة بالمرصد التي تشمل القطاع الحكومي والقطاع الخاص والمجتمع المدني. الإنجازات. في مارس 2017 حصل المرصد الحضري بمدينة الرياض على الشهادة الذهبية WCCD ISO 37120 من المجلس العالمي لبيانات المدن في كندا (WCCD).</td>\n",
       "      <td>ما هو الهدف من المرصد الحضري لمدينة الرياض؟</td>\n",
       "      <td>يهدف إلى فهم الوضع الحالي للمدينة ووضع تصور للاتجاهات المستقبلية،</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>المرصد الحضري لمدينة الرياض ويعرف اختصارًا بمرصد الرياض هو مركز متخصص في وضع نظم مراقبة حضرية لرصد سير عمليات التنمية الحضرية للمدينة، ويهدف إلى فهم الوضع الحالي للمدينة ووضع تصور للاتجاهات المستقبلية، ومراقبة الإنجاز لتحقيق الأهداف واتخاذ القرارات. التأسيس. بدأت أول خطوات إنشاء المرصد في عام 2009م، من الهيئة العليا لتطوير مدينة الرياض؛ ومن ثم أُقرَّ الهيكل التنظيمي للمرصد الحضري الذي يتكون من مجلس ولجنة تنفيذية ومركز. ويترأس مجلس المرصد أمير المنطقة بالإضافة إلى أربعة عشر عضوا، وتتكون اللَّجنة التنفيذية من 15 عضوًا يمثلون أهم مصادر البيانات ذات الصلة بالمؤشرات الحضرية من القطاع الحكومي والقطاع الخاص. المهام. في عام 1434هـ أطلق المرصد الحضري لمدينة الرياض، المؤشرات الحضرية للدورة الأولى التي ضمت (80) مؤشراً، بعد إقرار نتائج تلك المؤشرات في اجتماع الهيئة الثاني لعام 1435هـ، وشملت الحدّ الأدنى من المؤشرات الحضرية العالمية بالإضافة إلى المؤشرات المحلية. يعمل المرصد الحضري لمدينة الرياض على رصد وتقييم اتجاهات التنمية في مدينة الرياض من خلال إنتاج المؤشرات الحضرية التي تقدم معلومات موجزة عن الوضع الراهن والاتجاهات المستقبلية المتوقعة وتقيس مستوى الاستجابة للسياسات والبرامج التنفيذية حسب الأهداف لخطط التنمية المستدامة، ويتم ذلك ضمن إطار رصد عالمي يوفر خطة شاملة للرصد والتقييم ويسهل من عملية تحديد المؤشرات الأساسية ضمن مجموعات معيارية تُمكِّن من مقارنة التقدم مع المدن الأخرى ومؤشرات أخرى تعكس خصوصية مدينة الرياض من خلال تحديد الأولويات والقضايا الهامة في المدينة حسب أهداف المخطط الاستراتيجي الشامل لمدينة الرياض، ورؤية المملكة 2030، بالإضافة إلى أولويات الجهات المشاركة بالمرصد التي تشمل القطاع الحكومي والقطاع الخاص والمجتمع المدني. الإنجازات. في مارس 2017 حصل المرصد الحضري بمدينة الرياض على الشهادة الذهبية WCCD ISO 37120 من المجلس العالمي لبيانات المدن في كندا (WCCD).</td>\n",
       "      <td>ما هي مهام المرصد الحضري لمدينة الرياض؟</td>\n",
       "      <td>ومراقبة الإنجاز لتحقيق الأهداف واتخاذ القرارات.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    context  \\\n",
       "0  المرصد الحضري لمدينة الرياض ويعرف اختصارًا بمرصد الرياض هو مركز متخصص في وضع نظم مراقبة حضرية لرصد سير عمليات التنمية الحضرية للمدينة، ويهدف إلى فهم الوضع الحالي للمدينة ووضع تصور للاتجاهات المستقبلية، ومراقبة الإنجاز لتحقيق الأهداف واتخاذ القرارات. التأسيس. بدأت أول خطوات إنشاء المرصد في عام 2009م، من الهيئة العليا لتطوير مدينة الرياض؛ ومن ثم أُقرَّ الهيكل التنظيمي للمرصد الحضري الذي يتكون من مجلس ولجنة تنفيذية ومركز. ويترأس مجلس المرصد أمير المنطقة بالإضافة إلى أربعة عشر عضوا، وتتكون اللَّجنة التنفيذية من 15 عضوًا يمثلون أهم مصادر البيانات ذات الصلة بالمؤشرات الحضرية من القطاع الحكومي والقطاع الخاص. المهام. في عام 1434هـ أطلق المرصد الحضري لمدينة الرياض، المؤشرات الحضرية للدورة الأولى التي ضمت (80) مؤشراً، بعد إقرار نتائج تلك المؤشرات في اجتماع الهيئة الثاني لعام 1435هـ، وشملت الحدّ الأدنى من المؤشرات الحضرية العالمية بالإضافة إلى المؤشرات المحلية. يعمل المرصد الحضري لمدينة الرياض على رصد وتقييم اتجاهات التنمية في مدينة الرياض من خلال إنتاج المؤشرات الحضرية التي تقدم معلومات موجزة عن الوضع الراهن والاتجاهات المستقبلية المتوقعة وتقيس مستوى الاستجابة للسياسات والبرامج التنفيذية حسب الأهداف لخطط التنمية المستدامة، ويتم ذلك ضمن إطار رصد عالمي يوفر خطة شاملة للرصد والتقييم ويسهل من عملية تحديد المؤشرات الأساسية ضمن مجموعات معيارية تُمكِّن من مقارنة التقدم مع المدن الأخرى ومؤشرات أخرى تعكس خصوصية مدينة الرياض من خلال تحديد الأولويات والقضايا الهامة في المدينة حسب أهداف المخطط الاستراتيجي الشامل لمدينة الرياض، ورؤية المملكة 2030، بالإضافة إلى أولويات الجهات المشاركة بالمرصد التي تشمل القطاع الحكومي والقطاع الخاص والمجتمع المدني. الإنجازات. في مارس 2017 حصل المرصد الحضري بمدينة الرياض على الشهادة الذهبية WCCD ISO 37120 من المجلس العالمي لبيانات المدن في كندا (WCCD).   \n",
       "1  المرصد الحضري لمدينة الرياض ويعرف اختصارًا بمرصد الرياض هو مركز متخصص في وضع نظم مراقبة حضرية لرصد سير عمليات التنمية الحضرية للمدينة، ويهدف إلى فهم الوضع الحالي للمدينة ووضع تصور للاتجاهات المستقبلية، ومراقبة الإنجاز لتحقيق الأهداف واتخاذ القرارات. التأسيس. بدأت أول خطوات إنشاء المرصد في عام 2009م، من الهيئة العليا لتطوير مدينة الرياض؛ ومن ثم أُقرَّ الهيكل التنظيمي للمرصد الحضري الذي يتكون من مجلس ولجنة تنفيذية ومركز. ويترأس مجلس المرصد أمير المنطقة بالإضافة إلى أربعة عشر عضوا، وتتكون اللَّجنة التنفيذية من 15 عضوًا يمثلون أهم مصادر البيانات ذات الصلة بالمؤشرات الحضرية من القطاع الحكومي والقطاع الخاص. المهام. في عام 1434هـ أطلق المرصد الحضري لمدينة الرياض، المؤشرات الحضرية للدورة الأولى التي ضمت (80) مؤشراً، بعد إقرار نتائج تلك المؤشرات في اجتماع الهيئة الثاني لعام 1435هـ، وشملت الحدّ الأدنى من المؤشرات الحضرية العالمية بالإضافة إلى المؤشرات المحلية. يعمل المرصد الحضري لمدينة الرياض على رصد وتقييم اتجاهات التنمية في مدينة الرياض من خلال إنتاج المؤشرات الحضرية التي تقدم معلومات موجزة عن الوضع الراهن والاتجاهات المستقبلية المتوقعة وتقيس مستوى الاستجابة للسياسات والبرامج التنفيذية حسب الأهداف لخطط التنمية المستدامة، ويتم ذلك ضمن إطار رصد عالمي يوفر خطة شاملة للرصد والتقييم ويسهل من عملية تحديد المؤشرات الأساسية ضمن مجموعات معيارية تُمكِّن من مقارنة التقدم مع المدن الأخرى ومؤشرات أخرى تعكس خصوصية مدينة الرياض من خلال تحديد الأولويات والقضايا الهامة في المدينة حسب أهداف المخطط الاستراتيجي الشامل لمدينة الرياض، ورؤية المملكة 2030، بالإضافة إلى أولويات الجهات المشاركة بالمرصد التي تشمل القطاع الحكومي والقطاع الخاص والمجتمع المدني. الإنجازات. في مارس 2017 حصل المرصد الحضري بمدينة الرياض على الشهادة الذهبية WCCD ISO 37120 من المجلس العالمي لبيانات المدن في كندا (WCCD).   \n",
       "2  المرصد الحضري لمدينة الرياض ويعرف اختصارًا بمرصد الرياض هو مركز متخصص في وضع نظم مراقبة حضرية لرصد سير عمليات التنمية الحضرية للمدينة، ويهدف إلى فهم الوضع الحالي للمدينة ووضع تصور للاتجاهات المستقبلية، ومراقبة الإنجاز لتحقيق الأهداف واتخاذ القرارات. التأسيس. بدأت أول خطوات إنشاء المرصد في عام 2009م، من الهيئة العليا لتطوير مدينة الرياض؛ ومن ثم أُقرَّ الهيكل التنظيمي للمرصد الحضري الذي يتكون من مجلس ولجنة تنفيذية ومركز. ويترأس مجلس المرصد أمير المنطقة بالإضافة إلى أربعة عشر عضوا، وتتكون اللَّجنة التنفيذية من 15 عضوًا يمثلون أهم مصادر البيانات ذات الصلة بالمؤشرات الحضرية من القطاع الحكومي والقطاع الخاص. المهام. في عام 1434هـ أطلق المرصد الحضري لمدينة الرياض، المؤشرات الحضرية للدورة الأولى التي ضمت (80) مؤشراً، بعد إقرار نتائج تلك المؤشرات في اجتماع الهيئة الثاني لعام 1435هـ، وشملت الحدّ الأدنى من المؤشرات الحضرية العالمية بالإضافة إلى المؤشرات المحلية. يعمل المرصد الحضري لمدينة الرياض على رصد وتقييم اتجاهات التنمية في مدينة الرياض من خلال إنتاج المؤشرات الحضرية التي تقدم معلومات موجزة عن الوضع الراهن والاتجاهات المستقبلية المتوقعة وتقيس مستوى الاستجابة للسياسات والبرامج التنفيذية حسب الأهداف لخطط التنمية المستدامة، ويتم ذلك ضمن إطار رصد عالمي يوفر خطة شاملة للرصد والتقييم ويسهل من عملية تحديد المؤشرات الأساسية ضمن مجموعات معيارية تُمكِّن من مقارنة التقدم مع المدن الأخرى ومؤشرات أخرى تعكس خصوصية مدينة الرياض من خلال تحديد الأولويات والقضايا الهامة في المدينة حسب أهداف المخطط الاستراتيجي الشامل لمدينة الرياض، ورؤية المملكة 2030، بالإضافة إلى أولويات الجهات المشاركة بالمرصد التي تشمل القطاع الحكومي والقطاع الخاص والمجتمع المدني. الإنجازات. في مارس 2017 حصل المرصد الحضري بمدينة الرياض على الشهادة الذهبية WCCD ISO 37120 من المجلس العالمي لبيانات المدن في كندا (WCCD).   \n",
       "3  المرصد الحضري لمدينة الرياض ويعرف اختصارًا بمرصد الرياض هو مركز متخصص في وضع نظم مراقبة حضرية لرصد سير عمليات التنمية الحضرية للمدينة، ويهدف إلى فهم الوضع الحالي للمدينة ووضع تصور للاتجاهات المستقبلية، ومراقبة الإنجاز لتحقيق الأهداف واتخاذ القرارات. التأسيس. بدأت أول خطوات إنشاء المرصد في عام 2009م، من الهيئة العليا لتطوير مدينة الرياض؛ ومن ثم أُقرَّ الهيكل التنظيمي للمرصد الحضري الذي يتكون من مجلس ولجنة تنفيذية ومركز. ويترأس مجلس المرصد أمير المنطقة بالإضافة إلى أربعة عشر عضوا، وتتكون اللَّجنة التنفيذية من 15 عضوًا يمثلون أهم مصادر البيانات ذات الصلة بالمؤشرات الحضرية من القطاع الحكومي والقطاع الخاص. المهام. في عام 1434هـ أطلق المرصد الحضري لمدينة الرياض، المؤشرات الحضرية للدورة الأولى التي ضمت (80) مؤشراً، بعد إقرار نتائج تلك المؤشرات في اجتماع الهيئة الثاني لعام 1435هـ، وشملت الحدّ الأدنى من المؤشرات الحضرية العالمية بالإضافة إلى المؤشرات المحلية. يعمل المرصد الحضري لمدينة الرياض على رصد وتقييم اتجاهات التنمية في مدينة الرياض من خلال إنتاج المؤشرات الحضرية التي تقدم معلومات موجزة عن الوضع الراهن والاتجاهات المستقبلية المتوقعة وتقيس مستوى الاستجابة للسياسات والبرامج التنفيذية حسب الأهداف لخطط التنمية المستدامة، ويتم ذلك ضمن إطار رصد عالمي يوفر خطة شاملة للرصد والتقييم ويسهل من عملية تحديد المؤشرات الأساسية ضمن مجموعات معيارية تُمكِّن من مقارنة التقدم مع المدن الأخرى ومؤشرات أخرى تعكس خصوصية مدينة الرياض من خلال تحديد الأولويات والقضايا الهامة في المدينة حسب أهداف المخطط الاستراتيجي الشامل لمدينة الرياض، ورؤية المملكة 2030، بالإضافة إلى أولويات الجهات المشاركة بالمرصد التي تشمل القطاع الحكومي والقطاع الخاص والمجتمع المدني. الإنجازات. في مارس 2017 حصل المرصد الحضري بمدينة الرياض على الشهادة الذهبية WCCD ISO 37120 من المجلس العالمي لبيانات المدن في كندا (WCCD).   \n",
       "4  المرصد الحضري لمدينة الرياض ويعرف اختصارًا بمرصد الرياض هو مركز متخصص في وضع نظم مراقبة حضرية لرصد سير عمليات التنمية الحضرية للمدينة، ويهدف إلى فهم الوضع الحالي للمدينة ووضع تصور للاتجاهات المستقبلية، ومراقبة الإنجاز لتحقيق الأهداف واتخاذ القرارات. التأسيس. بدأت أول خطوات إنشاء المرصد في عام 2009م، من الهيئة العليا لتطوير مدينة الرياض؛ ومن ثم أُقرَّ الهيكل التنظيمي للمرصد الحضري الذي يتكون من مجلس ولجنة تنفيذية ومركز. ويترأس مجلس المرصد أمير المنطقة بالإضافة إلى أربعة عشر عضوا، وتتكون اللَّجنة التنفيذية من 15 عضوًا يمثلون أهم مصادر البيانات ذات الصلة بالمؤشرات الحضرية من القطاع الحكومي والقطاع الخاص. المهام. في عام 1434هـ أطلق المرصد الحضري لمدينة الرياض، المؤشرات الحضرية للدورة الأولى التي ضمت (80) مؤشراً، بعد إقرار نتائج تلك المؤشرات في اجتماع الهيئة الثاني لعام 1435هـ، وشملت الحدّ الأدنى من المؤشرات الحضرية العالمية بالإضافة إلى المؤشرات المحلية. يعمل المرصد الحضري لمدينة الرياض على رصد وتقييم اتجاهات التنمية في مدينة الرياض من خلال إنتاج المؤشرات الحضرية التي تقدم معلومات موجزة عن الوضع الراهن والاتجاهات المستقبلية المتوقعة وتقيس مستوى الاستجابة للسياسات والبرامج التنفيذية حسب الأهداف لخطط التنمية المستدامة، ويتم ذلك ضمن إطار رصد عالمي يوفر خطة شاملة للرصد والتقييم ويسهل من عملية تحديد المؤشرات الأساسية ضمن مجموعات معيارية تُمكِّن من مقارنة التقدم مع المدن الأخرى ومؤشرات أخرى تعكس خصوصية مدينة الرياض من خلال تحديد الأولويات والقضايا الهامة في المدينة حسب أهداف المخطط الاستراتيجي الشامل لمدينة الرياض، ورؤية المملكة 2030، بالإضافة إلى أولويات الجهات المشاركة بالمرصد التي تشمل القطاع الحكومي والقطاع الخاص والمجتمع المدني. الإنجازات. في مارس 2017 حصل المرصد الحضري بمدينة الرياض على الشهادة الذهبية WCCD ISO 37120 من المجلس العالمي لبيانات المدن في كندا (WCCD).   \n",
       "\n",
       "                                                          question  \\\n",
       "0                       من الذي يترأس المرصد الحضري لمدينة الرياض؟   \n",
       "1  ما هي الإنجازات البارزة التي حققها المرصد الحضري بمدينة الرياض؟   \n",
       "2                               ما هو المرصد الحضري لمدينة الرياض؟   \n",
       "3                      ما هو الهدف من المرصد الحضري لمدينة الرياض؟   \n",
       "4                          ما هي مهام المرصد الحضري لمدينة الرياض؟   \n",
       "\n",
       "                                                                                                                      ground_truth  \n",
       "0                                                                      يترأس مجلس المرصد أمير المنطقة بالإضافة إلى أربعة عشر عضوا،  \n",
       "1   في مارس 2017 حصل المرصد الحضري بمدينة الرياض على الشهادة الذهبية WCCD ISO 37120 من المجلس العالمي لبيانات المدن في كندا (WCCD)  \n",
       "2                                                   هو مركز متخصص في وضع نظم مراقبة حضرية لرصد سير عمليات التنمية الحضرية للمدينة،  \n",
       "3                                                                يهدف إلى فهم الوضع الحالي للمدينة ووضع تصور للاتجاهات المستقبلية،  \n",
       "4                                                                                  ومراقبة الإنجاز لتحقيق الأهداف واتخاذ القرارات.  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def flatten_arabica_mrc(dataset):\n",
    "    rows = []\n",
    "\n",
    "    for item in dataset:\n",
    "        for para in item[\"paragraphs\"]:\n",
    "            context = para[\"context\"]\n",
    "            for qa in para[\"qas\"]:\n",
    "                question = qa[\"question\"]\n",
    "                answers = qa[\"answers\"]\n",
    "                # Most have exactly 1 answer\n",
    "                gt_answer = answers[0][\"text\"] if len(answers) > 0 else \"\"\n",
    "\n",
    "                rows.append({\n",
    "                    \"context\": context,\n",
    "                    \"question\": question,\n",
    "                    \"ground_truth\": gt_answer\n",
    "                })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "df_test = flatten_arabica_mrc(test_ds)\n",
    "df_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bec44903-dc65-4e6e-b3f9-10afeb90f469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13970, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bdc6975-5a54-4004-a12c-572dedca968a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Shuffle the dataset safely\n",
    "df_shuffled = df_test.sample(frac=1, random_state=42)\n",
    "\n",
    "# Take a representative sample\n",
    "df_sample = df_shuffled.head(1000)\n",
    "\n",
    "df_sample.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d45d76b-ac44-45dd-82d3-9842bb9f499d",
   "metadata": {},
   "source": [
    "## Deduplicate contexts → build RAG documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c7b0ac5-7468-441d-90ff-cd04da08219f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a list of unique contexts (documents)\n",
    "unique_contexts = df_sample[\"context\"].drop_duplicates().tolist()\n",
    "\n",
    "len(unique_contexts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7fe25c2-f691-4d57-bbef-a079c89ec34c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "السيخية (بالبنجابيَّة: ਸਿੱਖੀ) هي ديانة توحيدية دارميَّة نشأت في شمالي الهند في نهاية القرن الخامس عشر. وتأتي كلمة «سيخية» من كلمة «سيخ» وهي بدورها تأتي من الجذر السنسكريتي التي تعني التلميذ و في اللغة البالية المريد أو التابع. وهي واحدة من أحدث الأديان الرئيسية في العالم، وهي واحدة من أكبر الديانات في العالم. وتتضمن المعتقدات الأساسية للسيخية، والتي وضِحَت في كتابهم المقدس جورو جرانث صاحب، الإيمان والتأمل في اسم الخالق الواحد، والوحدة الإلهية والمساواة للبشرية جمعاء، والانخراط في خدمة نكران الذات، والسعي لتحقيق العدالة لمصلحة الجميع وازدهارها، وإتباع سلوك معيشة صادق. وفي أوائل القرن الواحد والعشرين كان هناك حوالي 25 مليون سيخي في جميع أنحاء العالم، وتعيش الغالبية العظمى أو 76% (20 مليون) من السيخ في البنجاب، موطن السيخ في شمال غرب الهند، ويعيش حوالي مليوني في الدول الهندية المجاورة، والتي كانت جزءاً من ولاية البنجاب الهندية سابقاً. وسبب انتشارها في العالم هو اعتماد الإنجليز عليهم في بعض الحروب وهجرات السيخ خارج بلادهم، حيث بدأت الهجرة السيخية من الهند البريطانية خلال النصف الثاني من القرن التاسع عشر، عندما أكمل البريطانيون ضمهم للبنجاب.\n",
      "تستند السيخية على التعاليم الروحية لمؤسس الديانة وهو الغورو ناناك، وخلفائه التسعة من الغورو البشر. لقب غورو يعني بالهندية المعلم. أما الغورو غورو جوبيند سينغ الملقب بالعاشر، ساهم في الكثير من أجل السيخية، وكان إسهامه في الإضفاء المستمر للطابع الرسمي على الديانة التي أسسها أولًا الغورو السيخ ناناك ديف جي في القرن الخامس عشر إسهامًا جديرًا بالملاحظة. وسمى الكتاب المقدس للسيخ جورو جرانث صاحب كخليفة له، وبالتالي أنهى خط الغورو البشر وجعل ن الكتاب المقدس للسيخ جورو جرانث صاحب الدليل الروحي الديني والدينوي للسيخ. وترفض الديانة السيخية الادعاءات بأن أي تقليد ديني معين له احتكار للحقيقة المطلقة. وتطورت السيخية في أوقات الاضطهاد الديني. حيث تعرض اثنان من أتباع السيخ وهم الغورو أرجان والغورو تيج بهادور للتعذيب وأعدم من قبل حكام المغول بعد رفضهم اعتناق الإسلام. وأثار اضطهاد السيخ تأسيس الخالسا كطلب لحماية حرية الضمير والدين.\n",
      "التاريخ.\n",
      "يرتبط تاريخ السيخية ارتباطًا وثيقًا بتاريخ منطقة البنجاب والوضع الاجتماعي السياسي في شمال غرب شبه القارة الهندية في القرن السادس عشر. منذ الحكم المغولي للهند على يد الإمبراطور جهانكير (1605-1707)، كانت السيخية في صراع مع قوانين إمبراطورية المغول، لأنها كانت تؤثر في التعاقب السياسي للمغول في حين تعتز بالأولياء من الإسلام. قُتل العديد من السيخ البارزين على يد حكام المغول لرفضهم الانصياع لأوامرهم، ومعارضتهم لاضطهاد السيخ. من مجموع 10 من الغورو السيخ، عُذب وأُعدم اثنان من المعلمين أنفسهم (الغورو أرجان والغورو تيج بهادور)، وأقرباء مقربين للعديد من الغورو السيخ قُتلو بوحشية دون رحمة (مثل أبناء الغورو جوبيند سينغ البالغين من العمر 6 و9 سنوات)، إلى جانب العديد من الشخصيات الرئيسية الأخرى السيخية التي عُذبت وقُتلت (مثل باندا بهادور، بهاي ماتي داس، بهاي ساتي داس وباهاي ديالا)، على يد الحكام المغول المتجبرين لرفضهم الخضوع لأوامرهم، ومعارضتهم لاضطهاد السيخ والهندوس. بعد ذلك، عسكرت السيخية لمعارضة هيمنة المغول على أرضهم.\n",
      "تميّز ظهور الكونفدرالية السيخية تحت حكم الأمراء والسيخ تحت حكم المهراجا رانجيت سينغ بالتسامح الديني والتعايش السلمي والتعددية مع المسيحيين والمسلمين والهندوس في مواقع السلطة. يعد تأسيس إمبراطورية السيخ عادةً ذروة السيخية على المستوى السياسي، خلال هذه الفترة جاءت إمبراطورية السيخ لتشمل كشمير (أقصى شمال شبه القارة الهندية)، ولداخ (إقليم اتحادي تديره الهند)، وبيشاور (هي عاصمة مقاطعة خيبر بختونخوا الباكستانية وأكبر مدنها). اعتنق عدد من الفلاحين المسلمين والهندوس السيخية. أخذ هاري سينغ نالوا، القائد العام لجيش السيخ على طول الحدود الشمالية الغربية، حدود إمبراطورية السيخ إلى مصب ممر خيبر (هو ممر جبلي في شمال غرب باكستان، على الحدود مع أفغانستان). دمجت الإدارة العلمانية لإمبراطورية السيخ إصلاحات عسكرية واقتصادية وحكومية مبتكرة.\n",
      "شهدت الأشهر التي سبقت تقسيم الهند (تقسيم الهند البريطانية إلى دولتين مستقلتين، الهند وباكستان) سنة 1947، صراعًا حادًا في البنجاب (منطقة جيوسياسية وثقافية وتاريخية في جنوب آسيا، تحديدًا شمال شبه القارة الهندية، وتضم مناطق في شرق باكستان وشمال الهند) بين السيخ والمسلمين، شهد الهجرة الدينية الفعالة للسيخ البنجاب والهندوس من البنجاب الغربية مقابل هجرة دينية مماثلة للمسلمين البنجاب في شرق البنجاب. في الوقت الحاضر، يعيش غالبية السيخ في ولاية البنجاب في الهند.\n",
      "الخمسة كاكارس أو الكافات الخمسة.\n",
      "الخمسة كافات هم يصرون على الألتزام بها وعندهم من لا يلتزم بالكافات الخمس يصفوه بصفة باتت patitأي المرتد، ومن يدخل السيخية جديد يجعلوه يتعود عليها ويسموه المتكيف البطئ.\n",
      "الغورو السيخ.\n",
      "الغورو كلمة تعني المعلم وهم عشرة غورو للسيخية وهم:\n",
      "\n",
      "---------------------------------------\n",
      "صيفنا الحبيب (هانغل: 그 해 우리는)؛ هو مسلسل تلفزيوني رومانسي كوميدي كوري جنوبي، يصنف بأنه «أول مشروع أصلي لي إستوديو إن». من بطولة وكيم دامي، عرض على SBS TV من 6 ديسمبر 2021 إلى 25 يناير 2022، بث كل يوم الإثنين والثلاثاء الساعة 22:00 بتوقيت (KST). وهو متاحًا أيضًا على نتفليكس. القصة. انفصل الثنائي تشوي وونغ (تشوي وو شيك) ويون سو (كيم دامي) قبل 10 سنوات، لكن يصبح الفيلم الوثائقي الذي صوروه خلال أيام دراستهما الثانوية شائعًا، بسببه عليهما الوقوف أمام الكاميرا مجددا، على رغم انهم لايريدون ذلك. طاقم. الشخصيات الرئيسية. رسام تشكيلي حر مفعم بالحيوية. خبيرة علاقات عامة وواقعية. مخرج وثائقي، وهو كان المسؤول عن إنتاج الفيلم الوثائقي لي تشوي وونغ وايون سو. أيدول مشهورة تحتفظ بالمركز الأول منذ ظهورها. الإنتاج. صناعة. تم إنشاء المشروع بواسطة إستوديو إن، وهي أول دراما أصلية لهم، سيتم إنتاج المسلسل بتعاون مع شركة سوبر مون بيكتشرز، بتنسيق مع المقر الرئيسي للإنتاج والتخطيط الدرامي التابع لإس بي إس المعروف بـ «إستوديو إس». طاقم. في مارس 2021، أعلن تأكيد انضمام كل من تشوي وو شيك وكيم دا مي في المسلسل التلفزيوني، يجمع المسلسل بهم بعد ثلاث سنوات، آخر مرة ظهروا فيه في معا بفيلم الغموض \"\" لعام 2018. تم تأكيد اختيار الطاقم الشبابي في 8 يوليو. التصوير. بدأ تصوير المسلسل في أوائل يوليو 2021. طبعة أخرى. سيتم أيضًا إنتاج ويب تون من «صيفنا الحبيب»، الويب تون هو عبارة عن مقدمة عن أيام المدرسة الثانوية للشخصيتين الرئيسيتين في المسلسل التلفزيوني (تشوي وانغ وايون سوو)، ومن المقرر أن يتم إصداره على «نايفر ويبتوون» هذا العام. هي ناشر ومنصة على الويب أطلقته شركة نافير في كوريا الجنوبية في عام 2004.\n",
      "---------------------------------------\n",
      "\"العنف ضد كبار السن\" هو مصطلح يشير إلى السلوك العدواني والعنيف ضد كبار السن والذي من شأنه أن يسبب لهم العديد من الأضرار على المستويين النفسي والجسدي. قد يتم العنف ضد كبار السن في أي مكانً كان وعلى يدي أي شخص فهو لا ينطوي على شكل أو سبب واحد وهو يعتبر ظاهرة عالمية واسعة الانتشار ومن القضايا المجتمعية الرئيسية والتي تُقلِق المحاكم الدولية والمجتمعية وتدفعها باستمرار للبحث عن طرق للحفاظ على حقوق هؤلاء المُسنين وحمايتهم منه. كبار السن حسب تعريف دولة اسرائيل هم الأشخاص الذي يتجاوز عمرهم ال 65 سنة وهم أشخاص يحصلون على امتيازات وحماية مكثفة في اسرائيل وذلك بحسب التعديل رقم 26 لقانون العقوبات وهو قانون حماية القاصرين والعاجزين كما ويعود ذلك لضعفهم ولكثرة احتياجاتهم والتحديات التي يواجهها قسم كبير منهم. في دولة اسرائيل يتم التفريق بين مصطلح \"العنف ضد كبار السن\" وبين مصطلح \"إساءة وإهمال كبار السن\" حيث أنه وعلى الرغم من أن الإساءة لكبار السن قد تضمن العنف إلا أنها عادة ما تحدث من شخص مقرب لكبير السن مثل الأقرباء والأشخاص المخصصين لرعايتهم وتستمر لفترة وهو ضمن مجال عمل وزارة الرفاه والضمان الاجتماعي، على عكس مصطلح العنف ضد كبار السن والذي يدل على حادث الذي فيه يتم التهجم على شخص كبير بالسن من قبل شخص غريب ويحدث ذلك لمرة واحدة ويكون ضمن مجال عمل الشرطة. من الجدير بالذكر أن دولة إسرائيل تقوم باتخاذ الإجراءات اللازمة في كلتا الحالتين، سواء كانت إساءة او عنف، بهدف الحد من ظاهرة العنف ضد كبار السن. إحصائيات العنف ضد كبار السن. حسب التقرير الذي أصدرته الكنيست عام 2007 والذي يعرض ظاهرة العنف ضد كبار السن فأنه وفقًا للإحصائيات التي أجريت في نهاية سنة 2006 عاش ما يقارب ال 70،000 مُسن في اسرائيل وهذا يعادل 10% من إجمالي السكان، 30% منهم هم ناجون من المحرقة اليهودية او الهولوكوست كما ان حوالي 12،000 من كبار السن يعيشون مع شخص واحد على الأقل لا تربطه معهم صلة دم (عادة ما يكون هذا الشخص معالج او مرافق للاعتناء بهم). مراكز الشرطة تتلقى عدد هائل من البلاغات وفتحت ما يقارب 12,228 ملف يتعلق بالعنف والجرائم ضد كبار السن من عام 2002 حتى الرابع من سبتمبر عام 2007 (هذه الملفات تتضمن القتل، محاولات القتل، الجرائم الجنسية والاغتصاب، جرائم السرقة والسطو على البيوت كما وتتضمن الاعتداء والتخريب) هذا العدد من الشكاوي والملفات لا يتضمن أولئك الذين وصلوا إلى الحرس المدني وغيرها من الأقسام. بحسب الاحصائيات فإن: 32% من هذه الشكاوى هي بلاغات عن السطو على بيوتهم، 17% هي عن تهديدات تلقوها، 31% عن سرقات تعرضوا لها بينما 11% هي فقط اعتداءات جسدية. بشكل عام في تلك السنوات (2002-2007) كان يقدم كبار السن القادمون جديدًا للدولة (المهاجرون) حوالي 9% من الشكاوى رغم أن نسبتهم من السكان لا تتعدى 25% بينما المسنين العرب كانوا يقدمون 5% من البلاغات. وفقًا لوزارة الرفاه والضمان الاجتماعي إن لجائحة كورونا أثرًا سلبيًا على ظاهرة العنف ضد كبار السن فقد لوحظ ارتفاع في الحالات التي تم فيها تعنيف كبار السن (معظمها تمت من قبل أفراد العائلة ومقدمي الرعاية) فعلى سبيل المثال في عام 2018 تم علاج 6707 حالة بينما حتى منتصف عام 2019 فقط تم علاج أكثر من 7000 حالة وهذا عدا عن الحالات التي\n"
     ]
    }
   ],
   "source": [
    "print(unique_contexts[0])\n",
    "print(\"---------------------------------------\")\n",
    "print(unique_contexts[1])\n",
    "print(\"---------------------------------------\")\n",
    "print(unique_contexts[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cb6222-36d2-4047-b5f5-9daa08a12aea",
   "metadata": {},
   "source": [
    "## Build the Vector Index (Embedding + Index + QueryEngine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ccd678e-0a50-4da5-8f00-ca085e808f8b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AZhaa\\anaconda3\\envs\\nlp_gpu\\python.exe\n",
      "Name: llama-index\n",
      "Version: 0.14.8\n",
      "Summary: Interface between LLMs and your data\n",
      "Home-page: https://llamaindex.ai\n",
      "Author: \n",
      "Author-email: Jerry Liu <jerry@llamaindex.ai>\n",
      "License-Expression: MIT\n",
      "Location: c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\n",
      "Requires: llama-index-cli, llama-index-core, llama-index-embeddings-openai, llama-index-indices-managed-llama-cloud, llama-index-llms-openai, llama-index-readers-file, llama-index-readers-llama-parse, nltk\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "%pip show llama-index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87089d87-3767-44ab-969a-3b15a4d7301a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-embeddings-huggingface>=0.1.4\n",
      "  Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl.metadata (458 bytes)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface>=0.1.4) (0.36.0)\n",
      "Requirement already satisfied: llama-index-core<0.15,>=0.13.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-embeddings-huggingface>=0.1.4) (0.14.8)\n",
      "Collecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface>=0.1.4)\n",
      "  Downloading sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (3.13.2)\n",
      "Requirement already satisfied: aiosqlite in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (2025.10.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (0.27.2)\n",
      "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (2.11.3)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (3.9.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (2.0.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (11.1.0)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (4.5.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (2.12.4)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (2.0.44)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (0.12.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (4.15.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (1.17.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (1.22.0)\n",
      "Requirement already satisfied: griffe in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (1.15.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (3.1.6)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (0.4.6)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (3.11)\n",
      "Requirement already satisfied: filelock in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface>=0.1.4) (3.20.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface>=0.1.4) (25.0)\n",
      "Requirement already satisfied: click in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (8.3.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (2025.11.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (2025.11.12)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface>=0.1.4) (4.57.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface>=0.1.4) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface>=0.1.4) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface>=0.1.4) (1.15.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface>=0.1.4) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface>=0.1.4) (0.7.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (3.2.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface>=0.1.4) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface>=0.1.4) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from dataclasses-json->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (3.26.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (1.0.9)\n",
      "Requirement already satisfied: sniffio in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from anyio->httpx->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface>=0.1.4) (3.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface>=0.1.4) (3.6.0)\n",
      "Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl (8.9 kB)\n",
      "Downloading sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Installing collected packages: sentence-transformers, llama-index-embeddings-huggingface\n",
      "\n",
      "   ---------------------------------------- 0/2 [sentence-transformers]\n",
      "   ---------------------------------------- 0/2 [sentence-transformers]\n",
      "   ---------------------------------------- 0/2 [sentence-transformers]\n",
      "   ---------------------------------------- 0/2 [sentence-transformers]\n",
      "   ---------------------------------------- 0/2 [sentence-transformers]\n",
      "   ---------------------------------------- 0/2 [sentence-transformers]\n",
      "   ---------------------------------------- 0/2 [sentence-transformers]\n",
      "   ---------------------------------------- 0/2 [sentence-transformers]\n",
      "   ----------------------------------- 2/2 [llama-index-embeddings-huggingface]\n",
      "\n",
      "Successfully installed llama-index-embeddings-huggingface-0.6.1 sentence-transformers-5.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install \"llama-index-embeddings-huggingface>=0.1.4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0e3196d-c152-42ad-affa-04013215c992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test embedding length: 384\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "import torch\n",
    "from llama_index.core import Settings\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "test_vec = embed_model.get_text_embedding(\"hello world\")\n",
    "print(\"Test embedding length:\", len(test_vec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a24268-8d8d-44cb-b217-1a446e6955c8",
   "metadata": {},
   "source": [
    "## Create LlamaIndex Documents from ArabicaQA contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83376434-f1a4-4bac-8926-ce45c610cfa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "documents = [Document(text=c) for c in unique_contexts]\n",
    "len(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f2d9cb-9ae2-4d16-91bc-4f0d7cea730a",
   "metadata": {},
   "source": [
    "## Build the RAG Vector Store using HuggingFace Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc0c4b83-e6fb-4890-ad75-583c29897de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings, VectorStoreIndex\n",
    "from llama_index.core import Document\n",
    "\n",
    "def build_query_engine(documents):\n",
    "\n",
    "    # reset old config\n",
    "    Settings.llm = llm\n",
    "    Settings.embed_model = embed_model\n",
    "    Settings.callback_manager = None\n",
    "\n",
    "    # create the index\n",
    "    vector_index = VectorStoreIndex.from_documents(\n",
    "        documents,\n",
    "        embed_model=embed_model\n",
    "    )\n",
    "\n",
    "    # query engine\n",
    "    query_engine = vector_index.as_query_engine(similarity_top_k=2)\n",
    "\n",
    "    return query_engine\n",
    "\n",
    "query_engine = build_query_engine(documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231aa3d0-4401-4687-a3b0-5391f80a6764",
   "metadata": {},
   "source": [
    "## Generate model answers for the test questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4ea4e59-9933-4efd-ad03-fc95fe099dd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m df_sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mquery_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m         model_answers\u001b[38;5;241m.\u001b[39mappend(response\u001b[38;5;241m.\u001b[39mresponse)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:335\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    332\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    337\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    338\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\llama_index\\core\\base\\base_query_engine.py:44\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[1;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     43\u001b[0m         str_or_query_bundle \u001b[38;5;241m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[1;32m---> 44\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m     46\u001b[0m     QueryEndEvent(query\u001b[38;5;241m=\u001b[39mstr_or_query_bundle, response\u001b[38;5;241m=\u001b[39mquery_result)\n\u001b[0;32m     47\u001b[0m )\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:335\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    332\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    337\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    338\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\llama_index\\core\\query_engine\\retriever_query_engine.py:197\u001b[0m, in \u001b[0;36mRetrieverQueryEngine._query\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    194\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mQUERY, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str}\n\u001b[0;32m    195\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m query_event:\n\u001b[0;32m    196\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve(query_bundle)\n\u001b[1;32m--> 197\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_response_synthesizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthesize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_bundle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     query_event\u001b[38;5;241m.\u001b[39mon_end(payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mRESPONSE: response})\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:335\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    332\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    337\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    338\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\llama_index\\core\\response_synthesizers\\base.py:235\u001b[0m, in \u001b[0;36mBaseSynthesizer.synthesize\u001b[1;34m(self, query, nodes, additional_source_nodes, **response_kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m     query \u001b[38;5;241m=\u001b[39m QueryBundle(query_str\u001b[38;5;241m=\u001b[39mquery)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    232\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mSYNTHESIZE,\n\u001b[0;32m    233\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query\u001b[38;5;241m.\u001b[39mquery_str},\n\u001b[0;32m    234\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[1;32m--> 235\u001b[0m     response_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_response(\n\u001b[0;32m    236\u001b[0m         query_str\u001b[38;5;241m=\u001b[39mquery\u001b[38;5;241m.\u001b[39mquery_str,\n\u001b[0;32m    237\u001b[0m         text_chunks\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m    238\u001b[0m             n\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mget_content(metadata_mode\u001b[38;5;241m=\u001b[39mMetadataMode\u001b[38;5;241m.\u001b[39mLLM) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m nodes\n\u001b[0;32m    239\u001b[0m         ],\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs,\n\u001b[0;32m    241\u001b[0m     )\n\u001b[0;32m    243\u001b[0m     additional_source_nodes \u001b[38;5;241m=\u001b[39m additional_source_nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[0;32m    244\u001b[0m     source_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(nodes) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(additional_source_nodes)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:335\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    332\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    337\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    338\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\llama_index\\core\\response_synthesizers\\compact_and_refine.py:43\u001b[0m, in \u001b[0;36mCompactAndRefine.get_response\u001b[1;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# use prompt helper to fix compact text_chunks under the prompt limitation\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# TODO: This is a temporary fix - reason it's temporary is that\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# the refine template does not account for size of previous answer.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m new_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_compact_text_chunks(query_str, text_chunks)\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mget_response(\n\u001b[0;32m     44\u001b[0m     query_str\u001b[38;5;241m=\u001b[39mquery_str,\n\u001b[0;32m     45\u001b[0m     text_chunks\u001b[38;5;241m=\u001b[39mnew_texts,\n\u001b[0;32m     46\u001b[0m     prev_response\u001b[38;5;241m=\u001b[39mprev_response,\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs,\n\u001b[0;32m     48\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:335\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    332\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    337\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    338\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\llama_index\\core\\response_synthesizers\\refine.py:179\u001b[0m, in \u001b[0;36mRefine.get_response\u001b[1;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text_chunk \u001b[38;5;129;01min\u001b[39;00m text_chunks:\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prev_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;66;03m# if this is the first chunk, and text chunk already\u001b[39;00m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;66;03m# is an answer, then return it\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_give_response_single(\n\u001b[0;32m    180\u001b[0m             query_str, text_chunk, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs\n\u001b[0;32m    181\u001b[0m         )\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;66;03m# refine response if possible\u001b[39;00m\n\u001b[0;32m    184\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refine_response_single(\n\u001b[0;32m    185\u001b[0m             prev_response, query_str, text_chunk, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs\n\u001b[0;32m    186\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\llama_index\\core\\response_synthesizers\\refine.py:241\u001b[0m, in \u001b[0;36mRefine._give_response_single\u001b[1;34m(self, query_str, text_chunk, **response_kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_streaming:\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m         structured_response \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m    240\u001b[0m             StructuredRefineResponse,\n\u001b[1;32m--> 241\u001b[0m             program(\n\u001b[0;32m    242\u001b[0m                 context_str\u001b[38;5;241m=\u001b[39mcur_text_chunk,\n\u001b[0;32m    243\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs,\n\u001b[0;32m    244\u001b[0m             ),\n\u001b[0;32m    245\u001b[0m         )\n\u001b[0;32m    246\u001b[0m         query_satisfied \u001b[38;5;241m=\u001b[39m structured_response\u001b[38;5;241m.\u001b[39mquery_satisfied\n\u001b[0;32m    247\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m query_satisfied:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:335\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    332\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    337\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    338\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\llama_index\\core\\response_synthesizers\\refine.py:85\u001b[0m, in \u001b[0;36mDefaultRefineProgram.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m     83\u001b[0m         answer \u001b[38;5;241m=\u001b[39m answer\u001b[38;5;241m.\u001b[39mmodel_dump_json()\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prompt,\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[0;32m     88\u001b[0m     )\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m StructuredRefineResponse(answer\u001b[38;5;241m=\u001b[39manswer, query_satisfied\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:335\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    332\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    337\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    338\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\llama_index\\core\\llms\\llm.py:627\u001b[0m, in \u001b[0;36mLLM.predict\u001b[1;34m(self, prompt, **prompt_args)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     formatted_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_prompt(prompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprompt_args)\n\u001b[1;32m--> 627\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatted_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    628\u001b[0m     output \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    629\u001b[0m parsed_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_output(output)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:335\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    332\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    337\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    338\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\llama_index\\core\\llms\\callbacks.py:435\u001b[0m, in \u001b[0;36mllm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict\u001b[1;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    426\u001b[0m event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[0;32m    427\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[0;32m    428\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    432\u001b[0m     },\n\u001b[0;32m    433\u001b[0m )\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 435\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m f(_self, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    437\u001b[0m     callback_manager\u001b[38;5;241m.\u001b[39mon_event_end(\n\u001b[0;32m    438\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[0;32m    439\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mEXCEPTION: e},\n\u001b[0;32m    440\u001b[0m         event_id\u001b[38;5;241m=\u001b[39mevent_id,\n\u001b[0;32m    441\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\llama_index\\llms\\huggingface\\base.py:339\u001b[0m, in \u001b[0;36mHuggingFaceLLM.complete\u001b[1;34m(self, prompt, formatted, **kwargs)\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[0;32m    337\u001b[0m         inputs\u001b[38;5;241m.\u001b[39mpop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 339\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[0;32m    341\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_new_tokens,\n\u001b[0;32m    342\u001b[0m     stopping_criteria\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping_criteria,\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_kwargs,\n\u001b[0;32m    344\u001b[0m )\n\u001b[0;32m    345\u001b[0m completion_tokens \u001b[38;5;241m=\u001b[39m tokens[\u001b[38;5;241m0\u001b[39m][inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) :]\n\u001b[0;32m    346\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mdecode(completion_tokens, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\transformers\\generation\\utils.py:2564\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[0;32m   2561\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m generation_config\u001b[38;5;241m.\u001b[39muse_cache\n\u001b[0;32m   2563\u001b[0m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[1;32m-> 2564\u001b[0m result \u001b[38;5;241m=\u001b[39m decoding_method(\n\u001b[0;32m   2565\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2566\u001b[0m     input_ids,\n\u001b[0;32m   2567\u001b[0m     logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2568\u001b[0m     stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2569\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2570\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgeneration_mode_kwargs,\n\u001b[0;32m   2571\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2572\u001b[0m )\n\u001b[0;32m   2574\u001b[0m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[0;32m   2575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2576\u001b[0m     generation_config\u001b[38;5;241m.\u001b[39mreturn_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2577\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result\u001b[38;5;241m.\u001b[39mpast_key_values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_legacy_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2579\u001b[0m ):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\transformers\\generation\\utils.py:2784\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   2781\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[1;32m-> 2784\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2785\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2786\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\transformers\\utils\\generic.py:918\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict_passed\n\u001b[1;32m--> 918\u001b[0m output \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    920\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\transformers\\models\\qwen2\\modeling_qwen2.py:449\u001b[0m, in \u001b[0;36mQwen2ForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Unpack[TransformersKwargs],\n\u001b[0;32m    431\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CausalLMOutputWithPast:\n\u001b[0;32m    432\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;124;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m    ```\"\"\"\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m     outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[0;32m    450\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    451\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    452\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    453\u001b[0m         past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    454\u001b[0m         inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m    455\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    456\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m    457\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    458\u001b[0m     )\n\u001b[0;32m    460\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\transformers\\utils\\generic.py:1064\u001b[0m, in \u001b[0;36mcheck_model_inputs.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1061\u001b[0m                 monkey_patched_layers\u001b[38;5;241m.\u001b[39mappend((module, original_forward))\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1064\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m     kwargs_without_recordable \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\transformers\\models\\qwen2\\modeling_qwen2.py:384\u001b[0m, in \u001b[0;36mQwen2Model.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_emb(hidden_states, position_ids)\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers]:\n\u001b[1;32m--> 384\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[0;32m    385\u001b[0m         hidden_states,\n\u001b[0;32m    386\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcausal_mask_mapping[decoder_layer\u001b[38;5;241m.\u001b[39mattention_type],\n\u001b[0;32m    387\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    388\u001b[0m         past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    389\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    390\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m    391\u001b[0m         position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[0;32m    392\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    393\u001b[0m     )\n\u001b[0;32m    395\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(hidden_states)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[0;32m    397\u001b[0m     last_hidden_state\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[0;32m    398\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    399\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning_once(message)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\transformers\\models\\qwen2\\modeling_qwen2.py:249\u001b[0m, in \u001b[0;36mQwen2DecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    247\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m    248\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[1;32m--> 249\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\transformers\\models\\qwen2\\modeling_qwen2.py:46\u001b[0m, in \u001b[0;36mQwen2MLP.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 46\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdown_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_answers = []\n",
    "\n",
    "for q in df_sample[\"question\"]:\n",
    "    try:\n",
    "        response = query_engine.query(q)\n",
    "        model_answers.append(response.response)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        model_answers.append(\"\")\n",
    "\n",
    "# Add model answers to dataframe\n",
    "df_sample[\"model_answer\"] = model_answers\n",
    "\n",
    "df_sample.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "258a8a22-62cb-4ace-9b1a-b118dcd2a78d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>model_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>السيخية (بالبنجابيَّة: ਸਿੱਖੀ) هي ديانة توحيدية دارميَّة نشأت في شمالي الهند في نهاية القرن الخامس عشر. وتأتي كلمة «سيخية» من كلمة «سيخ» وهي بدورها تأتي من الجذر السنسكريتي التي تعني التلميذ و في اللغة البالية المريد أو التابع. وهي واحدة من أحدث الأديان الرئيسية في العالم، وهي واحدة من أكبر الديانات في العالم. وتتضمن المعتقدات الأساسية للسيخية، والتي وضِحَت في كتابهم المقدس جورو جرانث صاحب، الإيمان والتأمل في اسم الخالق الواحد، والوحدة الإلهية والمساواة للبشرية جمعاء، والانخراط في خدمة نكران الذات، والسعي لتحقيق العدالة لمصلحة الجميع وازدهارها، وإتباع سلوك معيشة صادق. وفي أوائل القرن الواحد والعشرين كان هناك حوالي 25 مليون سيخي في جميع أنحاء العالم، وتعيش الغالبية العظمى أو 76% (20 مليون) من السيخ في البنجاب، موطن السيخ في شمال غرب الهند، ويعيش حوالي مليوني في الدول الهندية المجاورة، والتي كانت جزءاً من ولاية البنجاب الهندية سابقاً. وسبب انتشارها في العالم هو اعتماد الإنجليز عليهم في بعض الحروب وهجرات السيخ خارج بلادهم، حيث بدأت الهجرة السيخية من الهند البريطانية خلال النصف الثاني من القرن التاسع عشر، عندما أكمل البريطانيون ضمهم للبنجاب.\\nتستند السيخية على التعاليم الروحية لمؤسس الديانة وهو الغورو ناناك، وخلفائه التسعة من الغورو البشر. لقب غورو يعني بالهندية المعلم. أما الغورو غورو جوبيند سينغ الملقب بالعاشر، ساهم في الكثير من أجل السيخية، وكان إسهامه في الإضفاء المستمر للطابع الرسمي على الديانة التي أسسها أولًا الغورو السيخ ناناك ديف جي في القرن الخامس عشر إسهامًا جديرًا بالملاحظة. وسمى الكتاب المقدس للسيخ جورو جرانث صاحب كخليفة له، وبالتالي أنهى خط الغورو البشر وجعل ن الكتاب المقدس للسيخ جورو جرانث صاحب الدليل الروحي الديني والدينوي للسيخ. وترفض الديانة السيخية الادعاءات بأن أي تقليد ديني معين له احتكار للحقيقة المطلقة. وتطورت السيخية في أوقات الاضطهاد الديني. حيث تعرض اثنان من أتباع السيخ وهم الغورو أرجان والغورو تيج بهادور للتعذيب وأعدم من قبل حكام المغول بعد رفضهم اعتناق الإسلام. وأثار اضطهاد السيخ تأسيس الخالسا كطلب لحماية حرية الضمير والدين.\\nالتاريخ.\\nيرتبط تاريخ السيخية ارتباطًا وثيقًا بتاريخ منطقة البنجاب والوضع الاجتماعي السياسي في شمال غرب شبه القارة الهندية في القرن السادس عشر. منذ الحكم المغولي للهند على يد الإمبراطور جهانكير (1605-1707)، كانت السيخية في صراع مع قوانين إمبراطورية المغول، لأنها كانت تؤثر في التعاقب السياسي للمغول في حين تعتز بالأولياء من الإسلام. قُتل العديد من السيخ البارزين على يد حكام المغول لرفضهم الانصياع لأوامرهم، ومعارضتهم لاضطهاد السيخ. من مجموع 10 من الغورو السيخ، عُذب وأُعدم اثنان من المعلمين أنفسهم (الغورو أرجان والغورو تيج بهادور)، وأقرباء مقربين للعديد من الغورو السيخ قُتلو بوحشية دون رحمة (مثل أبناء الغورو جوبيند سينغ البالغين من العمر 6 و9 سنوات)، إلى جانب العديد من الشخصيات الرئيسية الأخرى السيخية التي عُذبت وقُتلت (مثل باندا بهادور، بهاي ماتي داس، بهاي ساتي داس وباهاي ديالا)، على يد الحكام المغول المتجبرين لرفضهم الخضوع لأوامرهم، ومعارضتهم لاضطهاد السيخ والهندوس. بعد ذلك، عسكرت السيخية لمعارضة هيمنة المغول على أرضهم.\\nتميّز ظهور الكونفدرالية السيخية تحت حكم الأمراء والسيخ تحت حكم المهراجا رانجيت سينغ بالتسامح الديني والتعايش السلمي والتعددية مع المسيحيين والمسلمين والهندوس في مواقع السلطة. يعد تأسيس إمبراطورية السيخ عادةً ذروة السيخية على المستوى السياسي، خلال هذه الفترة جاءت إمبراطورية السيخ لتشمل كشمير (أقصى شمال شبه القارة الهندية)، ولداخ (إقليم اتحادي تديره الهند)، وبيشاور (هي عاصمة مقاطعة خيبر بختونخوا الباكستانية وأكبر مدنها). اعتنق عدد من الفلاحين المسلمين والهندوس السيخية. أخذ هاري سينغ نالوا، القائد العام لجيش السيخ على طول الحدود الشمالية الغربية، حدود إمبراطورية السيخ إلى مصب ممر خيبر (هو ممر جبلي في شمال غرب باكستان، على الحدود مع أفغانستان). دمجت الإدارة العلمانية لإمبراطورية السيخ إصلاحات عسكرية واقتصادية وحكومية مبتكرة.\\nشهدت الأشهر التي سبقت تقسيم الهند (تقسيم الهند البريطانية إلى دولتين مستقلتين، الهند وباكستان) سنة 1947، صراعًا حادًا في البنجاب (منطقة جيوسياسية وثقافية وتاريخية في جنوب آسيا، تحديدًا شمال شبه القارة الهندية، وتضم مناطق في شرق باكستان وشمال الهند) بين السيخ والمسلمين، شهد الهجرة الدينية الفعالة للسيخ البنجاب والهندوس من البنجاب الغربية مقابل هجرة دينية مماثلة للمسلمين البنجاب في شرق البنجاب. في الوقت الحاضر، يعيش غالبية السيخ في ولاية البنجاب في الهند.\\nالخمسة كاكارس أو الكافات الخمسة.\\nالخمسة كافات هم يصرون على الألتزام بها وعندهم من لا يلتزم بالكافات الخمس يصفوه بصفة باتت patitأي المرتد، ومن يدخل السيخية جديد يجعلوه يتعود عليها ويسموه المتكيف البطئ.\\nالغورو السيخ.\\nالغورو كلمة تعني المعلم وهم عشرة غورو للسيخية وهم:\\n</td>\n",
       "      <td>\\nما هي المناطق التي شملتها إمبراطورية السيخ؟</td>\n",
       "      <td>كشمير (أقصى شمال شبه القارة الهندية)، ولداخ (إقليم اتحادي تديره الهند)، وبيشاور (هي عاصمة مقاطعة خيبر بختونخوا الباكستانية وأكبر مدنها)</td>\n",
       "      <td>لا يوجد معلومات حول الإمبراطورية السيخية أو أي منطقة كانت تحتوي على إمبراطورية السيخ. يبدو أن هناك خطأ في السؤال. هل يمكنك تقديم المزيد من المعلومات أو التحقق من السؤال؟\\n\\nفيما يلي بعض المعلومات العامة عن الإمبراطورية السيخية:\\n\\n1. كانت الإمبراطورية السيخية تأسست في القرن الثالث عشر الميلادي.\\n\\n2. كانت تغطي معظم شمال أفريقيا وجنوب شرق آسيا.\\n\\n3. كانت تضم العديد من الدول والمناطق مثل مصر، سوريا، العراق، الهند، الصين، وباكستان.\\n\\n4. كانت تتميز بالثقافة الإسلامية واللغة العربية.\\n\\n5. كانت تواجه تحديات كبيرة بسبب الصراعات الداخلية والخارجية.\\n\\n6. انتهت الإمبراطورية في القرن السادس عشر الميلادي بعد هزيمتها في حرب النيل الكبرى.\\n\\nلذا، فإن الإجابة على السؤال \"ما هي المناطق التي شملتها الإمبراطورية السيخية؟\" قد تكون غير دقيقة أو غير دقيقة بشكل كبير، حيث أنها لم تشمل جميع المناطق كما ذكرت في السؤال. يجب التحقق من المعلومات المقدمة للحصول على الإ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>صيفنا الحبيب (هانغل: 그 해 우리는)؛ هو مسلسل تلفزيوني رومانسي كوميدي كوري جنوبي، يصنف بأنه «أول مشروع أصلي لي إستوديو إن». من بطولة وكيم دامي، عرض على SBS TV من 6 ديسمبر 2021 إلى 25 يناير 2022، بث كل يوم الإثنين والثلاثاء الساعة 22:00 بتوقيت (KST). وهو متاحًا أيضًا على نتفليكس. القصة. انفصل الثنائي تشوي وونغ (تشوي وو شيك) ويون سو (كيم دامي) قبل 10 سنوات، لكن يصبح الفيلم الوثائقي الذي صوروه خلال أيام دراستهما الثانوية شائعًا، بسببه عليهما الوقوف أمام الكاميرا مجددا، على رغم انهم لايريدون ذلك. طاقم. الشخصيات الرئيسية. رسام تشكيلي حر مفعم بالحيوية. خبيرة علاقات عامة وواقعية. مخرج وثائقي، وهو كان المسؤول عن إنتاج الفيلم الوثائقي لي تشوي وونغ وايون سو. أيدول مشهورة تحتفظ بالمركز الأول منذ ظهورها. الإنتاج. صناعة. تم إنشاء المشروع بواسطة إستوديو إن، وهي أول دراما أصلية لهم، سيتم إنتاج المسلسل بتعاون مع شركة سوبر مون بيكتشرز، بتنسيق مع المقر الرئيسي للإنتاج والتخطيط الدرامي التابع لإس بي إس المعروف بـ «إستوديو إس». طاقم. في مارس 2021، أعلن تأكيد انضمام كل من تشوي وو شيك وكيم دا مي في المسلسل التلفزيوني، يجمع المسلسل بهم بعد ثلاث سنوات، آخر مرة ظهروا فيه في معا بفيلم الغموض \"\" لعام 2018. تم تأكيد اختيار الطاقم الشبابي في 8 يوليو. التصوير. بدأ تصوير المسلسل في أوائل يوليو 2021. طبعة أخرى. سيتم أيضًا إنتاج ويب تون من «صيفنا الحبيب»، الويب تون هو عبارة عن مقدمة عن أيام المدرسة الثانوية للشخصيتين الرئيسيتين في المسلسل التلفزيوني (تشوي وانغ وايون سوو)، ومن المقرر أن يتم إصداره على «نايفر ويبتوون» هذا العام. هي ناشر ومنصة على الويب أطلقته شركة نافير في كوريا الجنوبية في عام 2004.</td>\n",
       "      <td>متى تم عرض المسلسل  \"صيفنا الحبيب ؟\\n</td>\n",
       "      <td>من 6 ديسمبر 2021</td>\n",
       "      <td>2023\\nThe given text does not contain any information about a TV series called \"Our Sweet Summer\". Therefore, I cannot provide an accurate date for when it was first shown. The provided information only mentions that there is a Russian mission named Lena-26 planned to explore the Moon's pole in 2024 using Soyuz 2 rockets. There is no mention of any other TV shows or movies being released around this time period. Without more specific details from reliable sources, I am unable to determine if there has been any release of a TV show titled \"Our Sweet Summer\" at all, let alone its premiere year. Thus, based on the limited information available, I cannot confidently state whether \"Our Sweet Summer\" was first shown in 2023 or not. To accurately answer such questions, one would need access to comprehensive databases of television releases or official announcements regarding the airing dates of various programs. \\n\\nPlease note that without additional context or verification through external resources, providing an exact date for the premiere of a fictional or non-existent TV show like \"Our Sweet Summer\" is speculative and unreliable. If you have any further information or clarification about this topic, please feel free to ask! However, my current understanding based solely on the provided context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"العنف ضد كبار السن\" هو مصطلح يشير إلى السلوك العدواني والعنيف ضد كبار السن والذي من شأنه أن يسبب لهم العديد من الأضرار على المستويين النفسي والجسدي. قد يتم العنف ضد كبار السن في أي مكانً كان وعلى يدي أي شخص فهو لا ينطوي على شكل أو سبب واحد وهو يعتبر ظاهرة عالمية واسعة الانتشار ومن القضايا المجتمعية الرئيسية والتي تُقلِق المحاكم الدولية والمجتمعية وتدفعها باستمرار للبحث عن طرق للحفاظ على حقوق هؤلاء المُسنين وحمايتهم منه. كبار السن حسب تعريف دولة اسرائيل هم الأشخاص الذي يتجاوز عمرهم ال 65 سنة وهم أشخاص يحصلون على امتيازات وحماية مكثفة في اسرائيل وذلك بحسب التعديل رقم 26 لقانون العقوبات وهو قانون حماية القاصرين والعاجزين كما ويعود ذلك لضعفهم ولكثرة احتياجاتهم والتحديات التي يواجهها قسم كبير منهم. في دولة اسرائيل يتم التفريق بين مصطلح \"العنف ضد كبار السن\" وبين مصطلح \"إساءة وإهمال كبار السن\" حيث أنه وعلى الرغم من أن الإساءة لكبار السن قد تضمن العنف إلا أنها عادة ما تحدث من شخص مقرب لكبير السن مثل الأقرباء والأشخاص المخصصين لرعايتهم وتستمر لفترة وهو ضمن مجال عمل وزارة الرفاه والضمان الاجتماعي، على عكس مصطلح العنف ضد كبار السن والذي يدل على حادث الذي فيه يتم التهجم على شخص كبير بالسن من قبل شخص غريب ويحدث ذلك لمرة واحدة ويكون ضمن مجال عمل الشرطة. من الجدير بالذكر أن دولة إسرائيل تقوم باتخاذ الإجراءات اللازمة في كلتا الحالتين، سواء كانت إساءة او عنف، بهدف الحد من ظاهرة العنف ضد كبار السن. إحصائيات العنف ضد كبار السن. حسب التقرير الذي أصدرته الكنيست عام 2007 والذي يعرض ظاهرة العنف ضد كبار السن فأنه وفقًا للإحصائيات التي أجريت في نهاية سنة 2006 عاش ما يقارب ال 70،000 مُسن في اسرائيل وهذا يعادل 10% من إجمالي السكان، 30% منهم هم ناجون من المحرقة اليهودية او الهولوكوست كما ان حوالي 12،000 من كبار السن يعيشون مع شخص واحد على الأقل لا تربطه معهم صلة دم (عادة ما يكون هذا الشخص معالج او مرافق للاعتناء بهم). مراكز الشرطة تتلقى عدد هائل من البلاغات وفتحت ما يقارب 12,228 ملف يتعلق بالعنف والجرائم ضد كبار السن من عام 2002 حتى الرابع من سبتمبر عام 2007 (هذه الملفات تتضمن القتل، محاولات القتل، الجرائم الجنسية والاغتصاب، جرائم السرقة والسطو على البيوت كما وتتضمن الاعتداء والتخريب) هذا العدد من الشكاوي والملفات لا يتضمن أولئك الذين وصلوا إلى الحرس المدني وغيرها من الأقسام. بحسب الاحصائيات فإن: 32% من هذه الشكاوى هي بلاغات عن السطو على بيوتهم، 17% هي عن تهديدات تلقوها، 31% عن سرقات تعرضوا لها بينما 11% هي فقط اعتداءات جسدية. بشكل عام في تلك السنوات (2002-2007) كان يقدم كبار السن القادمون جديدًا للدولة (المهاجرون) حوالي 9% من الشكاوى رغم أن نسبتهم من السكان لا تتعدى 25% بينما المسنين العرب كانوا يقدمون 5% من البلاغات. وفقًا لوزارة الرفاه والضمان الاجتماعي إن لجائحة كورونا أثرًا سلبيًا على ظاهرة العنف ضد كبار السن فقد لوحظ ارتفاع في الحالات التي تم فيها تعنيف كبار السن (معظمها تمت من قبل أفراد العائلة ومقدمي الرعاية) فعلى سبيل المثال في عام 2018 تم علاج 6707 حالة بينما حتى منتصف عام 2019 فقط تم علاج أكثر من 7000 حالة وهذا عدا عن الحالات التي</td>\n",
       "      <td>من هم كبار السن حسب تعريف دولة إسرائيل؟\\n\\n</td>\n",
       "      <td>الذي يتجاوز عمرهم ال 65 سنة</td>\n",
       "      <td>1992 هو العام الذي ولد فيه الميلاميد، وهو أكبر من كولينز بعام واحد فقط. لذا فإن كولينز هو الأكبر سنًا حسب هذا التعريف. ولكن إذا تم تقسيم السن إلى 65 عامًا أو أكثر، فهناك العديد من الأشخاص الذين يتجاوزون ذلك مثل رونالدينيو (70 عامًا) ورونالدو (34 عامًا). لذا فإن الإجابة على السؤال \"من هم كبار السن حسب تعريف دولة إسرائيل\" قد تتغير بناءً على هذه التفاصيل. ولكن من الناحية العامة، يمكن اعتبار كولينز كبار السن حسب هذا التعريف. \\n\\nفيما يتعلق بالسؤال عن كبار السن حسب تعريف دولة إسرائيل، فإن الإجابة هي كولينز. فهو أكبر من الميلاميد بعام واحد فقط، وبالتالي يعتبر كبار السن حسب هذا التعريف. ولكن إذا تم تقسيم السن إلى 65 عامًا أو أكثر، فهناك العديد من الأشخاص الذين يتجاوزون ذلك مثل رونالدينيو (70 عامًا) و</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>عدم التحمل في نظام الطاقة الكهربائية هي الحالة التي يكون فيها فقدان التحمل المفاجئ في النظام والذي يتسبب في زيادة تواتر معدات التوليد. يعد اختبار عدم التحمل جزءًا من التكليف لأنظمة الطاقة للتأكد من أن النظام يمكنه تحمل الفقد المفاجئ للتحمل والعودة إلى ظروف التشغيل العادية.</td>\n",
       "      <td>ما هي عدم التحمل في نظام الطاقة الكهربائية؟\\n</td>\n",
       "      <td>الحالة التي يكون فيها فقدان التحمل المفاجئ في النظام والذي يتسبب في زيادة تواتر معدات التوليد</td>\n",
       "      <td>لا يوجد أي معلومات محددة حول \"العدوى الكهربائية\" أو \"العدوى في النظام الكهربائي\". يبدو أن هناك خطأ في الطلب. هل يمكن إعادة طرح السؤال بشكل صحيح؟ إذا كان لديك المزيد من المعلومات أو استفسارات أخرى، فأنا هنا للمساعدة. \\n\\nفيما يتعلق بالسؤال الذي تم تقديمته، فإن \"العدوى الكهربائية\" ليست عبارة عن مشكلة في النظام الكهربائي. ربما كان هناك بعض الخطأ في كتابة السؤال. قد يكون هناك شيء آخر تحتاج إلى معرفته. هل يمكنك تقديم المزيد من المعلومات أو الاستفسارات حتى أتمكن من مساعدتك بشكل أفضل؟\\n---------------------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الهندسة الكهربائية هي تخصص يهتم بدراسة وتطبيقات علوم الكهرباء والإلكترونيات والمجالات الكهرومغناطيسية.\\nأصبح هذا المجال معروفاً في أواخر القرن التاسع عشر وذلك بعد انتشار التلغراف ومحطات إمداد الطاقة. والآن يغطي هذا المجال عدداً من المواضيع الفرعية والتي تتضمن الطاقة والإلكترونيات ونظم التحكم الآلي ومعالجة الإشارات والاتصالات اللاسلكية.\\nومن الممكن أن نقول أن الهندسة الكهربائية قد تتضمن أيضاً هندسة الإلكترونيات وقد لا تتضمنها. ويمكن التفريق بينهما حيث تهتم هندسة الكهرباء بالأمور المتعلقة بنظم الكهرباء عالية الجهد مثل نقل الطاقة والتحكم في المحركات، بينما تتعامل هندسة الإلكترونيات مع دراسة النظم الإلكترونية ذات المقاييس المنخفضة (تيار منخفض –جهد منخفض)، ويتضمن ذلك علوم الحاسبات والدوائر المتكاملة.\\nوتتناول الهندسة الكهربائية دراسة وتصميم العديد من النظم الكهربائية والإلكترونية المختلفة، مثل الدوائر الكهربائية والمولدات، المحركات، المحولات، مولد القدرة غير المنقطعة UPS، المواد المغناطيسية وغيرها من الأجهزة الكهرومغناطيسية والكهروميكانيكية.\\nتاريخ وأعلام الهندسة الكهربائية.\\nظهر الاهتمام العلمي بالكهرباء منذ بدايات القرن السابع عشر على الأقل. فيعتقد أن أول مهندس كهرباء هو وليام جلبرت الذي صمم آلة لاكتشاف الأجسام ذات الشحنات الكهربية الساكنة. وهو من فرَّق بين المغناطيسية والكهربية الساكنة، كما يعتقد بأنه أول من أنشأ مصطلح الكهرباء.\\nوفي بادئ الأمر كانت كل الاكتشافات والاختراعات تتعلق بالشحنة. وبدأ فصل الهندسة الكهربائية عن الفيزياء في زمن توماس اديسون وفيرنر فون سيمنس. وفي عام 1752 اخترع بينيامين فرانكلين موصلة الصواعق ونشر بين 1751 و1753 نتائج تجاربه تحت عنوان «تجارب ومشاهدات عن الكهرباء» (Experiments and Observations on Electricity). في العام 1800 قام ألساندرو فولتا ببناء بطاريته الأولى المسماة «عمود فولتا» بعد اعجابه بتجربة اجراها لويجي جالفاني عام 1792. في العام 1820 قام هانز كريستيان اورستد بعمل تجارب عن انحناء ابرة البوصلة بتاثير التيار الكهربي. وفي نفس العام كرر اندريه ماري امبير تلك التجربة واثبت ان سلكين يمر فيهما التيار يؤثران بقوى على بعضهما البعض وعرف خلالها الجهد الكهربي والتيار الكهربي.\\nمايكل فاراداي (ينطق أيضا ميشيل فاراداي) قدم أعمال كبيرة في مجال الفيضين الكهربي والمغناطيسي، وعرف أيضا خطوط المجال. وبناء على أعمال فاراداي قدم جيمس كليرك ماكسويل أعمالا في إكمال نظرية الكهرومغناطيسية والكهروديناميكيةـ وقدم عام 1864 معادلات ماكسويل والتي تعتبر أحد أهم أسس الهندسة الكهربية.\\nتطور مجال إنتاج الطاقة الكهربائية والضوء في نفس السنوات أدت لزيادة الطلب على مهندسوا كهرباء ذوي تجربة. في نفس الفترة تم الحصول على المؤهلات الهندسية من خلال التخصصات بأطر أعمال هندسية. هذه الطريقة اهلت مهندسوا بناء ومهندسو ماكينات لكنها فشلت بان تؤهل مهندسوا كهرباء على ضوء تسارع المجال، ولم يكن هناك مهندسو كهرباء يدرسون الموضوع لطلاب هندسه الكهرباء. \\nبشكل طبيعي مهمة تعليم وتأهيل مهندسوا الكهرباء وقعت على عاتق الفيزيائين، حيث انه لم يكن لاحد اخر العلم بمجال الكهرباء المطلوب والقدرة لتوصيله لاكبر عدد من الطلاب.\\n</td>\n",
       "      <td>ما هو دور الإلكترونيات في مجال الهندسة الكهربائية؟\\n</td>\n",
       "      <td>.</td>\n",
       "      <td>الإلكترونات هي جزء أساسي من الهندسة الكهربائية حيث تستخدم لإنتاج ونقل الطاقة الكهربائية. يمكن أن تكون الإلكترونات في شكل كابلات أو أجهزة كهربائية مثل الأجهزة المنزلية أو المعدات الصناعية. بالإضافة إلى ذلك، يمكن استخدام الإلكترونات في مجالات أخرى مثل التكنولوجيا الحيوية والذكاء الاصطناعي. في النهاية، الإلكترونات هي جزء لا يتجزأ من الهندسة الكهربائية. \\n\\nالإجابة على السؤال \"ما هو دور الإلكترونيات في مجال الهندسة الكهربائية؟\" هي أنه تعتبر جزءًا أساسياً من الهندسة الكهربائية حيث تستخدم لإنتاج ونقل الطاقة الكهربائية. ويمكن أن تكون الإلكترونات في شكل كابلات أو أجهزة كهربائية مثل الأجهزة المنزلية أو المعدات الصناعية. بالإضافة إلى ذلك، يمكن استخدام الإلكترونات في مجالات أخرى مثل التكنولوجيا الحيوية والذكاء الاصطناعي. في النهاية، الإلكترونات هي جزء لا</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               context  \\\n",
       "0  السيخية (بالبنجابيَّة: ਸਿੱਖੀ) هي ديانة توحيدية دارميَّة نشأت في شمالي الهند في نهاية القرن الخامس عشر. وتأتي كلمة «سيخية» من كلمة «سيخ» وهي بدورها تأتي من الجذر السنسكريتي التي تعني التلميذ و في اللغة البالية المريد أو التابع. وهي واحدة من أحدث الأديان الرئيسية في العالم، وهي واحدة من أكبر الديانات في العالم. وتتضمن المعتقدات الأساسية للسيخية، والتي وضِحَت في كتابهم المقدس جورو جرانث صاحب، الإيمان والتأمل في اسم الخالق الواحد، والوحدة الإلهية والمساواة للبشرية جمعاء، والانخراط في خدمة نكران الذات، والسعي لتحقيق العدالة لمصلحة الجميع وازدهارها، وإتباع سلوك معيشة صادق. وفي أوائل القرن الواحد والعشرين كان هناك حوالي 25 مليون سيخي في جميع أنحاء العالم، وتعيش الغالبية العظمى أو 76% (20 مليون) من السيخ في البنجاب، موطن السيخ في شمال غرب الهند، ويعيش حوالي مليوني في الدول الهندية المجاورة، والتي كانت جزءاً من ولاية البنجاب الهندية سابقاً. وسبب انتشارها في العالم هو اعتماد الإنجليز عليهم في بعض الحروب وهجرات السيخ خارج بلادهم، حيث بدأت الهجرة السيخية من الهند البريطانية خلال النصف الثاني من القرن التاسع عشر، عندما أكمل البريطانيون ضمهم للبنجاب.\\nتستند السيخية على التعاليم الروحية لمؤسس الديانة وهو الغورو ناناك، وخلفائه التسعة من الغورو البشر. لقب غورو يعني بالهندية المعلم. أما الغورو غورو جوبيند سينغ الملقب بالعاشر، ساهم في الكثير من أجل السيخية، وكان إسهامه في الإضفاء المستمر للطابع الرسمي على الديانة التي أسسها أولًا الغورو السيخ ناناك ديف جي في القرن الخامس عشر إسهامًا جديرًا بالملاحظة. وسمى الكتاب المقدس للسيخ جورو جرانث صاحب كخليفة له، وبالتالي أنهى خط الغورو البشر وجعل ن الكتاب المقدس للسيخ جورو جرانث صاحب الدليل الروحي الديني والدينوي للسيخ. وترفض الديانة السيخية الادعاءات بأن أي تقليد ديني معين له احتكار للحقيقة المطلقة. وتطورت السيخية في أوقات الاضطهاد الديني. حيث تعرض اثنان من أتباع السيخ وهم الغورو أرجان والغورو تيج بهادور للتعذيب وأعدم من قبل حكام المغول بعد رفضهم اعتناق الإسلام. وأثار اضطهاد السيخ تأسيس الخالسا كطلب لحماية حرية الضمير والدين.\\nالتاريخ.\\nيرتبط تاريخ السيخية ارتباطًا وثيقًا بتاريخ منطقة البنجاب والوضع الاجتماعي السياسي في شمال غرب شبه القارة الهندية في القرن السادس عشر. منذ الحكم المغولي للهند على يد الإمبراطور جهانكير (1605-1707)، كانت السيخية في صراع مع قوانين إمبراطورية المغول، لأنها كانت تؤثر في التعاقب السياسي للمغول في حين تعتز بالأولياء من الإسلام. قُتل العديد من السيخ البارزين على يد حكام المغول لرفضهم الانصياع لأوامرهم، ومعارضتهم لاضطهاد السيخ. من مجموع 10 من الغورو السيخ، عُذب وأُعدم اثنان من المعلمين أنفسهم (الغورو أرجان والغورو تيج بهادور)، وأقرباء مقربين للعديد من الغورو السيخ قُتلو بوحشية دون رحمة (مثل أبناء الغورو جوبيند سينغ البالغين من العمر 6 و9 سنوات)، إلى جانب العديد من الشخصيات الرئيسية الأخرى السيخية التي عُذبت وقُتلت (مثل باندا بهادور، بهاي ماتي داس، بهاي ساتي داس وباهاي ديالا)، على يد الحكام المغول المتجبرين لرفضهم الخضوع لأوامرهم، ومعارضتهم لاضطهاد السيخ والهندوس. بعد ذلك، عسكرت السيخية لمعارضة هيمنة المغول على أرضهم.\\nتميّز ظهور الكونفدرالية السيخية تحت حكم الأمراء والسيخ تحت حكم المهراجا رانجيت سينغ بالتسامح الديني والتعايش السلمي والتعددية مع المسيحيين والمسلمين والهندوس في مواقع السلطة. يعد تأسيس إمبراطورية السيخ عادةً ذروة السيخية على المستوى السياسي، خلال هذه الفترة جاءت إمبراطورية السيخ لتشمل كشمير (أقصى شمال شبه القارة الهندية)، ولداخ (إقليم اتحادي تديره الهند)، وبيشاور (هي عاصمة مقاطعة خيبر بختونخوا الباكستانية وأكبر مدنها). اعتنق عدد من الفلاحين المسلمين والهندوس السيخية. أخذ هاري سينغ نالوا، القائد العام لجيش السيخ على طول الحدود الشمالية الغربية، حدود إمبراطورية السيخ إلى مصب ممر خيبر (هو ممر جبلي في شمال غرب باكستان، على الحدود مع أفغانستان). دمجت الإدارة العلمانية لإمبراطورية السيخ إصلاحات عسكرية واقتصادية وحكومية مبتكرة.\\nشهدت الأشهر التي سبقت تقسيم الهند (تقسيم الهند البريطانية إلى دولتين مستقلتين، الهند وباكستان) سنة 1947، صراعًا حادًا في البنجاب (منطقة جيوسياسية وثقافية وتاريخية في جنوب آسيا، تحديدًا شمال شبه القارة الهندية، وتضم مناطق في شرق باكستان وشمال الهند) بين السيخ والمسلمين، شهد الهجرة الدينية الفعالة للسيخ البنجاب والهندوس من البنجاب الغربية مقابل هجرة دينية مماثلة للمسلمين البنجاب في شرق البنجاب. في الوقت الحاضر، يعيش غالبية السيخ في ولاية البنجاب في الهند.\\nالخمسة كاكارس أو الكافات الخمسة.\\nالخمسة كافات هم يصرون على الألتزام بها وعندهم من لا يلتزم بالكافات الخمس يصفوه بصفة باتت patitأي المرتد، ومن يدخل السيخية جديد يجعلوه يتعود عليها ويسموه المتكيف البطئ.\\nالغورو السيخ.\\nالغورو كلمة تعني المعلم وهم عشرة غورو للسيخية وهم:\\n   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         صيفنا الحبيب (هانغل: 그 해 우리는)؛ هو مسلسل تلفزيوني رومانسي كوميدي كوري جنوبي، يصنف بأنه «أول مشروع أصلي لي إستوديو إن». من بطولة وكيم دامي، عرض على SBS TV من 6 ديسمبر 2021 إلى 25 يناير 2022، بث كل يوم الإثنين والثلاثاء الساعة 22:00 بتوقيت (KST). وهو متاحًا أيضًا على نتفليكس. القصة. انفصل الثنائي تشوي وونغ (تشوي وو شيك) ويون سو (كيم دامي) قبل 10 سنوات، لكن يصبح الفيلم الوثائقي الذي صوروه خلال أيام دراستهما الثانوية شائعًا، بسببه عليهما الوقوف أمام الكاميرا مجددا، على رغم انهم لايريدون ذلك. طاقم. الشخصيات الرئيسية. رسام تشكيلي حر مفعم بالحيوية. خبيرة علاقات عامة وواقعية. مخرج وثائقي، وهو كان المسؤول عن إنتاج الفيلم الوثائقي لي تشوي وونغ وايون سو. أيدول مشهورة تحتفظ بالمركز الأول منذ ظهورها. الإنتاج. صناعة. تم إنشاء المشروع بواسطة إستوديو إن، وهي أول دراما أصلية لهم، سيتم إنتاج المسلسل بتعاون مع شركة سوبر مون بيكتشرز، بتنسيق مع المقر الرئيسي للإنتاج والتخطيط الدرامي التابع لإس بي إس المعروف بـ «إستوديو إس». طاقم. في مارس 2021، أعلن تأكيد انضمام كل من تشوي وو شيك وكيم دا مي في المسلسل التلفزيوني، يجمع المسلسل بهم بعد ثلاث سنوات، آخر مرة ظهروا فيه في معا بفيلم الغموض \"\" لعام 2018. تم تأكيد اختيار الطاقم الشبابي في 8 يوليو. التصوير. بدأ تصوير المسلسل في أوائل يوليو 2021. طبعة أخرى. سيتم أيضًا إنتاج ويب تون من «صيفنا الحبيب»، الويب تون هو عبارة عن مقدمة عن أيام المدرسة الثانوية للشخصيتين الرئيسيتين في المسلسل التلفزيوني (تشوي وانغ وايون سوو)، ومن المقرر أن يتم إصداره على «نايفر ويبتوون» هذا العام. هي ناشر ومنصة على الويب أطلقته شركة نافير في كوريا الجنوبية في عام 2004.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \"العنف ضد كبار السن\" هو مصطلح يشير إلى السلوك العدواني والعنيف ضد كبار السن والذي من شأنه أن يسبب لهم العديد من الأضرار على المستويين النفسي والجسدي. قد يتم العنف ضد كبار السن في أي مكانً كان وعلى يدي أي شخص فهو لا ينطوي على شكل أو سبب واحد وهو يعتبر ظاهرة عالمية واسعة الانتشار ومن القضايا المجتمعية الرئيسية والتي تُقلِق المحاكم الدولية والمجتمعية وتدفعها باستمرار للبحث عن طرق للحفاظ على حقوق هؤلاء المُسنين وحمايتهم منه. كبار السن حسب تعريف دولة اسرائيل هم الأشخاص الذي يتجاوز عمرهم ال 65 سنة وهم أشخاص يحصلون على امتيازات وحماية مكثفة في اسرائيل وذلك بحسب التعديل رقم 26 لقانون العقوبات وهو قانون حماية القاصرين والعاجزين كما ويعود ذلك لضعفهم ولكثرة احتياجاتهم والتحديات التي يواجهها قسم كبير منهم. في دولة اسرائيل يتم التفريق بين مصطلح \"العنف ضد كبار السن\" وبين مصطلح \"إساءة وإهمال كبار السن\" حيث أنه وعلى الرغم من أن الإساءة لكبار السن قد تضمن العنف إلا أنها عادة ما تحدث من شخص مقرب لكبير السن مثل الأقرباء والأشخاص المخصصين لرعايتهم وتستمر لفترة وهو ضمن مجال عمل وزارة الرفاه والضمان الاجتماعي، على عكس مصطلح العنف ضد كبار السن والذي يدل على حادث الذي فيه يتم التهجم على شخص كبير بالسن من قبل شخص غريب ويحدث ذلك لمرة واحدة ويكون ضمن مجال عمل الشرطة. من الجدير بالذكر أن دولة إسرائيل تقوم باتخاذ الإجراءات اللازمة في كلتا الحالتين، سواء كانت إساءة او عنف، بهدف الحد من ظاهرة العنف ضد كبار السن. إحصائيات العنف ضد كبار السن. حسب التقرير الذي أصدرته الكنيست عام 2007 والذي يعرض ظاهرة العنف ضد كبار السن فأنه وفقًا للإحصائيات التي أجريت في نهاية سنة 2006 عاش ما يقارب ال 70،000 مُسن في اسرائيل وهذا يعادل 10% من إجمالي السكان، 30% منهم هم ناجون من المحرقة اليهودية او الهولوكوست كما ان حوالي 12،000 من كبار السن يعيشون مع شخص واحد على الأقل لا تربطه معهم صلة دم (عادة ما يكون هذا الشخص معالج او مرافق للاعتناء بهم). مراكز الشرطة تتلقى عدد هائل من البلاغات وفتحت ما يقارب 12,228 ملف يتعلق بالعنف والجرائم ضد كبار السن من عام 2002 حتى الرابع من سبتمبر عام 2007 (هذه الملفات تتضمن القتل، محاولات القتل، الجرائم الجنسية والاغتصاب، جرائم السرقة والسطو على البيوت كما وتتضمن الاعتداء والتخريب) هذا العدد من الشكاوي والملفات لا يتضمن أولئك الذين وصلوا إلى الحرس المدني وغيرها من الأقسام. بحسب الاحصائيات فإن: 32% من هذه الشكاوى هي بلاغات عن السطو على بيوتهم، 17% هي عن تهديدات تلقوها، 31% عن سرقات تعرضوا لها بينما 11% هي فقط اعتداءات جسدية. بشكل عام في تلك السنوات (2002-2007) كان يقدم كبار السن القادمون جديدًا للدولة (المهاجرون) حوالي 9% من الشكاوى رغم أن نسبتهم من السكان لا تتعدى 25% بينما المسنين العرب كانوا يقدمون 5% من البلاغات. وفقًا لوزارة الرفاه والضمان الاجتماعي إن لجائحة كورونا أثرًا سلبيًا على ظاهرة العنف ضد كبار السن فقد لوحظ ارتفاع في الحالات التي تم فيها تعنيف كبار السن (معظمها تمت من قبل أفراد العائلة ومقدمي الرعاية) فعلى سبيل المثال في عام 2018 تم علاج 6707 حالة بينما حتى منتصف عام 2019 فقط تم علاج أكثر من 7000 حالة وهذا عدا عن الحالات التي   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    عدم التحمل في نظام الطاقة الكهربائية هي الحالة التي يكون فيها فقدان التحمل المفاجئ في النظام والذي يتسبب في زيادة تواتر معدات التوليد. يعد اختبار عدم التحمل جزءًا من التكليف لأنظمة الطاقة للتأكد من أن النظام يمكنه تحمل الفقد المفاجئ للتحمل والعودة إلى ظروف التشغيل العادية.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  الهندسة الكهربائية هي تخصص يهتم بدراسة وتطبيقات علوم الكهرباء والإلكترونيات والمجالات الكهرومغناطيسية.\\nأصبح هذا المجال معروفاً في أواخر القرن التاسع عشر وذلك بعد انتشار التلغراف ومحطات إمداد الطاقة. والآن يغطي هذا المجال عدداً من المواضيع الفرعية والتي تتضمن الطاقة والإلكترونيات ونظم التحكم الآلي ومعالجة الإشارات والاتصالات اللاسلكية.\\nومن الممكن أن نقول أن الهندسة الكهربائية قد تتضمن أيضاً هندسة الإلكترونيات وقد لا تتضمنها. ويمكن التفريق بينهما حيث تهتم هندسة الكهرباء بالأمور المتعلقة بنظم الكهرباء عالية الجهد مثل نقل الطاقة والتحكم في المحركات، بينما تتعامل هندسة الإلكترونيات مع دراسة النظم الإلكترونية ذات المقاييس المنخفضة (تيار منخفض –جهد منخفض)، ويتضمن ذلك علوم الحاسبات والدوائر المتكاملة.\\nوتتناول الهندسة الكهربائية دراسة وتصميم العديد من النظم الكهربائية والإلكترونية المختلفة، مثل الدوائر الكهربائية والمولدات، المحركات، المحولات، مولد القدرة غير المنقطعة UPS، المواد المغناطيسية وغيرها من الأجهزة الكهرومغناطيسية والكهروميكانيكية.\\nتاريخ وأعلام الهندسة الكهربائية.\\nظهر الاهتمام العلمي بالكهرباء منذ بدايات القرن السابع عشر على الأقل. فيعتقد أن أول مهندس كهرباء هو وليام جلبرت الذي صمم آلة لاكتشاف الأجسام ذات الشحنات الكهربية الساكنة. وهو من فرَّق بين المغناطيسية والكهربية الساكنة، كما يعتقد بأنه أول من أنشأ مصطلح الكهرباء.\\nوفي بادئ الأمر كانت كل الاكتشافات والاختراعات تتعلق بالشحنة. وبدأ فصل الهندسة الكهربائية عن الفيزياء في زمن توماس اديسون وفيرنر فون سيمنس. وفي عام 1752 اخترع بينيامين فرانكلين موصلة الصواعق ونشر بين 1751 و1753 نتائج تجاربه تحت عنوان «تجارب ومشاهدات عن الكهرباء» (Experiments and Observations on Electricity). في العام 1800 قام ألساندرو فولتا ببناء بطاريته الأولى المسماة «عمود فولتا» بعد اعجابه بتجربة اجراها لويجي جالفاني عام 1792. في العام 1820 قام هانز كريستيان اورستد بعمل تجارب عن انحناء ابرة البوصلة بتاثير التيار الكهربي. وفي نفس العام كرر اندريه ماري امبير تلك التجربة واثبت ان سلكين يمر فيهما التيار يؤثران بقوى على بعضهما البعض وعرف خلالها الجهد الكهربي والتيار الكهربي.\\nمايكل فاراداي (ينطق أيضا ميشيل فاراداي) قدم أعمال كبيرة في مجال الفيضين الكهربي والمغناطيسي، وعرف أيضا خطوط المجال. وبناء على أعمال فاراداي قدم جيمس كليرك ماكسويل أعمالا في إكمال نظرية الكهرومغناطيسية والكهروديناميكيةـ وقدم عام 1864 معادلات ماكسويل والتي تعتبر أحد أهم أسس الهندسة الكهربية.\\nتطور مجال إنتاج الطاقة الكهربائية والضوء في نفس السنوات أدت لزيادة الطلب على مهندسوا كهرباء ذوي تجربة. في نفس الفترة تم الحصول على المؤهلات الهندسية من خلال التخصصات بأطر أعمال هندسية. هذه الطريقة اهلت مهندسوا بناء ومهندسو ماكينات لكنها فشلت بان تؤهل مهندسوا كهرباء على ضوء تسارع المجال، ولم يكن هناك مهندسو كهرباء يدرسون الموضوع لطلاب هندسه الكهرباء. \\nبشكل طبيعي مهمة تعليم وتأهيل مهندسوا الكهرباء وقعت على عاتق الفيزيائين، حيث انه لم يكن لاحد اخر العلم بمجال الكهرباء المطلوب والقدرة لتوصيله لاكبر عدد من الطلاب.\\n   \n",
       "\n",
       "                                               question  \\\n",
       "0         \\nما هي المناطق التي شملتها إمبراطورية السيخ؟   \n",
       "1                 متى تم عرض المسلسل  \"صيفنا الحبيب ؟\\n   \n",
       "2           من هم كبار السن حسب تعريف دولة إسرائيل؟\\n\\n   \n",
       "3         ما هي عدم التحمل في نظام الطاقة الكهربائية؟\\n   \n",
       "4  ما هو دور الإلكترونيات في مجال الهندسة الكهربائية؟\\n   \n",
       "\n",
       "                                                                                                                              ground_truth  \\\n",
       "0  كشمير (أقصى شمال شبه القارة الهندية)، ولداخ (إقليم اتحادي تديره الهند)، وبيشاور (هي عاصمة مقاطعة خيبر بختونخوا الباكستانية وأكبر مدنها)   \n",
       "1                                                                                                                         من 6 ديسمبر 2021   \n",
       "2                                                                                                              الذي يتجاوز عمرهم ال 65 سنة   \n",
       "3                                            الحالة التي يكون فيها فقدان التحمل المفاجئ في النظام والذي يتسبب في زيادة تواتر معدات التوليد   \n",
       "4                                                                                                                                        .   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       model_answer  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                          لا يوجد معلومات حول الإمبراطورية السيخية أو أي منطقة كانت تحتوي على إمبراطورية السيخ. يبدو أن هناك خطأ في السؤال. هل يمكنك تقديم المزيد من المعلومات أو التحقق من السؤال؟\\n\\nفيما يلي بعض المعلومات العامة عن الإمبراطورية السيخية:\\n\\n1. كانت الإمبراطورية السيخية تأسست في القرن الثالث عشر الميلادي.\\n\\n2. كانت تغطي معظم شمال أفريقيا وجنوب شرق آسيا.\\n\\n3. كانت تضم العديد من الدول والمناطق مثل مصر، سوريا، العراق، الهند، الصين، وباكستان.\\n\\n4. كانت تتميز بالثقافة الإسلامية واللغة العربية.\\n\\n5. كانت تواجه تحديات كبيرة بسبب الصراعات الداخلية والخارجية.\\n\\n6. انتهت الإمبراطورية في القرن السادس عشر الميلادي بعد هزيمتها في حرب النيل الكبرى.\\n\\nلذا، فإن الإجابة على السؤال \"ما هي المناطق التي شملتها الإمبراطورية السيخية؟\" قد تكون غير دقيقة أو غير دقيقة بشكل كبير، حيث أنها لم تشمل جميع المناطق كما ذكرت في السؤال. يجب التحقق من المعلومات المقدمة للحصول على الإ  \n",
       "1  2023\\nThe given text does not contain any information about a TV series called \"Our Sweet Summer\". Therefore, I cannot provide an accurate date for when it was first shown. The provided information only mentions that there is a Russian mission named Lena-26 planned to explore the Moon's pole in 2024 using Soyuz 2 rockets. There is no mention of any other TV shows or movies being released around this time period. Without more specific details from reliable sources, I am unable to determine if there has been any release of a TV show titled \"Our Sweet Summer\" at all, let alone its premiere year. Thus, based on the limited information available, I cannot confidently state whether \"Our Sweet Summer\" was first shown in 2023 or not. To accurately answer such questions, one would need access to comprehensive databases of television releases or official announcements regarding the airing dates of various programs. \\n\\nPlease note that without additional context or verification through external resources, providing an exact date for the premiere of a fictional or non-existent TV show like \"Our Sweet Summer\" is speculative and unreliable. If you have any further information or clarification about this topic, please feel free to ask! However, my current understanding based solely on the provided context  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    1992 هو العام الذي ولد فيه الميلاميد، وهو أكبر من كولينز بعام واحد فقط. لذا فإن كولينز هو الأكبر سنًا حسب هذا التعريف. ولكن إذا تم تقسيم السن إلى 65 عامًا أو أكثر، فهناك العديد من الأشخاص الذين يتجاوزون ذلك مثل رونالدينيو (70 عامًا) ورونالدو (34 عامًا). لذا فإن الإجابة على السؤال \"من هم كبار السن حسب تعريف دولة إسرائيل\" قد تتغير بناءً على هذه التفاصيل. ولكن من الناحية العامة، يمكن اعتبار كولينز كبار السن حسب هذا التعريف. \\n\\nفيما يتعلق بالسؤال عن كبار السن حسب تعريف دولة إسرائيل، فإن الإجابة هي كولينز. فهو أكبر من الميلاميد بعام واحد فقط، وبالتالي يعتبر كبار السن حسب هذا التعريف. ولكن إذا تم تقسيم السن إلى 65 عامًا أو أكثر، فهناك العديد من الأشخاص الذين يتجاوزون ذلك مثل رونالدينيو (70 عامًا) و  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         لا يوجد أي معلومات محددة حول \"العدوى الكهربائية\" أو \"العدوى في النظام الكهربائي\". يبدو أن هناك خطأ في الطلب. هل يمكن إعادة طرح السؤال بشكل صحيح؟ إذا كان لديك المزيد من المعلومات أو استفسارات أخرى، فأنا هنا للمساعدة. \\n\\nفيما يتعلق بالسؤال الذي تم تقديمته، فإن \"العدوى الكهربائية\" ليست عبارة عن مشكلة في النظام الكهربائي. ربما كان هناك بعض الخطأ في كتابة السؤال. قد يكون هناك شيء آخر تحتاج إلى معرفته. هل يمكنك تقديم المزيد من المعلومات أو الاستفسارات حتى أتمكن من مساعدتك بشكل أفضل؟\\n---------------------  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 الإلكترونات هي جزء أساسي من الهندسة الكهربائية حيث تستخدم لإنتاج ونقل الطاقة الكهربائية. يمكن أن تكون الإلكترونات في شكل كابلات أو أجهزة كهربائية مثل الأجهزة المنزلية أو المعدات الصناعية. بالإضافة إلى ذلك، يمكن استخدام الإلكترونات في مجالات أخرى مثل التكنولوجيا الحيوية والذكاء الاصطناعي. في النهاية، الإلكترونات هي جزء لا يتجزأ من الهندسة الكهربائية. \\n\\nالإجابة على السؤال \"ما هو دور الإلكترونيات في مجال الهندسة الكهربائية؟\" هي أنه تعتبر جزءًا أساسياً من الهندسة الكهربائية حيث تستخدم لإنتاج ونقل الطاقة الكهربائية. ويمكن أن تكون الإلكترونات في شكل كابلات أو أجهزة كهربائية مثل الأجهزة المنزلية أو المعدات الصناعية. بالإضافة إلى ذلك، يمكن استخدام الإلكترونات في مجالات أخرى مثل التكنولوجيا الحيوية والذكاء الاصطناعي. في النهاية، الإلكترونات هي جزء لا  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "completed_n = len(model_answers)  # should be 328\n",
    "df_sample = df_sample.reset_index(drop=True)\n",
    "\n",
    "# Attach the answers ONLY to the first completed_n rows\n",
    "df_sample.loc[:completed_n-1, \"model_answer\"] = model_answers\n",
    "\n",
    "# Keep only rows that actually have a model answer (not NaN / empty)\n",
    "df_done = df_sample.iloc[:completed_n].copy()\n",
    "df_done = df_done[df_done[\"model_answer\"] != \"\"]\n",
    "\n",
    "print(df_done.shape)\n",
    "df_done.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7acc35e0-59ee-4816-98d5-390375af2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_done.to_csv(\"df_sample_with_answers_328.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5037fbbc-59b2-4168-829d-e790bb7b72ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:6006/\n"
     ]
    }
   ],
   "source": [
    "print(session.url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7753a1e4-ede6-4c45-952b-fce34e2d53b6",
   "metadata": {},
   "source": [
    "## RAGAS Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00d9090e-5d13-4c84-ba6a-898ec1c4465a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (1.1.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: ragas 0.3.9 does not provide the extra 'langchain'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: langchain in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (1.0.8)\n",
      "Requirement already satisfied: pydantic in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (2.12.4)\n",
      "Requirement already satisfied: ragas[langchain] in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (0.1.4)\n",
      "Collecting ragas[langchain]\n",
      "  Downloading ragas-0.3.9-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.21.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from ragas[langchain]) (2.0.1)\n",
      "Requirement already satisfied: datasets>=4.0.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from ragas[langchain]) (4.4.1)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from ragas[langchain]) (0.12.0)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from ragas[langchain]) (1.6.0)\n",
      "Requirement already satisfied: appdirs in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from ragas[langchain]) (1.4.4)\n",
      "Collecting diskcache>=5.6.3 (from ragas[langchain])\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting typer (from ragas[langchain])\n",
      "  Downloading typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting rich (from ragas[langchain])\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: openai>=1.0.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from ragas[langchain]) (2.8.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from ragas[langchain]) (4.67.1)\n",
      "Collecting instructor (from ragas[langchain])\n",
      "  Downloading instructor-1.13.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gitpython (from ragas[langchain])\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pillow>=10.4.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from ragas[langchain]) (11.1.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from ragas[langchain]) (3.4.2)\n",
      "Collecting scikit-network (from ragas[langchain])\n",
      "  Downloading scikit_network-0.33.5-cp310-cp310-win_amd64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from ragas[langchain]) (0.4.1)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from ragas[langchain]) (1.0.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langchain-core) (0.4.45)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from pydantic) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from pydantic) (0.4.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.27.2)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.11)\n",
      "Requirement already satisfied: sniffio in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langchain) (1.0.3)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from datasets>=4.0.0->ragas[langchain]) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from datasets>=4.0.0->ragas[langchain]) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from datasets>=4.0.0->ragas[langchain]) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from datasets>=4.0.0->ragas[langchain]) (2.2.3)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from datasets>=4.0.0->ragas[langchain]) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=4.0.0->ragas[langchain]) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from datasets>=4.0.0->ragas[langchain]) (0.36.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=4.0.0->ragas[langchain]) (3.13.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=4.0.0->ragas[langchain]) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=4.0.0->ragas[langchain]) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=4.0.0->ragas[langchain]) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=4.0.0->ragas[langchain]) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=4.0.0->ragas[langchain]) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=4.0.0->ragas[langchain]) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=4.0.0->ragas[langchain]) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=4.0.0->ragas[langchain]) (1.22.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from openai>=1.0.0->ragas[langchain]) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from openai>=1.0.0->ragas[langchain]) (0.12.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from tqdm->ragas[langchain]) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython->ragas[langchain])\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->ragas[langchain])\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting docstring-parser<1.0,>=0.16 (from instructor->ragas[langchain])\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from instructor->ragas[langchain]) (3.1.6)\n",
      "Collecting jiter<1,>=0.10.0 (from openai>=1.0.0->ragas[langchain])\n",
      "  Downloading jiter-0.11.1-cp310-cp310-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pre-commit>=4.3.0 (from instructor->ragas[langchain])\n",
      "  Downloading pre_commit-4.5.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting ty>=0.0.1a23 (from instructor->ragas[langchain])\n",
      "  Downloading ty-0.0.1a27-py3-none-win_amd64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from jinja2<4.0.0,>=3.1.4->instructor->ragas[langchain]) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->ragas[langchain])\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from rich->ragas[langchain]) (2.19.2)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from typer->ragas[langchain]) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from typer->ragas[langchain]) (1.5.4)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->ragas[langchain])\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cfgv>=2.0.0 (from pre-commit>=4.3.0->instructor->ragas[langchain])\n",
      "  Downloading cfgv-3.5.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting identify>=1.0.0 (from pre-commit>=4.3.0->instructor->ragas[langchain])\n",
      "  Downloading identify-2.6.15-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting nodeenv>=0.11.1 (from pre-commit>=4.3.0->instructor->ragas[langchain])\n",
      "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting virtualenv>=20.10.0 (from pre-commit>=4.3.0->instructor->ragas[langchain])\n",
      "  Downloading virtualenv-20.35.4-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor->ragas[langchain])\n",
      "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor->ragas[langchain]) (4.5.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langchain-community->ragas[langchain]) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langchain-community->ragas[langchain]) (2.0.44)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langchain-community->ragas[langchain]) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langchain-community->ragas[langchain]) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langchain-community->ragas[langchain]) (0.4.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->ragas[langchain]) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->ragas[langchain]) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community->ragas[langchain]) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community->ragas[langchain]) (1.2.1)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community->ragas[langchain]) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community->ragas[langchain]) (1.1.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from tiktoken->ragas[langchain]) (2025.11.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from pandas->datasets>=4.0.0->ragas[langchain]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from pandas->datasets>=4.0.0->ragas[langchain]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from pandas->datasets>=4.0.0->ragas[langchain]) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets>=4.0.0->ragas[langchain]) (1.17.0)\n",
      "Requirement already satisfied: scipy>=1.7.3 in c:\\users\\azhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages (from scikit-network->ragas[langchain]) (1.15.3)\n",
      "Downloading ragas-0.3.9-py3-none-any.whl (366 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading instructor-1.13.0-py3-none-any.whl (160 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading jiter-0.11.1-cp310-cp310-win_amd64.whl (207 kB)\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading typer-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading pre_commit-4.5.0-py2.py3-none-any.whl (226 kB)\n",
      "Downloading cfgv-3.5.0-py2.py3-none-any.whl (7.4 kB)\n",
      "Downloading identify-2.6.15-py2.py3-none-any.whl (99 kB)\n",
      "Downloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
      "Downloading ty-0.0.1a27-py3-none-win_amd64.whl (9.6 MB)\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/9.6 MB 3.4 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.0/9.6 MB 3.4 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.8/9.6 MB 3.2 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.4/9.6 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.1/9.6 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.2/9.6 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.0/9.6 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.0/9.6 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.1/9.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.4/9.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.6 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.6/9.6 MB 4.1 MB/s  0:00:02\n",
      "Downloading virtualenv-20.35.4-py3-none-any.whl (6.0 MB)\n",
      "   ---------------------------------------- 0.0/6.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.8/6.0 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.1/6.0 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.1/6.0 MB 5.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.2/6.0 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.5/6.0 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.0/6.0 MB 5.2 MB/s  0:00:01\n",
      "Downloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
      "Downloading scikit_network-0.33.5-cp310-cp310-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.6/2.7 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.6/2.7 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 4.3 MB/s  0:00:00\n",
      "Installing collected packages: distlib, virtualenv, ty, smmap, nodeenv, mdurl, jiter, identify, docstring-parser, diskcache, cfgv, scikit-network, pre-commit, markdown-it-py, gitdb, rich, gitpython, typer, instructor, ragas\n",
      "\n",
      "   -- -------------------------------------  1/20 [virtualenv]\n",
      "   -- -------------------------------------  1/20 [virtualenv]\n",
      "   -- -------------------------------------  1/20 [virtualenv]\n",
      "   -- -------------------------------------  1/20 [virtualenv]\n",
      "   -- -------------------------------------  1/20 [virtualenv]\n",
      "   ---- -----------------------------------  2/20 [ty]\n",
      "   ---------- -----------------------------  5/20 [mdurl]\n",
      "  Attempting uninstall: jiter\n",
      "   ---------- -----------------------------  5/20 [mdurl]\n",
      "    Found existing installation: jiter 0.12.0\n",
      "   ---------- -----------------------------  5/20 [mdurl]\n",
      "    Uninstalling jiter-0.12.0:\n",
      "   ---------- -----------------------------  5/20 [mdurl]\n",
      "      Successfully uninstalled jiter-0.12.0\n",
      "   ---------- -----------------------------  5/20 [mdurl]\n",
      "   -------------- -------------------------  7/20 [identify]\n",
      "   ---------------- -----------------------  8/20 [docstring-parser]\n",
      "   ---------------------- ----------------- 11/20 [scikit-network]\n",
      "   ---------------------- ----------------- 11/20 [scikit-network]\n",
      "   ---------------------- ----------------- 11/20 [scikit-network]\n",
      "   ---------------------- ----------------- 11/20 [scikit-network]\n",
      "   ---------------------- ----------------- 11/20 [scikit-network]\n",
      "   ---------------------- ----------------- 11/20 [scikit-network]\n",
      "   ---------------------- ----------------- 11/20 [scikit-network]\n",
      "   ---------------------- ----------------- 11/20 [scikit-network]\n",
      "   ---------------------- ----------------- 11/20 [scikit-network]\n",
      "   ---------------------- ----------------- 11/20 [scikit-network]\n",
      "   ------------------------ --------------- 12/20 [pre-commit]\n",
      "   ------------------------ --------------- 12/20 [pre-commit]\n",
      "   ------------------------ --------------- 12/20 [pre-commit]\n",
      "   -------------------------- ------------- 13/20 [markdown-it-py]\n",
      "   -------------------------- ------------- 13/20 [markdown-it-py]\n",
      "   -------------------------- ------------- 13/20 [markdown-it-py]\n",
      "   ---------------------------- ----------- 14/20 [gitdb]\n",
      "   ------------------------------ --------- 15/20 [rich]\n",
      "   ------------------------------ --------- 15/20 [rich]\n",
      "   ------------------------------ --------- 15/20 [rich]\n",
      "   ------------------------------ --------- 15/20 [rich]\n",
      "   ------------------------------ --------- 15/20 [rich]\n",
      "   -------------------------------- ------- 16/20 [gitpython]\n",
      "   -------------------------------- ------- 16/20 [gitpython]\n",
      "   -------------------------------- ------- 16/20 [gitpython]\n",
      "   ---------------------------------- ----- 17/20 [typer]\n",
      "   ------------------------------------ --- 18/20 [instructor]\n",
      "   ------------------------------------ --- 18/20 [instructor]\n",
      "   ------------------------------------ --- 18/20 [instructor]\n",
      "   ------------------------------------ --- 18/20 [instructor]\n",
      "   ------------------------------------ --- 18/20 [instructor]\n",
      "  Attempting uninstall: ragas\n",
      "   ------------------------------------ --- 18/20 [instructor]\n",
      "    Found existing installation: ragas 0.1.4\n",
      "   ------------------------------------ --- 18/20 [instructor]\n",
      "    Uninstalling ragas-0.1.4:\n",
      "   ------------------------------------ --- 18/20 [instructor]\n",
      "      Successfully uninstalled ragas-0.1.4\n",
      "   ------------------------------------ --- 18/20 [instructor]\n",
      "   -------------------------------------- - 19/20 [ragas]\n",
      "   -------------------------------------- - 19/20 [ragas]\n",
      "   -------------------------------------- - 19/20 [ragas]\n",
      "   -------------------------------------- - 19/20 [ragas]\n",
      "   -------------------------------------- - 19/20 [ragas]\n",
      "   -------------------------------------- - 19/20 [ragas]\n",
      "   -------------------------------------- - 19/20 [ragas]\n",
      "   -------------------------------------- - 19/20 [ragas]\n",
      "   -------------------------------------- - 19/20 [ragas]\n",
      "   ---------------------------------------- 20/20 [ragas]\n",
      "\n",
      "Successfully installed cfgv-3.5.0 diskcache-5.6.3 distlib-0.4.0 docstring-parser-0.17.0 gitdb-4.0.12 gitpython-3.1.45 identify-2.6.15 instructor-1.13.0 jiter-0.11.1 markdown-it-py-4.0.0 mdurl-0.1.2 nodeenv-1.9.1 pre-commit-4.5.0 ragas-0.3.9 rich-14.2.0 scikit-network-0.33.5 smmap-5.0.2 ty-0.0.1a27 typer-0.20.0 virtualenv-20.35.4\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"ragas[langchain]\" langchain-core langchain pydantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2099e725-0fd5-47cc-8a3b-f786a49c74f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AZhaa\\AppData\\Local\\Temp\\ipykernel_2132\\843810481.py:5: DeprecationWarning: LlamaIndexLLMWrapper is deprecated and will be removed in a future version. Use llm_factory instead: from openai import OpenAI; from ragas.llms import llm_factory; llm = llm_factory('gpt-4o-mini', client=OpenAI(api_key='...'))\n",
      "  evaluator_llm = LlamaIndexLLMWrapper(llm)\n"
     ]
    }
   ],
   "source": [
    "from ragas.llms import LlamaIndexLLMWrapper\n",
    "\n",
    "# you already defined `llm = HuggingFaceLLM(...)` and `Settings.llm = llm`\n",
    "\n",
    "evaluator_llm = LlamaIndexLLMWrapper(llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97ef2602-0f8b-48e3-8f29-0e205124811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\n",
    "    \"sentence-transformers/LaBSE\",\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e02bb965-1393-44f6-a7ca-128d21ba4b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AZhaa\\AppData\\Local\\Temp\\ipykernel_2132\\3569151.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/LaBSE\",\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3096901c-2f88-4723-9a45-209339839aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['context', 'question', 'ground_truth', 'model_answer',\n",
      "       'retrieved_contexts', 'response', 'user_input', 'reference'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Starting from df_sample with: context, question, ground_truth, model_answer\n",
    "df_ragas = df_done.copy()\n",
    "\n",
    "# Rename columns to match Ragas expectations\n",
    "df_ragas[\"retrieved_contexts\"] = df_ragas[\"context\"].apply(lambda x: [x])  # must be list of strings\n",
    "df_ragas[\"response\"] = df_ragas[\"model_answer\"]\n",
    "df_ragas[\"user_input\"] = df_ragas[\"question\"]\n",
    "df_ragas[\"reference\"] = df_ragas[\"ground_truth\"]  # rename ground_truth to reference\n",
    "\n",
    "print(df_ragas.columns)\n",
    "# Should include: 'user_input', 'response', 'retrieved_contexts', 'reference'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "09c68957-b6ce-4636-990d-6fe84acb1102",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ragas import EvaluationDataset\n",
    "ragas_dataset = EvaluationDataset.from_pandas(df_ragas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d9be93-97e7-46cc-a21c-1d54dccad37a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AZhaa\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\pydantic\\v1\\main.py:1054: UserWarning: LangSmith now uses UUID v7 for run and trace identifiers. This warning appears when passing custom IDs. Please use: from langsmith import uuid7\n",
      "            id = uuid7()\n",
      "Future versions will require UUID v7.\n",
      "  input_data = validator(cls_, input_data)\n",
      "n values greater than 1 not support for LlamaIndex LLMs0 [00:00<?, ?it/s]\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n"
     ]
    }
   ],
   "source": [
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    answer_correctness,\n",
    ")\n",
    "\n",
    "from ragas import evaluate\n",
    "\n",
    "result = evaluate(\n",
    "    ragas_dataset,\n",
    "    metrics=[\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        answer_correctness,\n",
    "    ],\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=embeddings,\n",
    ")\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebf1cec-0e46-4184-9f46-0d2c304ee11b",
   "metadata": {},
   "source": [
    "### Overall RAGAS Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88c8a32-5452-4e53-844f-a779c1d78855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "overall_df = result.to_pandas()\n",
    "overall_df.to_csv(\"ragas_overall_scores.csv\", index=False)\n",
    "\n",
    "print(\"Saved: ragas_overall_scores.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303dec01-52f0-4ab3-8030-1575d109cdbd",
   "metadata": {},
   "source": [
    "### Per-Question RAGAS Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dab4e5-e824-4cd8-a8be-7053492a73a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "\n",
    "per_question = evaluate(\n",
    "    df_sample,\n",
    "    metrics=[\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        answer_correctness,\n",
    "    ],\n",
    "    return_multi=True \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec8d57f-254e-4982-8151-0d0386621101",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_question_df = per_question.to_pandas()\n",
    "per_question_df.to_csv(\"ragas_per_question_scores.csv\", index=False)\n",
    "\n",
    "print(\"Saved: ragas_per_question_scores.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34277cf0-c532-434b-b462-5fbde0b2653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ragas_df = result.to_pandas()\n",
    "ragas_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dfea3c-b664-4b41-a5a6-5e2c19c8afb7",
   "metadata": {},
   "source": [
    "## Bar Chart + Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b343f3-e007-47fc-a948-1422ee7bbcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(ragas_df[\"metric\"], ragas_df[\"value\"], color=\"#4C72B0\")\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"RAGAS Metrics Overview\", fontsize=16)\n",
    "plt.ylabel(\"Score\", fontsize=14)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"ragas_bar_chart.png\", dpi=400)\n",
    "plt.show()\n",
    "\n",
    "print(\"✔ Saved: ragas_bar_chart.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8795eb96-1352-4224-a265-b19825d2bbbb",
   "metadata": {},
   "source": [
    "## Line Chart + Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d35baa-cc46-43ce-a927-b29bc8e0efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(ragas_df[\"metric\"], ragas_df[\"value\"], marker=\"o\", linewidth=2, color=\"#55A868\")\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"RAGAS Metrics Trend\", fontsize=16)\n",
    "plt.ylabel(\"Score\", fontsize=14)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"ragas_line_chart.png\", dpi=400)\n",
    "plt.show()\n",
    "\n",
    "print(\"✔ Saved: ragas_line_chart.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9946037-c886-4923-b149-a4247a86f11f",
   "metadata": {},
   "source": [
    "## Radar Chart (Spider Plot) + Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9790a61e-b38d-4b02-839b-06f418b2457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics = ragas_df[\"metric\"].tolist()\n",
    "values = ragas_df[\"value\"].tolist()\n",
    "\n",
    "# Close the circle\n",
    "values += values[:1]\n",
    "angles = np.linspace(0, 2*np.pi, len(values))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "ax = plt.subplot(111, polar=True)\n",
    "\n",
    "ax.plot(angles, values, linewidth=2, color=\"#C44E52\")\n",
    "ax.fill(angles, values, alpha=0.25, color=\"#C44E52\")\n",
    "\n",
    "ax.set_thetagrids(angles[:-1] * 180/np.pi, metrics)\n",
    "ax.set_title(\"RAGAS Radar Chart\", fontsize=16)\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"ragas_radar_chart.png\", dpi=400)\n",
    "plt.show()\n",
    "\n",
    "print(\"✔ Saved: ragas_radar_chart.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49432dcc-a2a0-4882-8ef7-1e523f3876ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c0e7da-46f7-48aa-9d22-77aa72cbc9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "NLP_GPU",
   "language": "python",
   "name": "nlp_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "001c0e7167de433ba6cdb0153b4e659c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a9282831c7941debba6167f822f34ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_58688824aaba46eca6c12780d1b40208",
      "placeholder": "​",
      "style": "IPY_MODEL_c46744a601b44b2888a0f74cee2d37ad",
      "value": ""
     }
    },
    "0b24a0c92fea45e3b0c9cbbcfe5415da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33465b5f13f4470691d62e02bbcfc0f1",
      "placeholder": "​",
      "style": "IPY_MODEL_cfe51a7e9b1744149d052a179aee5394",
      "value": "Connecting..."
     }
    },
    "14d4231d5e1840e48fbab399d928a0e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1b47880b48754a76baf2c33695e0d710": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "201fc2a10d6e4fa09fcdf4450ef217a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33465b5f13f4470691d62e02bbcfc0f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4583f946b07d428a81f6a4a091428436": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48266caffc3642bf80243e2b263788ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ec524274197a472bab36b64889c7dc22",
       "IPY_MODEL_4b4e2f42e5d943cfa4452775d7f578d8",
       "IPY_MODEL_60d5150556e24769b4226fb6140c4063"
      ],
      "layout": "IPY_MODEL_be5e183822084b678718b93b1be65825"
     }
    },
    "4b4e2f42e5d943cfa4452775d7f578d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b47880b48754a76baf2c33695e0d710",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_14d4231d5e1840e48fbab399d928a0e3",
      "value": 0
     }
    },
    "5219f1cda6084778a3020c9ca610937b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58688824aaba46eca6c12780d1b40208": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ed956e96d91490abaf0b81686b93e41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "60d5150556e24769b4226fb6140c4063": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_201fc2a10d6e4fa09fcdf4450ef217a4",
      "placeholder": "​",
      "style": "IPY_MODEL_9fa638591c1446f296bcd0a4d5d8beec",
      "value": " 0/0 [00:00&lt;?, ?it/s]"
     }
    },
    "6180a95556ff4750ad719853f6ee4def": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "66a21e5670724ec3996051f880d036ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5219f1cda6084778a3020c9ca610937b",
      "placeholder": "​",
      "style": "IPY_MODEL_ea13d1684e4344128c5d9d0671e939e7",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "6869d513358e4bfd83bdb71574bf10c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d156d4754294af1813ea22b6661babe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_b9132baefcc8429d858ccfeaf9ec3fd5",
      "style": "IPY_MODEL_4583f946b07d428a81f6a4a091428436",
      "value": true
     }
    },
    "808c36e93d2048668b69d3ae318c907c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ccc0cd0211b4149a777ceddb8eb9966": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3c47d7999f74d7aa5e515124ec7f1de",
      "placeholder": "​",
      "style": "IPY_MODEL_6180a95556ff4750ad719853f6ee4def",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "9ac57a0bea624b609b14cee87aee51d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_808c36e93d2048668b69d3ae318c907c",
      "placeholder": "​",
      "style": "IPY_MODEL_ad6f03081dbd4db3a0bff7541ed73a1a",
      "value": "'latin-1' codec can't encode characters in position 12-51: ordinal not in range(256)"
     }
    },
    "9fa638591c1446f296bcd0a4d5d8beec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a901cee7ad8745a690d40488cfdff2b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_cc335451b3654eccafd9482b68870f91",
      "style": "IPY_MODEL_5ed956e96d91490abaf0b81686b93e41",
      "tooltip": ""
     }
    },
    "ac65ea30c9b64970b7bbe555d3db25fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "ad6f03081dbd4db3a0bff7541ed73a1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b60afac4cbc64b0f84449d614362c444": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9ac57a0bea624b609b14cee87aee51d5"
      ],
      "layout": "IPY_MODEL_ac65ea30c9b64970b7bbe555d3db25fe"
     }
    },
    "b9132baefcc8429d858ccfeaf9ec3fd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be5e183822084b678718b93b1be65825": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c46744a601b44b2888a0f74cee2d37ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cc335451b3654eccafd9482b68870f91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cfe51a7e9b1744149d052a179aee5394": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea13d1684e4344128c5d9d0671e939e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec524274197a472bab36b64889c7dc22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_001c0e7167de433ba6cdb0153b4e659c",
      "placeholder": "​",
      "style": "IPY_MODEL_6869d513358e4bfd83bdb71574bf10c7",
      "value": ""
     }
    },
    "f3c47d7999f74d7aa5e515124ec7f1de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
